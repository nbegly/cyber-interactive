<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>SecurityX Prep Quiz</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="manifest" href="../../../manifest.json">
    
    <style>
        .top-right-nav {
            position: fixed;
            top: 15px;
            right: 15px;
            z-index: 1060;
        }

        :root {
            --main-bg: #121212;
            --card-bg: #1e1e1e;
            --text-color: #e0e0e0;
            --sidebar-bg: #1a1a1a;
            --sidebar-active: #4CAF50;
            --sidebar-text: #e0e0e0;
            --answer-bg: #2c2c2c;
            --answer-active: #388E3C;
            --btn-next: #4CAF50; 
            --btn-prev: #2c2c2c;
            --btn-next-text: #fff;
            --modal-bg: #2c2c2c;
            --modal-header-bg: #1e1e1e;
            --progress-bar-bg: #4CAF50;
        }

        body {
            background: var(--main-bg);
            color: var(--text-color);
            font-family: 'Segoe UI', Arial, sans-serif;
            min-height: 100vh;
        }

        .quiz-sidebar {
            background: var(--sidebar-bg);
            border-radius: 18px;
            box-shadow: 0 2px 12px #0008;
            padding: 1rem 0.5rem;
            min-height: 90vh;
            height: 100%;
            position: relative;
            display: flex;
            flex-direction: column;
        }

        .quiz-sidebar .sidebar-btn {
            display: block;
            border: none;
            background: none;
            width: 100%;
            text-align: left;
            color: var(--sidebar-text);
            border-radius: 8px;
            margin-bottom: 8px;
            padding: 10px 16px;
            transition: background 0.2s;
            font-weight: 500;
        }

        .quiz-sidebar .sidebar-btn.active,
        .quiz-sidebar .sidebar-btn:focus {
            background: var(--sidebar-active);
            color: #fff;
            outline: none;
        }

        .quiz-sidebar .sidebar-btn.missed {
            background: #5c4033;
            color: #f5e9e2;
        }

        .quiz-sidebar .sidebar-btn.flagged {
            border-left: 5px solid #ffab40;
            background: #59442b;
            color: #f5e9e2;
        }
        
        #quizContainer {
            height: 100vh;
        }

        .reset-quiz-container {
            position: sticky;
            bottom: 0;
            background: var(--sidebar-bg);
            padding-top: 5px;
            padding-bottom: 5px;
            z-index: 10;
            margin-top: auto;
        }

        .reset-quiz-btn {
            width: 100%; 
        }
        
        .main-content-area {
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
            justify-content: flex-start;
            position: relative;
        }

        .quiz-title {
            margin-top: 40px;
            font-weight: 700;
            color: var(--sidebar-active);
            font-size: 2rem;
            text-align: center;
            letter-spacing: 1px;
        }
        
        .quiz-card, #quizSetup .card {
            border-radius: 18px;
            background: var(--card-bg);
            border: 1px solid #2c2c2c;
            box-shadow: 0 2px 16px #0008;
            padding: 2rem;
            margin: 1rem 0 2rem 0;
            width: 90%;
        }

        #quizSetup .card {
            color: var(--text-color);
            background: var(--card-bg);
        }
        
        #category-list {
            max-height: 200px;
            overflow-y: auto;
            border: 1px solid #444;
            border-radius: .25rem;
            padding: 10px;
        }

        #sidebarList {
            flex-grow: 1; 
            overflow-y: auto; 
            margin-bottom: 1rem; 
        }

        .answer-option {
            border-radius: 10px;
            background: var(--answer-bg);
            margin-bottom: 14px;
            padding: 12px 20px;
            border: 2px solid transparent;
            cursor: pointer;
            transition: background 0.18s, border 0.18s;
        }

        .answer-option.selected {
            background: var(--answer-active);
            border-color: var(--sidebar-active);
            font-weight: 600;
        }

        .answer-option:hover {
            opacity: 0.8;
        }
        
        .nav-btns {
            display: flex;
            gap: 15px;
            justify-content: center;
        }

        .nav-btn {
            min-width: 140px;
            padding: 12px 0;
            border-radius: 10px;
            font-size: 1.13rem;
            font-weight: 600;
            border: none;
            transition: 0.15s;
        }

        .nav-btn.prev {
            background: var(--btn-prev);
            color: var(--text-color);
            border: 1px solid var(--sidebar-active);
        }

        .nav-btn.next {
            background: var(--btn-next);
            color: var(--btn-next-text);
        }

        .progress-bar {
            background-color: var(--progress-bar-bg);
        }
        
        .modal-content {
            border-radius: 16px;
            background: var(--modal-bg);
            color: var(--text-color);
            border: 1px solid #444;
        }

        .modal-header {
            background: var(--modal-header-bg);
            border-bottom: 1px solid #444;
            border-top-left-radius: 16px;
            border-top-right-radius: 16px;
        }

        .back-btn {
            display: inline-block;
            padding: 8px 16px;
            background-color: #34495e; 
            color: #fff;
            text-decoration: none; 
            border-radius: 5px;
            font-weight: 500;
            border: none;
        }

        .back-btn:hover {
            opacity: 0.9;
            color: #fff;
        }

        .btn-close {
            filter: invert(1) grayscale(100%) brightness(200%);
        }

        .progress-bar-objective {
            display: flex;
            height: 1.2rem;
            overflow: hidden;
            background-color: #3e3e3e;
            border-radius: .375rem;
            box-shadow: inset 0 1px 2px rgba(0,0,0,.2);
        }
        .progress-bar-correct { background-color: #4CAF50; }
        .progress-bar-incorrect { background-color: #dc3545; } 
        .progress-bar-flagged { background-color: #ffc107; } 

    </style>
</head>
<body>
    <div class="top-right-nav">
        <a href="../index.html" class="back-btn">Back to Exam Hub</a>
    </div>

    <div class="container-fluid">
        <div id="quizSetup" class="d-flex justify-content-center align-items-center" style="min-height: 100vh;">
            <div class="card p-4">
                <h3 class="text-center mb-3">Quiz Setup</h3>
                
<fieldset class="mb-3">
    <div class="d-flex justify-content-between align-items-center mb-2">
        <legend class="h5 mb-0">Exam Objectives</legend>
        <button type="button" class="btn btn-sm btn-outline-secondary" onclick="toggleAllCategories(this)">Deselect All</button>
    </div>
    <div id="category-list" class="p-2">
        </div>
</fieldset>

                <div class="mb-3">
                    <label for="numQuestions" class="form-label">Number of Questions: (max 343)</label>
                    <input type="number" class="form-control" id="numQuestions" value="25" min="1">
                </div>

                <div class="form-check mb-4">
                    <input class="form-check-input" type="checkbox" id="randomizeQuestions" checked>
                    <label class="form-check-label" for="randomizeQuestions">
                        Randomize Questions
                    </label>
                </div>
                <button class="btn btn-primary" onclick="startQuiz()" style="background-color: var(--btn-next); border-color: var(--btn-next);">Start Quiz</button>
            </div>
        </div>

        <div class="row flex-nowrap d-none" id="quizContainer">
            <div class="col-md-3 col-lg-2 p-3">
                <div class="quiz-sidebar h-100">
                    <h5 class="mb-2 ms-2">Questions</h5>
                    <div id="counters" class="mb-3 ms-2">
                        <div>Correct: <span id="correct-counter" class="fw-bold text-success">0</span></div>
                        <div>Incorrect: <span id="incorrect-counter" class="fw-bold text-danger">0</span></div>
                        <div>Flagged: <span id="flagged-counter" class="fw-bold text-warning">0</span></div>
                    </div>
                    <hr style="border-top: 1px solid #444;">
                    <div id="sidebarList"></div>
                    <div class="reset-quiz-container">
                        <button class="btn btn-danger reset-quiz-btn" onclick="resetQuiz()">New Quiz</button>
                    </div>
                </div>
            </div>
            <div class="col-md-9 col-lg-10 p-0">
                <div class="main-content-area">
                    <div class="quiz-title">SecurityX Practice Quiz</div>
                    <div class="progress mb-4" style="height: 16px; background-color: #444; width: 100vh;">
                        <div class="progress-bar" id="progressBar" style="width: 0%;">0%</div>
                    </div>
                    <div id="quizArea" style="width:100%; overflow-wrap: break-word;"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="modal fade" id="explanationModal" tabindex="-1" aria-labelledby="explanationLabel" aria-hidden="true">
        <div class="modal-dialog modal-md modal-dialog-centered">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="explanationLabel">Explanation</h5>
                    <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body" id="explanationBody"></div>
            </div>
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    
    <script>
        const examCategories = [
    "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
    "1.2 Given a set of organizational security requirements, perform risk management activities.",
    "1.3 Explain how compliance affects information security strategies.",
    "1.4 Given a scenario, perform threat-modeling activities.",
    "1.5 Summarize the information security challenges associated with artificial intelligence (AI) adoption.",
    "2.1 Given a scenario, analyze requirements to design resilient systems.",
    "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
    "2.3 Given a scenario, integrate appropriate controls in the design of a secure architecture.",
    "2.4 Given a scenario, apply security concepts to the design of access, authentication, and authorization systems.",
    "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
    "2.6 Given a scenario, integrate Zero Trust concepts into system architecture design.",
    "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
    "3.2 Given a scenario, analyze requirements to enhance the security of endpoints and servers.",
    "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
    "3.4 Given a scenario, implement hardware security technologies and techniques.",
    "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
    "3.6 Given a scenario, use automation to secure the enterprise.",
    "3.7 Explain the importance of advanced cryptographic concepts.",
    "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
    "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
    "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
    "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
    "4.4 Given a scenario, analyze data and artifacts in support of incident response activities."
];

        const allQuestions = [
    {
        "id": 1,
        "q": "A security engineer is reviewing event logs because an employee successfully connected a personal Windows laptop to the corporate network, which is against company policy. Company policy allows all Windows 10 and 11 laptops to connect to the system as long as the MDM agent installed by IT is running. Only compliant devices can connect, and the logic in the system to evaluate compliant laptops is as follows: <br><br> <img src='../../assets/quiz-images/CAS-005_1.png' alt='Compliance check code snippet'> <br><br> Which of the following most likely occurred when the employee connected a personally owned Windows laptop and was allowed on the network?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "The agent was not running on the laptop, which triggered a false positive.",
                "correct": false,
                "explain": "Incorrect. A false positive would occur if a compliant device was incorrectly flagged as non-compliant. In this scenario, a non-compliant device was incorrectly allowed on the network."
            },
            {
                "text": "The OS was a valid version, but the MDM agent was not installed, triggering a true positive.",
                "correct": false,
                "explain": "Incorrect. A true positive would occur if a non-compliant device was correctly identified as non-compliant and blocked. The device was allowed on the network."
            },
            {
                "text": "The OS was running a Windows version below 10 and triggered a false negative.",
                "correct": true,
                "explain": "Correct. The code has a logic flaw. If the 'laptop['OsVersion'] >= 10' check fails (i.e., the OS is older than Windows 10), the code's 'else' block automatically returns 'COMPLIANT' without checking for the MDM agent. This is a false negative because a non-compliant device was incorrectly approved."
            },
            {
                "text": "The OS version was higher than 11, and the MDM agent was running, triggering a true negative.",
                "correct": false,
                "explain": "Incorrect. A true negative would mean a compliant device (meeting all policy requirements) was correctly allowed. The scenario describes a non-compliant personal laptop being improperly allowed access."
            }
        ]
    },
    {
        "id": 2,
        "q": "An organization is working to secure its development process to ensure developers cannot deploy artifacts directly into the production environment. Which of the following security practice recommendations would be the best to accomplish this objective?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "Implement least privilege access to all systems.",
                "correct": false,
                "explain": "Incorrect. While least privilege is a crucial security principle, it is a broad concept. Separation of duties is a more specific control designed to prevent a single individual from having end-to-end control over a process like code deployment."
            },
            {
                "text": "Roll out security awareness training for all users.",
                "correct": false,
                "explain": "Incorrect. Security awareness training is important for changing user behavior but is not a technical or procedural control to prevent developers from deploying code to production."
            },
            {
                "text": "Set up policies and systems with separation of duties.",
                "correct": true,
                "explain": "Correct. Separation of duties is a foundational governance and security principle that ensures no single individual has the authority to execute all critical tasks in a process. [cite_start]In this context, it would mean the person who writes the code (the developer) is not the same person who deploys it to production, directly addressing the objective. [cite: 64]"
            },
            {
                "text": "Enforce job rotations for all developers and administrators.",
                "correct": false,
                "explain": "Incorrect. Job rotation is a control used to detect and deter fraud by moving personnel between different responsibilities, but it does not inherently prevent a developer from deploying code if they have the permissions to do so."
            },
            {
                "text": "Utilize mandatory vacations for all developers.",
                "correct": false,
                "explain": "Incorrect. Mandatory vacations are a detective control designed to uncover fraudulent activities that require constant presence to maintain, not a preventative control for deployment processes."
            },
            {
                "text": "Review all access to production systems on a quarterly basis.",
                "correct": false,
                "explain": "Incorrect. Access reviews are a detective control. While useful for identifying excessive permissions after the fact, they do not actively prevent the action of deploying code."
            }
        ]
    },
    {
        "id": 3,
        "q": "A security architect discovers the following while reviewing code for a company's website: <br><br> `selection = \"SELECT Item FROM Catalog WHERE ItemID = \" & Request(\"ItemID\")` <br><br> Which of the following should the security architect recommend?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Client-side processing",
                "correct": false,
                "explain": "Incorrect. Moving processing to the client-side does not solve the underlying vulnerability and can often introduce new risks, as client-side code can be manipulated by the user."
            },
            {
                "text": "Query parameterization",
                "correct": true,
                "explain": "Correct. The code snippet is vulnerable to SQL injection because it directly concatenates user input (`Request(\"ItemID\")`) into a database query. Query parameterization (using prepared statements) is the primary defense against SQL injection. It ensures that user input is treated as data, not as executable code, by pre-compiling the SQL statement."
            },
            {
                "text": "Data normalization",
                "correct": false,
                "explain": "Incorrect. Data normalization is a database design process for organizing columns and tables to minimize data redundancy. It is not a security control for mitigating SQL injection."
            },
            {
                "text": "Escape character blocking",
                "correct": false,
                "explain": "Incorrect. While escaping characters can be part of a defense-in-depth strategy, it is often incomplete and prone to error. Parameterization is the industry-standard best practice and is much more effective."
            },
            {
                "text": "URL encoding",
                "correct": false,
                "explain": "Incorrect. URL encoding ensures that data can be transmitted safely over the internet but does not protect against SQL injection vulnerabilities on the backend server."
            }
        ]
    },
    {
        "id": 4,
        "q": "A security architect needs to enable a container orchestrator for DevSecOps and SOAR initiatives. The engineer has discovered that several Ansible YAML files used for the automation of configuration management have the following content: <br><br> <img src='../../assets/quiz-images/CAS-005_4.png' alt='Ansible and Kubernetes configuration files'> <br><br> Which of the following should the engineer do to correct the security issues presented within this content?",
        "type": "single",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "Update the kubernetes.core.k8s module to kubernetes.core.k8s_service in the main.yml file.",
                "correct": false,
                "explain": "Incorrect. While using more specific modules can be a good practice, the primary security issue here is the insecure binding, not the module name itself."
            },
            {
                "text": "Update the COMPTIA001 hostname to localhost using the hostnamectl command.",
                "correct": false,
                "explain": "Incorrect. Changing the hostname does not resolve the insecure binding issue within the Kubernetes configuration."
            },
            {
                "text": "Update the state: present module to state: absent in the main.yml file.",
                "correct": false,
                "explain": "Incorrect. Setting the state to 'absent' would remove the Kubernetes service object, which is not the goal. The goal is to secure the existing service."
            },
            {
                "text": "Update or remove the ansible.cfg file.",
                "correct": false,
                "explain": "Incorrect. The ansible.cfg file simply enables the Kubernetes plugin; it is not the source of the insecure configuration."
            },
            {
                "text": "Update the insecure-bind-address from localhost to the COMPTIA001 in the manifests file.",
                "correct": true,
                "explain": "Correct. The line `insecure-bind-address \"localhost\"` in the Kubernetes manifest is a significant security risk. It implies the service is binding to an address without proper security controls. The most likely remediation is to bind it to a specific, secure interface (represented by the hostname COMPTIA001) or, more accurately, to remove the insecure binding entirely and use secure defaults. In the context of the choices, updating it from the overly permissive 'localhost' is the correct security action."
            }
        ]
    },
    {
        "id": 5,
        "q": "A CRM company leverages a CSP PaaS service to host and publish Its SaaS product. Recently, a large customer requested that all infrastructure components must meet strict regulatory requirements, including configuration management, patch management, and life-cycle management. Which of the following organizations is responsible for ensuring those regulatory requirements are met?",
        "type": "single",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "The CRM company",
                "correct": false,
                "explain": "Incorrect. [cite_start]In a PaaS model, the CRM company is responsible for the application and data, but the underlying infrastructure (including OS patching and configuration) is managed by the Cloud Service Provider (CSP). [cite: 326]"
            },
            {
                "text": "The CRM company's customer",
                "correct": false,
                "explain": "Incorrect. The customer is responsible for their use of the SaaS product, not the underlying infrastructure of the service they are consuming."
            },
            {
                "text": "The CSP",
                "correct": true,
                "explain": "Correct. According to the shared responsibility model, when using a Platform as a Service (PaaS) offering, the Cloud Service Provider (CSP) is responsible for managing the underlying infrastructure. [cite_start]This includes the physical hardware, networking, and the platform itself, which covers OS patching and configuration management. [cite: 326]"
            },
            {
                "text": "The regulatory body",
                "correct": false,
                "explain": "Incorrect. The regulatory body sets the requirements but is not responsible for implementing them; that responsibility falls to the service provider or their client."
            }
        ]
    },
    {
        "id": 6,
        "q": "Company A is merging with Company B. Company A is a small, local company. Company B has a large, global presence. The two companies have a lot of duplication in their IT systems, processes, and procedures. On the new Chief Information Officer's (CIO's) first day, a fire breaks out at Company B's main data center. Which of the following actions should the CIO take first?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Determine whether the incident response plan has been tested at both companies, and use it to respond.",
                "correct": false,
                "explain": "Incorrect. While checking if plans are tested is good, the immediate priority during a crisis is to activate the existing plans to manage the disaster, not to perform a comparative analysis."
            },
            {
                "text": "Review the incident response plans, and engage the disaster recovery plan while relying on the IT leaders from both companies.",
                "correct": true,
                "explain": "Correct. In a crisis like a data center fire, the immediate priority is to activate the documented plans for such an event. [cite_start]The CIO should engage the disaster recovery (DR) plan, which is specifically designed for catastrophic events, and leverage the expertise of the existing IT leadership to execute the response effectively. [cite: 96, 114]"
            },
            {
                "text": "Ensure hot, warm, and mobile disaster recovery sites are available, and give an update to the companies' leadership teams.",
                "correct": false,
                "explain": "Incorrect. While ensuring DR sites are available is part of the DR plan, the first action is to initiate the plan itself. The CIO wouldn't know if those sites are available without first consulting the plan and the team."
            },
            {
                "text": "Initiate Company A's IT systems processes and procedures, assess the damage, and perform a BIA.",
                "correct": false,
                "explain": "Incorrect. Performing a Business Impact Analysis (BIA) is a planning activity done before an incident, not during one. Arbitrarily using the smaller company's plans for a large global company's disaster is illogical."
            }
        ]
    },
    {
        "id": 7,
        "q": "The results of an internal audit indicate several employees reused passwords that were previously included in a published list of compromised passwords. The company has the following employee password policy: <br><br> <img src='../../assets/quiz-images/CAS-005_7.png' alt='Password policy table'> <br><br> Which of the following should be implemented to best address the password reuse issue? (Choose two.)",
        "type": "multiple",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Increase the minimum age to two days.",
                "correct": true,
                "explain": "Correct. Setting a minimum password age prevents users from immediately changing their password multiple times in a row to circumvent the history policy and reuse an old favorite password. This directly addresses the reuse issue."
            },
            {
                "text": "Increase the history to 20.",
                "correct": true,
                "explain": "Correct. The password history setting prevents users from reusing their most recent passwords. Increasing the history from 8 to 20 makes it significantly harder for a user to cycle back to a previously used or compromised password."
            },
            {
                "text": "Increase the character length to 12.",
                "correct": false,
                "explain": "Incorrect. While increasing length improves password strength against brute-force attacks, it does not directly prevent the reuse of a known, compromised password."
            },
            {
                "text": "Add case-sensitive requirements to character class.",
                "correct": false,
                "explain": "Incorrect. Adding more complexity requirements improves password strength but does not stop a user from reusing a compromised password that already meets those requirements."
            },
            {
                "text": "Decrease the maximum age to 30 days.",
                "correct": false,
                "explain": "Incorrect. Decreasing the maximum age forces more frequent password changes, which can lead to users choosing weaker, easier-to-remember passwords and does not in itself prevent reuse of compromised credentials."
            },
            {
                "text": "Remove the complexity requirements.",
                "correct": false,
                "explain": "Incorrect. Removing complexity requirements would weaken the password policy, making passwords easier to guess or brute-force."
            },
            {
                "text": "Increase the maximum age to 120 days.",
                "correct": false,
                "explain": "Incorrect. Increasing the maximum age allows a potentially compromised password to remain active for a longer period, increasing risk."
            }
        ]
    },
    {
        "id": 8,
        "q": "A mobile administrator is reviewing the following mobile device DHCP logs to ensure the proper mobile settings are applied to managed devices: <br><br> <img src='../../assets/quiz-images/CAS-005_8.png' alt='DHCP logs for a mobile device'> <br><br> Which of the following mobile configuration settings is the mobile administrator verifying?",
        "type": "single",
        "category": "3.2 Given a scenario, analyze requirements to enhance the security of endpoints and servers.",
        "answers": [
            {
                "text": "Service set identifier authentication",
                "correct": false,
                "explain": "Incorrect. SSID authentication relates to the name of the wireless network itself, which is not directly verifiable from these DHCP logs."
            },
            {
                "text": "Wireless network auto joining",
                "correct": false,
                "explain": "Incorrect. While the device is clearly joining a network, these logs do not provide information to verify if the connection was automatic or manual."
            },
            {
                "text": "802.1X with mutual authentication",
                "correct": false,
                "explain": "Incorrect. 802.1X is an authentication framework, but these logs are from DHCP, which occurs after successful network authentication. They show IP address assignment, not the authentication process itself."
            },
            {
                "text": "Association MAC address randomization",
                "correct": true,
                "explain": "Correct. The log shows that the same device, 'UserA-MobileDevice', is being assigned a new IP address each day, and more importantly, it is presenting a different MAC address each time (0236FB..., 068AD1..., 0ABC65..., etc.). This is a clear indicator of MAC address randomization, a privacy feature where a device uses a different, randomly generated MAC address for each network connection to prevent tracking."
            }
        ]
    },
    {
        "id": 9,
        "q": "A security analyst is investigating a possible insider threat incident that involves the use of an unauthorized USB from a shared account to exfiltrate data. The event did not create an alert. The analyst has confirmed the USB hardware ID is not on the device allow list, but has not yet confirmed the owner of the USB device. Which of the following actions should the analyst take next?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "Classify the incident as a false positive.",
                "correct": false,
                "explain": "Incorrect. A false positive is an alert that incorrectly indicates a problem. Here, there was a real problem (unauthorized USB use) but no alert was generated."
            },
            {
                "text": "Classify the incident as a false negative.",
                "correct": true,
                "explain": "Correct. A false negative is a failure of a security system to detect a genuine threat. [cite_start]Since an unauthorized USB device was used to exfiltrate data and the system did not generate an alert, this is a classic example of a false negative. [cite: 629]"
            },
            {
                "text": "Classify the incident as a true positive.",
                "correct": false,
                "explain": "Incorrect. A true positive is when a system correctly generates an alert for a genuine threat. No alert was generated in this scenario."
            },
            {
                "text": "Classify the incident as a true negative.",
                "correct": false,
                "explain": "Incorrect. A true negative is when a system correctly identifies benign activity as non-threatening and does not generate an alert. The activity described was malicious."
            }
        ]
    },
    {
        "id": 10,
        "q": "Which of the following security features do email signatures provide?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Non-repudiation",
                "correct": true,
                "explain": "Correct. A digital signature on an email provides non-repudiation, which is the assurance that the sender cannot later deny having sent the message. [cite_start]This is achieved because the signature is created with the sender's private key, which only they should possess. [cite: 595, 610]"
            },
            {
                "text": "Body encryption",
                "correct": false,
                "explain": "Incorrect. Digital signatures provide integrity and authentication, but they do not encrypt the content of the email body. Email encryption is a separate process."
            },
            {
                "text": "Code signing",
                "correct": false,
                "explain": "Incorrect. Code signing is the process of digitally signing software executables and scripts to verify the author's identity and ensure the code has not been altered. [cite_start]It is not used for email messages themselves. [cite: 608]"
            },
            {
                "text": "Sender authentication",
                "correct": false,
                "explain": "Incorrect. While a digital signature does authenticate the sender, its most comprehensive security feature is non-repudiation, which includes authentication as a component. Non-repudiation is the stronger and more complete answer."
            },
            {
                "text": "Chain of custody",
                "correct": false,
                "explain": "Incorrect. Chain of custody is a forensic process used to document the handling of evidence and is not a feature provided by email signatures."
            }
        ]
    },
    {
        "id": 11,
        "q": "A software development company wants to ensure that users can confirm the software is legitimate when installing it. Which of the following is the best way for the company to achieve this security objective?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Code signing",
                "correct": true,
                "explain": "Correct. Code signing is the process of applying a digital signature to a piece of software. This allows the end-user's system to verify that the software genuinely comes from the stated publisher (authenticity) and that it has not been tampered with since it was signed (integrity). [cite_start]This directly addresses the objective of confirming legitimacy. [cite: 603, 604, 608]"
            },
            {
                "text": "Non-repudiation",
                "correct": false,
                "explain": "Incorrect. Non-repudiation is a result of using digital signatures, but 'code signing' is the specific process used for software. [cite_start]Non-repudiation prevents the developer from denying they created the software. [cite: 595]"
            },
            {
                "text": "Key escrow",
                "correct": false,
                "explain": "Incorrect. Key escrow is the process of storing a copy of a private key with a trusted third party. It is used for key recovery, not for verifying software legitimacy to end-users."
            },
            {
                "text": "Private keys",
                "correct": false,
                "explain": "Incorrect. A private key is the tool used to create the digital signature in the code signing process, but it is not the process itself. The company would use its private key to sign the code."
            }
        ]
    },
    {
        "id": 12,
        "q": "While performing mandatory monthly patch updates on a production application server, the security analyst reports an instance of buffer overflow for a new application that was migrated to the cloud and is also publicly exposed. Security policy requires that only internal users have access to the application. Which of the following should the analyst implement to mitigate the issues reported? (Choose two.)",
        "type": "multiple",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Configure firewall rules to block all external traffic.",
                "correct": true,
                "explain": "Correct. The security policy explicitly states that only internal users should have access. Configuring firewall rules (or security group rules in a cloud context) to block all traffic from external IP addresses directly enforces this policy and mitigates the risk from the public exposure."
            },
            {
                "text": "Enable input validation for all fields.",
                "correct": true,
                "explain": "Correct. A buffer overflow vulnerability is typically caused by the application failing to properly validate the size and type of user-supplied input. [cite_start]Implementing proper input validation is a direct code-level mitigation for this class of vulnerability. [cite: 682]"
            },
            {
                "text": "Enable automatic updates to be installed on all servers.",
                "correct": false,
                "explain": "Incorrect. While patching is important, the scenario states the analyst was already performing patch updates when the issue was found. This action doesn't address the core issues of improper access control and the specific code vulnerability."
            },
            {
                "text": "Configure the security group to enable external traffic.",
                "correct": false,
                "explain": "Incorrect. This is the opposite of the required action. Enabling external traffic would violate the security policy that restricts access to internal users only."
            },
            {
                "text": "Set up a DLP policy to alert for exfiltration on all application servers.",
                "correct": false,
                "explain": "Incorrect. Data Loss Prevention (DLP) is a detective or preventative control for data exfiltration. It would not mitigate the buffer overflow vulnerability itself or the improper network exposure."
            },
            {
                "text": "Enable nightly vulnerability scans.",
                "correct": false,
                "explain": "Incorrect. Vulnerability scanning is a detective control used to find issues. It does not mitigate the existing, known vulnerabilities of public exposure and buffer overflow."
            }
        ]
    },
    {
        "id": 13,
        "q": "PKI can be used to support security requirements in the change management process. Which of the following capabilities does PKI provide for messages?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Non-repudiation",
                "correct": true,
                "explain": "Correct. Public Key Infrastructure (PKI) enables the use of digital signatures. [cite_start]A key feature of a digital signature is providing non-repudiation, which ensures that the originator of a message (or a change request) cannot deny having sent it. [cite: 595, 610]"
            },
            {
                "text": "Confidentiality",
                "correct": false,
                "explain": "Incorrect. While PKI can be used to provide confidentiality through encryption, its role in providing digital signatures for non-repudiation is a more direct application in a change management process to verify the authenticity and integrity of requests."
            },
            {
                "text": "Delivery receipts",
                "correct": false,
                "explain": "Incorrect. Delivery receipts are a function of mail systems and protocols, not a direct capability provided by PKI itself."
            },
            {
                "text": "Attestation",
                "correct": false,
                "explain": "Incorrect. Attestation is the process of verifying that a system or component is in a known, trusted state. [cite_start]While PKI can be used to sign attestation reports, non-repudiation of messages is a more fundamental capability. [cite: 298]"
            }
        ]
    },
    {
        "id": 14,
        "q": "Several unlabeled documents in a cloud document repository contain cardholder information. Which of the following configuration changes should be made to the DLP system to correctly label these documents in the future?",
        "type": "single",
        "category": "2.3 Given a scenario, integrate appropriate controls in the design of a secure architecture.",
        "answers": [
            {
                "text": "Digital rights management",
                "correct": false,
                "explain": "Incorrect. Digital Rights Management (DRM) is used to control what users can do with a file after they have access to it (e.g., prevent printing or copying). It doesn't identify or label the data itself."
            },
            {
                "text": "Network traffic decryption",
                "correct": false,
                "explain": "Incorrect. While decrypting traffic might be necessary for a network-based DLP solution to inspect content, it is not the mechanism used to identify specific data patterns like cardholder information."
            },
            {
                "text": "Regular expressions",
                "correct": true,
                "explain": "Correct. Data Loss Prevention (DLP) systems use pattern matching to identify sensitive data. Cardholder information, such as credit card numbers, follows a predictable pattern (e.g., 16 digits, specific starting numbers for different card brands). [cite_start]Regular expressions (regex) are used to define these patterns so the DLP system can automatically discover and classify documents containing this information. [cite: 279]"
            },
            {
                "text": "Watermarking",
                "correct": false,
                "explain": "Incorrect. Watermarking is a technique to embed hidden information into a file to track its provenance or ownership, not to discover and label existing sensitive data within it."
            }
        ]
    },
    {
        "id": 15,
        "q": "A systems administrator at a web-hosting provider has been tasked with renewing the public certificates of all customer sites. Which of the following would best support multiple domain names while minimizing the amount of certificates needed?",
        "type": "single",
        "category": "2.4 Given a scenario, apply security concepts to the design of access, authentication, and authorization systems.",
        "answers": [
            {
                "text": "OCSP",
                "correct": false,
                "explain": "Incorrect. The Online Certificate Status Protocol (OCSP) is a method for checking the revocation status of a certificate. [cite_start]It does not relate to supporting multiple domains on a single certificate. [cite: 308]"
            },
            {
                "text": "CRL",
                "correct": false,
                "explain": "Incorrect. A Certificate Revocation List (CRL) is a list of certificates that have been revoked. It does not relate to supporting multiple domains on a single certificate."
            },
            {
                "text": "SAN",
                "correct": true,
                "explain": "Correct. A Subject Alternative Name (SAN) certificate is a type of digital certificate that allows multiple hostnames (domain names) to be protected by a single certificate. [cite_start]This is the ideal solution for a web-hosting provider that needs to secure many different customer domains while minimizing certificate management overhead and cost. [cite: 306]"
            },
            {
                "text": "CA",
                "correct": false,
                "explain": "Incorrect. A Certificate Authority (CA) is an entity that issues digital certificates. [cite_start]It is the source of the certificates, not a type of certificate that can hold multiple domains. [cite: 310]"
            }
        ]
    },
    {
        "id": 16,
        "q": "Which of the following best explain why organizations prefer to utilize code that is digitally signed? (Choose two.)",
        "type": "multiple",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "It provides origin assurance.",
                "correct": true,
                "explain": "Correct. A digital signature verifies the identity of the publisher (the origin). The user's system can check the signature and confirm the code was created by the claimed developer and not an impostor. [cite_start]This is also referred to as authenticity or software provenance. [cite: 603]"
            },
            {
                "text": "It verifies integrity.",
                "correct": true,
                "explain": "Correct. A digital signature includes a hash of the original code. The user's system calculates a new hash of the received code and compares it to the hash in the signature. [cite_start]If they match, it proves the code has not been altered or corrupted since it was signed. [cite: 604]"
            },
            {
                "text": "It provides increased confidentiality.",
                "correct": false,
                "explain": "Incorrect. Digital signatures do not encrypt the code; they only provide assurance of origin and integrity. Confidentiality would require a separate encryption process."
            },
            {
                "text": "It integrates with DRMs.",
                "correct": false,
                "explain": "Incorrect. While a DRM system might use signed code, code signing itself is a separate security function and not inherently part of DRM."
            },
            {
                "text": "It verifies the recipient's identity.",
                "correct": false,
                "explain": "Incorrect. Code signing verifies the sender's (publisher's) identity, not the recipient's identity."
            },
            {
                "text": "It ensures the code is free of malware.",
                "correct": false,
                "explain": "Incorrect. Code signing only proves who wrote the code and that it hasn't been changed. It does not guarantee the code is bug-free or malware-free. A legitimate developer could unknowingly or maliciously sign malicious code."
            }
        ]
    },
    {
        "id": 17,
        "q": "A security engineer receives reports through the organization's bug bounty program about remote code execution in a specific component in a custom application. Management wants to properly secure the component and proactively avoid similar issues. Which of the following is the best approach to uncover additional vulnerable paths in the application?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Leverage an exploitation framework to uncover vulnerabilities.",
                "correct": false,
                "explain": "Incorrect. An exploitation framework like Metasploit is used to exploit known vulnerabilities, not necessarily to discover new or unknown ones in custom code."
            },
            {
                "text": "Use fuzz testing to uncover potential vulnerabilities in the application.",
                "correct": true,
                "explain": "Correct. Fuzz testing, or fuzzing, is an automated software testing technique that involves providing invalid, unexpected, or random data as inputs to a computer program. It is highly effective at discovering unknown vulnerabilities, particularly memory corruption issues like buffer overflows that can lead to remote code execution. Since an RCE is already known, fuzzing is an excellent way to find other, similar vulnerable paths."
            },
            {
                "text": "Utilize a software composition analysis tool to report known vulnerabilities.",
                "correct": false,
                "explain": "Incorrect. [cite_start]A Software Composition Analysis (SCA) tool identifies vulnerabilities in third-party and open-source libraries, not in the custom-written code itself. [cite: 261]"
            },
            {
                "text": "Reverse engineer the application to look for vulnerable code paths.",
                "correct": false,
                "explain": "Incorrect. While reverse engineering could be used, it is a highly manual and time-consuming process. Automated methods like fuzzing are a more efficient first step for uncovering new vulnerabilities."
            },
            {
                "text": "Analyze the use of an HTTP intercepting proxy to dynamically uncover issues.",
                "correct": false,
                "explain": "Incorrect. [cite_start]An intercepting proxy is a tool for Dynamic Application Security Testing (DAST) and is useful for finding many web vulnerabilities, but fuzzing is more specifically suited to finding memory-based RCE vulnerabilities by sending malformed data. [cite: 241]"
            }
        ]
    },
    {
        "id": 18,
        "q": "A security technician is investigating a system that tracks inventory via a batch update each night. The technician is concerned that the system poses a risk to the business, as errors are occasionally generated and reported inventory appears incorrect. The following output log is provided: <br><br> <img src='../../assets/quiz-images/CAS-005_18.png' alt='Batch job output log'> <br><br> The technician reviews the output of the batch job and discovers that the inventory was never less than zero, and the final inventory was 100 rather than 60. Which of the following should the technician do to resolve this issue?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Ensure that the application is using memory-safe functions to prevent integer overflows.",
                "correct": false,
                "explain": "Incorrect. The log shows a logical error where the balance goes below zero and subsequent calculations are incorrect, but this is not characteristic of an integer overflow, which involves a number wrapping around after exceeding its maximum value."
            },
            {
                "text": "Recommend thread-safe processes in the code to eliminate race conditions.",
                "correct": true,
                "explain": "Correct. The log shows multiple transactions happening in a sequence, but the final running total is incorrect. The fact that the actual inventory was 100 while the log shows 60, and the erroneous 'Below zero balance' message, strongly suggests a race condition. This occurs when multiple threads or processes access and manipulate shared data (the inventory count) concurrently, leading to unpredictable and incorrect results. [cite_start]Implementing thread-safe processes, such as using locks or atomic functions, ensures that operations are completed in the correct order without interfering with each other. [cite: 671, 686]"
            },
            {
                "text": "Require the developers to include exception handlers to accommodate out-of-bounds results.",
                "correct": false,
                "explain": "Incorrect. While exception handling is good practice, it is reactive. It would catch the error (like the negative balance) but wouldn't solve the root cause of the miscalculation, which is likely a race condition."
            },
            {
                "text": "Move the batch processing from client side to server side to remove client processing inconsistencies.",
                "correct": false,
                "explain": "Incorrect. The problem is with the logic of the batch processing itself, not where it's being run. Moving it from client to server side would not fix the underlying concurrency issue."
            }
        ]
    },
    {
        "id": 19,
        "q": "A programmer is reviewing the following proprietary piece of code that was identified as a vulnerability due to users being authenticated when they provide incorrect credentials: <br><br> <img src='../../assets/quiz-images/CAS-005_19.png' alt='Vulnerable authentication code'> <br><br> Which of the following should the programmer implement to remediate the code vulnerability?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Salted hashing via the proprietary SHASH function",
                "correct": false,
                "explain": "Incorrect. The code already uses a HASH function. While salted hashing is a best practice for password storage, it does not fix the fundamental logic flaw in this code that allows authentication to be bypassed."
            },
            {
                "text": "Input validation in the first two lines of code",
                "correct": false,
                "explain": "Incorrect. While input validation is a good security practice, it doesn't address the core vulnerability here, which is the unconditional jump that bypasses the authentication check entirely."
            },
            {
                "text": "Atomic execution of subroutines",
                "correct": true,
                "explain": "Correct. The critical vulnerability is the `JUMP TO :ALLOWUSER:` line, which unconditionally jumps to the section of code that grants access (`SET USERACL`), completely bypassing the `IF` statement that checks the userid and password hash. Removing this jump and ensuring the `IF` condition is checked before any access is granted would make the authentication check an atomic operation (an indivisible and irreducible series of operations). [cite_start]This prevents the check from being bypassed. [cite: 684]"
            },
            {
                "text": "TOCTOU remediation in SET USERACL",
                "correct": false,
                "explain": "Incorrect. A Time-of-Check to Time-of-Use (TOCTOU) vulnerability involves a state change between the check for a condition and the use of the results of that check. [cite_start]The vulnerability here is a logic bypass, not a TOCTOU issue. [cite: 681]"
            },
            {
                "text": "Database connection over encrypted channels",
                "correct": false,
                "explain": "Incorrect. Encrypting the database connection is important for protecting data in transit but does not fix the authentication bypass logic flaw in the application code."
            }
        ]
    },
    {
        "id": 20,
        "q": "A senior cybersecurity engineer is solving a digital certificate issue in which the CA denied certificate issuance due to failed subject identity validation. At which of the following steps within the PKI enrollment process would the denial have occurred?",
        "type": "single",
        "category": "2.4 Given a scenario, apply security concepts to the design of access, authentication, and authorization systems.",
        "answers": [
            {
                "text": "RA",
                "correct": true,
                "explain": "Correct. The Registration Authority (RA) is the component in a Public Key Infrastructure (PKI) responsible for verifying the identity of the entity requesting a certificate (the subject). If the identity validation fails, the RA will not forward the request to the Certificate Authority (CA) for signing, or it will instruct the CA to deny it. [cite_start]Therefore, the denial due to failed identity validation occurs at the RA stage. [cite: 310]"
            },
            {
                "text": "OCSP",
                "correct": false,
                "explain": "Incorrect. The Online Certificate Status Protocol (OCSP) is used to check the revocation status of an already-issued certificate. [cite_start]It is not part of the initial enrollment and identity validation process. [cite: 308]"
            },
            {
                "text": "CA",
                "correct": false,
                "explain": "Incorrect. The Certificate Authority (CA) is responsible for digitally signing and issuing the certificate. While it ultimately denies the issuance, it does so based on the validation (or lack thereof) performed by the RA. [cite_start]The root of the failure is in the identity validation step, which is the RA's function. [cite: 310]"
            },
            {
                "text": "IdP",
                "correct": false,
                "explain": "Incorrect. An Identity Provider (IdP) is a system that creates, maintains, and manages identity information for principals and provides authentication services. [cite_start]While related to identity, in the context of a traditional PKI, the RA performs the specific function of validating identity for certificate requests. [cite: 296]"
            }
        ]
    },
    {
        "id": 21,
        "q": "An internal user can send encrypted emails successfully to all recipients, except one, at an external organization. When the internal user attempts to send encrypted emails to this external recipient, a security error message appears. The issue does not affect unencrypted emails. The external recipient can send encrypted emails to internal users. Which of the following is the most likely cause of the issue?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "The validity dates of the external recipients private key do not match the SSH keys with which the internal user is accessing the system.",
                "correct": false,
                "explain": "Incorrect. SSH keys are used for secure shell access, not for S/MIME email encryption. The issue is with email, not remote server access."
            },
            {
                "text": "The external recipient has an expired public/private key pair that has not been revoked by the CA.",
                "correct": false,
                "explain": "Incorrect. If the external recipient's key pair was expired, they would likely have issues decrypting emails from anyone, not just this one sender. Also, the fact they can successfully send encrypted emails implies their key pair is functional for signing."
            },
            {
                "text": "The internal user's company email servers have an incorrect implementation of OCSP and CRL settings.",
                "correct": false,
                "explain": "Incorrect. If there were a systemic issue with OCSP/CRL on the sender's side, it would likely affect sending encrypted emails to all external recipients, not just one specific person."
            },
            {
                "text": "The external recipient's email address and the email address associated with the external recipient's public key are mismatched.",
                "correct": true,
                "explain": "Correct. To send an encrypted email, the sender's email client must first retrieve the recipient's public key, usually from a public directory or a previously signed email. If the email address the user is trying to send to ('user@example.com') does not match the email address contained within the public key certificate the client finds, the client will generate a security error and refuse to encrypt the message. This explains why the issue is specific to one recipient and only affects outbound encrypted mail to them."
            }
        ]
    },
    {
        "id": 22,
        "q": "A security administrator is setting up a virtualization solution that needs to run services from a single host. Each service should be the only one running in its environment. Each environment needs to have its own operating system as a base but share the kernel version and properties of the running host. Which of the following technologies would best meet these requirements?",
        "type": "single",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "Containers",
                "correct": true,
                "explain": "Correct. Containers meet all the requirements. They isolate individual services, have their own OS libraries and binaries, but share the kernel of the host operating system. [cite_start]This makes them lightweight and efficient for running single services in isolated environments. [cite: 332]"
            },
            {
                "text": "Type 1 hypervisor",
                "correct": false,
                "explain": "Incorrect. A Type 1 hypervisor runs directly on the hardware and hosts full virtual machines, each with its own complete guest OS and kernel. This does not meet the requirement of sharing the host's kernel."
            },
            {
                "text": "Type 2 hypervisor",
                "correct": false,
                "explain": "Incorrect. A Type 2 hypervisor runs on top of a conventional host OS and hosts full virtual machines, each with its own complete guest OS and kernel. This does not meet the requirement of sharing the host's kernel."
            },
            {
                "text": "Virtual desktop infrastructure",
                "correct": false,
                "explain": "Incorrect. Virtual Desktop Infrastructure (VDI) is a specific use case of virtualization for providing desktop environments to users, not for running isolated backend services."
            },
            {
                "text": "Emulation",
                "correct": false,
                "explain": "Incorrect. Emulation is a technique to run software designed for one hardware architecture on a completely different one. It is not the same as OS-level virtualization (containers)."
            }
        ]
    },
    {
        "id": 23,
        "q": "A company has data it would like to aggregate from its PLCs for data visualization and predictive maintenance purposes. Which of the following is the most likely destination for the tag data from the PLCs?",
        "type": "single",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "External drive",
                "correct": false,
                "explain": "Incorrect. An external drive is a simple storage device and lacks the necessary software and database capabilities to aggregate and process time-series data for visualization and analysis."
            },
            {
                "text": "Cloud storage",
                "correct": false,
                "explain": "Incorrect. While the data might eventually end up in the cloud, 'cloud storage' is too generic. The immediate destination in an industrial control system (ICS) environment for this type of data is a specialized server."
            },
            {
                "text": "System aggregator",
                "correct": false,
                "explain": "Incorrect. A system aggregator is a general term. [cite_start]A local historian is the specific and correct term for the system that collects data from PLCs and SCADA systems. [cite: 501]"
            },
            {
                "text": "Local historian",
                "correct": true,
                "explain": "Correct. In Operational Technology (OT) and Industrial Control System (ICS) environments, a historian is a centralized database server used for collecting and storing large amounts of time-series process data from devices like Programmable Logic Controllers (PLCs) and SCADA systems. This data is then used for purposes like data visualization and predictive maintenance."
            }
        ]
    },
    {
        "id": 24,
        "q": "Which of the following is the best way to protect the website Browse history for an executive who travels to foreign countries where internet usage is closely monitored?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "DoH",
                "correct": true,
                "explain": "Correct. DNS over HTTPS (DoH) encrypts Domain Name System (DNS) queries and sends them over port 443 as standard HTTPS traffic. This prevents local network monitors (like an ISP in a foreign country) from seeing which websites a user is attempting to resolve and visit, thus protecting the Browse history from this specific type of monitoring. While a VPN is a more comprehensive solution, of the choices given, DoH is the best fit."
            },
            {
                "text": "EAP-TLS",
                "correct": false,
                "explain": "Incorrect. Extensible Authentication Protocol-Transport Layer Security (EAP-TLS) is a strong authentication method used for connecting to networks (like Wi-Fi or VPNs), often with certificates. [cite_start]It secures the connection authentication but does not hide the subsequent Browse history from network monitors. [cite: 411]"
            },
            {
                "text": "Geofencing",
                "correct": false,
                "explain": "Incorrect. Geofencing restricts access to services based on a user's geographical location. It is a control used by a service provider, not a protection used by the traveling executive."
            },
            {
                "text": "Private Browse mode",
                "correct": false,
                "explain": "Incorrect. Private Browse mode (or incognito mode) only prevents the user's local browser from saving their Browse history, cookies, and site data. It does absolutely nothing to hide their activity from network administrators, ISPs, or websites they visit."
            }
        ]
    },
    {
        "id": 25,
        "q": "A systems administrator is working with the SOC to identify potential intrusions associated with ransomware. The SOC wants the systems administrator to perform network-level analysis to identify outbound traffic from any infected machines. Which of the following is the most appropriate action for the systems administrator to take?",
        "type": "single",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "Monitor for IoCs associated with C&C communications.",
                "correct": true,
                "explain": "Correct. Ransomware, like most malware, often communicates with a Command and Control (C2 or C&C) server to receive instructions, send status updates, or exfiltrate data. [cite_start]Monitoring outbound network traffic for Indicators of Compromise (IoCs) such as known malicious IP addresses, domain names, or unusual traffic patterns associated with C2 channels is a primary method for detecting infected machines. [cite: 723]"
            },
            {
                "text": "Tune alerts to Identify changes to administrative groups.",
                "correct": false,
                "explain": "Incorrect. This is a host-level or directory-level analysis, not a network-level analysis of outbound traffic."
            },
            {
                "text": "Review NetFlow logs for unexpected increases in egress traffic.",
                "correct": false,
                "explain": "Incorrect. While a large increase in egress traffic could be a sign of data exfiltration, C2 communication is often low-and-slow to avoid detection. Focusing on specific IoCs is a more targeted and effective approach than just looking at volume."
            },
            {
                "text": "Perform binary hash comparisons to identify infected devices.",
                "correct": false,
                "explain": "Incorrect. This is a host-level analysis technique used to identify malware files on a system, not a network-level analysis of outbound traffic."
            }
        ]
    },
    {
        "id": 26,
        "q": "A retail organization wants to properly test and verify its capabilities to detect and/or prevent specific TTPs as mapped to the MITRE ATT&CK framework specific to APTs. Which of the following should be used by the organization to accomplish this goal?",
        "type": "single",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "Tabletop exercise",
                "correct": false,
                "explain": "Incorrect. A tabletop exercise is a discussion-based session where team members walk through a simulated scenario. [cite_start]It tests processes and communication but does not technically test or verify detection and prevention controls. [cite: 755]"
            },
            {
                "text": "Penetration test",
                "correct": false,
                "explain": "Incorrect. A penetration test typically has a specific objective, like gaining access to a certain system, and may not cover the broad range of specific TTPs the organization wants to test against."
            },
            {
                "text": "Sandbox detonation",
                "correct": false,
                "explain": "Incorrect. Sandbox detonation is a technique for analyzing a single piece of malware in an isolated environment. [cite_start]It does not test the organization's broader detection and prevention capabilities against a range of TTPs. [cite: 735]"
            },
            {
                "text": "Adversary emulation",
                "correct": true,
                "explain": "Correct. Adversary emulation is a type of security assessment where the testing team mimics the specific Tactics, Techniques, and Procedures (TTPs) of known threat actors, such as Advanced Persistent Threats (APTs). [cite_start]This approach directly maps to the MITRE ATT&CK framework and is the perfect way to test and verify an organization's defenses against real-world attack methodologies. [cite: 710]"
            }
        ]
    },
    {
        "id": 27,
        "q": "IoCs were missed during a recent security incident due to the reliance on a signature-based detection platform. A security engineer must recommend a solution that can be implemented to address this shortcoming. Which of the following would be the most appropriate recommendation?",
        "type": "single",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "FIM",
                "correct": false,
                "explain": "Incorrect. File Integrity Monitoring (FIM) is a specific control that detects changes to critical files but does not provide broad, behavior-based detection to compensate for the failure of signature-based systems."
            },
            {
                "text": "SASE",
                "correct": false,
                "explain": "Incorrect. Secure Access Service Edge (SASE) is a network architecture model that combines security and networking functions in the cloud. [cite_start]It does not inherently provide advanced, non-signature-based threat detection on its own. [cite: 367]"
            },
            {
                "text": "UEBA",
                "correct": true,
                "explain": "Correct. Signature-based platforms fail when they encounter unknown threats (zero-days) or novel malware. User and Entity Behavior Analytics (UEBA) addresses this gap by creating a baseline of normal activity for users and systems and then looking for anomalous behavior. [cite_start]This allows it to detect threats that don't have a known signature, which is exactly the shortcoming that needs to be addressed. [cite: 715]"
            },
            {
                "text": "CSPM",
                "correct": false,
                "explain": "Incorrect. Cloud Security Posture Management (CSPM) tools are used to detect misconfigurations in cloud environments. [cite_start]They do not analyze user or system behavior to detect active threats. [cite: 649]"
            },
            {
                "text": "EAP",
                "correct": false,
                "explain": "Incorrect. [cite_start]Extensible Authentication Protocol (EAP) is an authentication framework and is not a threat detection solution. [cite: 411]"
            }
        ]
    },
    {
        "id": 28,
        "q": "A company that provides services to clients who work with highly sensitive data would like to provide assurance that the data's confidentiality is maintained in a dynamic, low-risk environment. Which of the following would best achieve this goal? (Choose two.)",
        "type": "multiple",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Install a SOAR on all endpoints.",
                "correct": false,
                "explain": "Incorrect. SOAR (Security Orchestration, Automation, and Response) is a platform for automating incident response workflows, not a direct control for ensuring data confidentiality."
            },
            {
                "text": "Hash all files.",
                "correct": false,
                "explain": "Incorrect. Hashing provides data integrity (ensuring data hasn't been changed), but it does not provide confidentiality. [cite_start]Hashing is a one-way process and the original data cannot be recovered. [cite: 613]"
            },
            {
                "text": "Install SIEM within a SOC.",
                "correct": false,
                "explain": "Incorrect. A SIEM (Security Information and Event Management) system is a monitoring and alerting tool. While it can detect unauthorized access attempts, it does not inherently protect the confidentiality of the data itself."
            },
            {
                "text": "Encrypt all data and files at rest, in transit, and in use.",
                "correct": true,
                "explain": "Correct. Encryption is the fundamental control for ensuring confidentiality. [cite_start]Protecting data across all its statesat rest (on disk), in transit (over the network), and in use (while being processed)provides comprehensive assurance that the data cannot be read by unauthorized parties. [cite: 589, 590, 592]"
            },
            {
                "text": "Configure SOAR to monitor and intercept files and data leaving the network.",
                "correct": false,
                "explain": "Incorrect. While a SOAR could potentially be integrated with a DLP solution to take action, this is an overly specific and complex description. The core technologies are encryption and DLP, not SOAR."
            },
            {
                "text": "Implement file integrity monitoring.",
                "correct": true,
                "explain": "Correct. While encryption provides the core confidentiality, file integrity monitoring (FIM) provides a critical supporting role. It provides assurance that the sensitive data has not been accessed or modified without authorization, which is a key part of maintaining confidentiality in a low-risk environment."
            }
        ]
    },
    {
        "id": 29,
        "q": "An organization wants to implement an access control system based on its data classification policy that includes the following data types: Confidential, Restricted, Internal, Public, Flag for Review. The access control system should support SSO federation to map users into groups. Each group should only access systems that process and store data at the classification assigned to the group. Which of the following should the organization implement to enforce its requirements with a minimal impact to systems and resources?",
        "type": "single",
        "category": "2.3 Given a scenario, integrate appropriate controls in the design of a secure architecture.",
        "answers": [
            {
                "text": "A tagging strategy in which all resources are assigned a tag based on the data classification type, and a system that enforces attribute-based access control",
                "correct": true,
                "explain": "Correct. This solution directly addresses all requirements. [cite_start]Using a tagging strategy applies the data classification labels (Confidential, Restricted, etc.) to the resources (e.g., servers, databases). [cite: 278] [cite_start]An Attribute-Based Access Control (ABAC) system can then create policies that grant access based on these tags and user attributes (like group membership from SSO), providing a highly flexible and scalable solution with minimal impact, as policies are evaluated dynamically. [cite: 301]"
            },
            {
                "text": "Role-based access control that maps data types to internal roles, which are defined in the human resources department's source of truth system",
                "correct": false,
                "explain": "Incorrect. While Role-Based Access Control (RBAC) is common, it can become very complex and rigid when dealing with multiple data classifications. It often leads to 'role explosion' and is less flexible than ABAC for this use case."
            },
            {
                "text": "Network microsegmentation based on data types, and a network access control system enforcing mandatory access control based on the user principal",
                "correct": false,
                "explain": "Incorrect. Microsegmentation and Mandatory Access Control (MAC) are powerful but complex and high-impact controls to implement. [cite_start]They are not typically the first choice for enforcing data classification access with minimal impact, and MAC is very rigid. [cite: 303, 356]"
            },
            {
                "text": "A rule-based access control strategy enforced by the SSO system with rules managed by the internal LDAP and applied on a per-system basis",
                "correct": false,
                "explain": "Incorrect. Rule-Based Access Control that is applied on a per-system basis would be difficult to manage at scale and would have a high impact on resources, contradicting the requirements."
            }
        ]
    },
    {
        "id": 30,
        "q": "A security analyst was monitoring the networks of a group of companies. The analyst identified several periods of concentrated, coordinated activity by unknown actors. The activity repeated at regular intervals and affected all the companies. Minor hardware outages that correlated with the same times as the discovered activity escalated in severity. Which of the following threat actors was most likely involved?",
        "type": "single",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "An organized crime collective running a ransomware campaign",
                "correct": false,
                "explain": "Incorrect. While organized crime is a possibility, their motivation is typically financial, and ransomware attacks are usually noisy and aimed at extortion, which doesn't fully align with the escalating hardware outages and repeated, regular intervals."
            },
            {
                "text": "A group of politically motivated hackers",
                "correct": false,
                "explain": "Incorrect. [cite_start]Activism or hacktivism usually involves defacement or denial of service for public attention, which doesn't fit the pattern of subtle, repeated, and escalating hardware-level attacks. [cite: 143]"
            },
            {
                "text": "Disgruntled employees who were recently terminated",
                "correct": false,
                "explain": "Incorrect. Insider threats are possible, but it is unlikely that a group of terminated employees would have the coordination and resources to conduct a long-term, escalating campaign against multiple companies."
            },
            {
                "text": "An advanced persistent threat financed by a nation-state",
                "correct": true,
                "explain": "Correct. The characteristics describedcoordinated, repeated at regular intervals, affecting multiple related companies, escalating in severity, and causing hardware outagesare all hallmarks of an Advanced Persistent Threat (APT). [cite_start]APTs are typically well-funded (often by a nation-state), patient, and have specific long-term objectives, such as espionage or sabotage, that align with this attack pattern. [cite: 142, 145, 146]"
            }
        ]
    },
    {
        "id": 31,
        "q": "The company's client service team is receiving a large number of inquiries from clients regarding a new vulnerability. Which of the following would provide the customer service team with a consistent message to deliver directly to clients?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "Communication plan",
                "correct": true,
                "explain": "Correct. A communication plan is a strategic document that outlines how, when, and what information will be communicated to various stakeholders (including customers, employees, and the public) during an incident or event. [cite_start]It would contain pre-approved messaging to ensure consistency and accuracy, which is exactly what the client service team needs. [cite: 61]"
            },
            {
                "text": "Response playbook",
                "correct": false,
                "explain": "Incorrect. A response playbook contains the specific technical and procedural steps for the incident response team to follow to contain and remediate an incident. It is for internal technical use, not for customer communication."
            },
            {
                "text": "Disaster recovery procedure",
                "correct": false,
                "explain": "Incorrect. A disaster recovery procedure is focused on restoring IT services after a major outage or disaster, not on communicating with clients about a vulnerability."
            },
            {
                "text": "Automated runbook",
                "correct": false,
                "explain": "Incorrect. A runbook is a set of automated procedures, often used in a SOAR platform, to execute technical response actions. [cite_start]It does not provide messaging for customer service teams. [cite: 555]"
            }
        ]
    },
    {
        "id": 32,
        "q": "A company wants to use a process to embed a sign of ownership covertly inside a proprietary document without adding any identifying attributes. Which of the following would be best to use as part of the process to support copyright protections of the document?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Steganography",
                "correct": true,
                "explain": "Correct. Steganography is the practice of concealing a message, image, or file within another message, image, or file. This perfectly matches the requirement to 'covertly' embed a sign of ownership without visible identifying attributes. It's a method of hiding data in plain sight."
            },
            {
                "text": "E-signature",
                "correct": false,
                "explain": "Incorrect. An electronic signature is a visible mark on a document used to indicate intent to sign. It is not covert. [cite_start]A digital signature is a cryptographic mechanism that is also not covert. [cite: 610]"
            },
            {
                "text": "Watermarking",
                "correct": false,
                "explain": "Incorrect. Watermarking typically refers to a visible or semi-visible mark placed on a document or image to identify its owner. The requirement here specifies a 'covert' process."
            },
            {
                "text": "Cryptography",
                "correct": false,
                "explain": "Incorrect. Cryptography is the practice of securing communication by encrypting it, making it unreadable to outsiders. It is used to protect content, not to covertly embed ownership information."
            }
        ]
    },
    {
        "id": 33,
        "q": "Which of the following utilizes policies that route packets to ensure only specific types of traffic are being sent to the correct destination based on application usage?",
        "type": "single",
        "category": "2.6 Given a scenario, integrate Zero Trust concepts into system architecture design.",
        "answers": [
            {
                "text": "SDN",
                "correct": true,
                "explain": "Correct. Software-Defined Networking (SDN) separates the network's control plane (which decides where traffic goes) from the data plane (which forwards the traffic). This allows for centralized, programmable control over the network. [cite_start]An administrator can define policies in the central controller to route traffic based on application type, user identity, or other criteria, which perfectly matches the description. [cite: 370]"
            },
            {
                "text": "pcap",
                "correct": false,
                "explain": "Incorrect. pcap (packet capture) is a file format and an API for capturing network traffic for analysis. It does not route or control traffic."
            },
            {
                "text": "vmstat",
                "correct": false,
                "explain": "Incorrect. vmstat is a command-line tool used to report virtual memory statistics on a Linux system. It has nothing to do with network routing."
            },
            {
                "text": "DNSSEC",
                "correct": false,
                "explain": "Incorrect. DNS Security Extensions (DNSSEC) is a suite of specifications for securing DNS by providing origin authentication and data integrity. [cite_start]It does not route application traffic. [cite: 454]"
            },
            {
                "text": "VPC",
                "correct": false,
                "explain": "Incorrect. A Virtual Private Cloud (VPC) is an isolated section of a public cloud. While it contains routing rules, SDN is the underlying technology that provides the policy-based, application-aware routing described."
            }
        ]
    },
    {
        "id": 34,
        "q": "An incident response team completed recovery from offline backup for several workstations. The workstations were subjected to a ransomware attack after users fell victim to a spear-phishing campaign, despite a robust training program. Which of the following questions should be considered during the lessons-learned phase to most likely reduce the risk of reoccurrence? (Choose two.)",
        "type": "multiple",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Are there opportunities for legal recourse against the originators of the spear-phishing campaign?",
                "correct": false,
                "explain": "Incorrect. While potentially a topic for legal or executive teams, this does not focus on improving internal security controls to prevent reoccurrence, which is the primary goal of a lessons-learned phase."
            },
            {
                "text": "What internal and external stakeholders need to be notified of the breach?",
                "correct": false,
                "explain": "Incorrect. This question should be addressed during the initial stages of incident response (identification and communication), not as a primary focus of the post-incident lessons-learned phase aimed at preventing reoccurrence."
            },
            {
                "text": "Which methods can be implemented to increase speed of offline backup recovery?",
                "correct": false,
                "explain": "Incorrect. While improving recovery speed is a valid consideration for business continuity, the core issue is that the initial compromise occurred. The focus should be on preventing the compromise in the first place."
            },
            {
                "text": "What measurable user behaviors were exhibited that contributed to the compromise?",
                "correct": true,
                "explain": "Correct. The incident happened despite a training program. Understanding the specific behaviors that led to failure (e.g., clicking links, opening attachments, ignoring warnings) is critical for improving the effectiveness of future training and identifying where it fell short."
            },
            {
                "text": "Which technical controls, if implemented, would provide defense when user training fails?",
                "correct": true,
                "explain": "Correct. The scenario explicitly states that the user-focused control (training) failed. The principle of defense-in-depth dictates that there should be technical controls to backstop human error. Asking this question directly addresses how to prevent reoccurrence by strengthening the technical security posture (e.g., better email filtering, endpoint protection, or browser isolation)."
            },
            {
                "text": "Which user roles are most often targeted by spear phishing attacks?",
                "correct": false,
                "explain": "Incorrect. While identifying targeted roles is useful, the two chosen answers are more direct in addressing the failure of existing controls and identifying specific improvements needed to prevent reoccurrence."
            }
        ]
    },
    {
        "id": 35,
        "q": "Two companies that recently merged would like to unify application access between the companies, without initially merging internal authentication stores. Which of the following technical strategies would best meet this objective?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Federation",
                "correct": true,
                "explain": "Correct. Identity federation is a system where two or more separate identity management systems (like the ones at the two merged companies) establish a trust relationship. This allows a user authenticated in one domain to access resources in the other, without needing to merge the underlying user databases (authentication stores). [cite_start]This perfectly matches the requirement. [cite: 294, 416]"
            },
            {
                "text": "RADIUS",
                "correct": false,
                "explain": "Incorrect. RADIUS is a networking protocol for centralized Authentication, Authorization, and Accounting (AAA) management for users who connect and use a network service. It is not designed for unifying application access across different corporate identity stores."
            },
            {
                "text": "TACACS+",
                "correct": false,
                "explain": "Incorrect. TACACS+ is another AAA protocol, primarily used for device administration (e.g., managing routers and switches). It is not the appropriate technology for federated application access."
            },
            {
                "text": "MFA",
                "correct": false,
                "explain": "Incorrect. Multifactor Authentication (MFA) is a method of verifying a user's identity by requiring multiple credentials. [cite_start]It can be part of a federated system but is not the strategy for connecting the two identity stores. [cite: 403]"
            },
            {
                "text": "ABAC",
                "correct": false,
                "explain": "Incorrect. Attribute-Based Access Control (ABAC) is an authorization model that grants access based on policies and attributes. [cite_start]It is an authorization strategy, not the mechanism for connecting two separate authentication stores. [cite: 301]"
            }
        ]
    },
    {
        "id": 36,
        "q": "An analyst needs to evaluate all images and documents that are publicly shared on a website. Which of the following would be the best tool to evaluate the metadata of these files?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "OllyDbg",
                "correct": false,
                "explain": "Incorrect. OllyDbg is a debugger used for reverse engineering and analyzing binary executable files, not for extracting metadata from images and documents."
            },
            {
                "text": "ExifTool",
                "correct": true,
                "explain": "Correct. ExifTool is a powerful, platform-independent command-line application specifically designed for reading, writing, and editing meta information (metadata) in a wide variety of file types, including images (EXIF, GPS), documents (PDF), and audio/video files. [cite_start]It is the perfect tool for this task. [cite: 738]"
            },
            {
                "text": "Volatility",
                "correct": false,
                "explain": "Incorrect. The Volatility Framework is a tool for incident response and malware analysis, specifically for analyzing volatile memory (RAM) dumps. [cite_start]It does not analyze file metadata. [cite: 749]"
            },
            {
                "text": "Ghidra",
                "correct": false,
                "explain": "Incorrect. Ghidra is a software reverse engineering (SRE) framework developed by the NSA. It is used for analyzing compiled code (malware, firmware), not for extracting metadata from standard image and document files."
            }
        ]
    },
    {
        "id": 37,
        "q": "An organization has deployed a cloud-based application that provides virtual event services globally to clients. During a typical event, thousands of users access various entry pages within a short period of time. The entry pages include sponsor-related content that is relatively static and is pulled from a database. When the first major event occurs, users report poor response time on the entry pages. Which of the following features is the most appropriate for the company to implement?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "Horizontal scalability",
                "correct": false,
                "explain": "Incorrect. While horizontal scaling (adding more servers) can handle increased load, it does not address the core inefficiency of repeatedly pulling static content from a database for every user. Caching is a more direct and efficient solution for this specific problem."
            },
            {
                "text": "Vertical scalability",
                "correct": false,
                "explain": "Incorrect. Vertical scaling (making servers more powerful) would also help with load but is often more expensive and less efficient than caching for handling requests for static content."
            },
            {
                "text": "Containerization",
                "correct": false,
                "explain": "Incorrect. Containerization is a deployment technology. While beneficial, it does not by itself solve the performance problem of serving static content from a database at scale."
            },
            {
                "text": "Static code analysis",
                "correct": false,
                "explain": "Incorrect. Static code analysis is a testing technique to find vulnerabilities in source code before it is run. It is not a runtime performance-enhancing feature."
            },
            {
                "text": "Caching",
                "correct": true,
                "explain": "Correct. The scenario describes a classic use case for caching. The sponsor content is static and repeatedly requested by thousands of users. A caching layer, such as a Content Delivery Network (CDN), can store a copy of this static content closer to the users. [cite_start]This means the application does not have to query the database for every single request, drastically reducing the load on the database and improving response times for users. [cite: 232]"
            }
        ]
    },
    {
        "id": 38,
        "q": "An organization's board of directors has asked the Chief Information Security Officer to build a third-party management program. Which of the following best explains a reason for this request?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Risk transference",
                "correct": false,
                "explain": "Incorrect. Risk transference, such as buying cybersecurity insurance, is a strategy to shift the financial impact of a risk. A third-party management program is about managing the operational and security risks introduced by vendors, not just transferring financial liability."
            },
            {
                "text": "Supply chain visibility",
                "correct": true,
                "explain": "Correct. A third-party management program is essential for gaining visibility into the security posture and risks associated with the organization's supply chain (vendors, suppliers, service providers). [cite_start]Attacks targeting third parties are a common vector for compromising a primary organization, so understanding and managing these dependencies is a critical governance function. [cite: 91, 92]"
            },
            {
                "text": "Support availability",
                "correct": false,
                "explain": "Incorrect. While ensuring support availability from vendors is part of a third-party relationship, it's a small component of the overall risk management program, which also covers security, compliance, and operational risks."
            },
            {
                "text": "Vulnerability management",
                "correct": false,
                "explain": "Incorrect. Vulnerability management is a process for handling vulnerabilities within an organization's own systems. A third-party risk management program is concerned with the risks introduced by external entities."
            }
        ]
    },
    {
        "id": 39,
        "q": "A company is rewriting a vulnerable application and adding the mprotect() system call in multiple parts of the application's code that was being leveraged by a recent exploitation tool. Which of the following should be enabled to ensure the application can leverage the new system call against similar attacks in the future?",
        "type": "single",
        "category": "3.4 Given a scenario, implement hardware security technologies and techniques.",
        "answers": [
            {
                "text": "TPM",
                "correct": false,
                "explain": "Incorrect. A Trusted Platform Module (TPM) is a hardware chip used for secure cryptographic operations and platform integrity measurements. [cite_start]It does not directly enable or enforce memory protection policies like the NX bit does. [cite: 477]"
            },
            {
                "text": "Secure boot",
                "correct": false,
                "explain": "Incorrect. Secure Boot is a UEFI feature that ensures only signed, trusted code is loaded during the boot process. [cite_start]It protects against bootkits and rootkits but does not enforce runtime memory protection. [cite: 486]"
            },
            {
                "text": "NX bit",
                "correct": true,
                "explain": "Correct. The `mprotect()` system call is used to change memory protection on a region of memory, such as marking a memory segment as non-executable. This is a key defense against buffer overflow attacks, where an attacker injects malicious code into a data segment (like the stack or heap) and tries to execute it. The No-Execute (NX) bit, also known as Execute Disable (XD) bit, is a hardware feature in CPUs that allows the operating system to mark certain areas of memory as non-executable. [cite_start]For `mprotect()` to be effective in preventing code injection attacks, the underlying hardware must support the NX bit. [cite: 480, 481]"
            },
            {
                "text": "HSM",
                "correct": false,
                "explain": "Incorrect. A Hardware Security Module (HSM) is an external device used for managing and protecting cryptographic keys. [cite_start]It has no role in enforcing memory protection within an application. [cite: 477]"
            }
        ]
    },
    {
        "id": 40,
        "q": "Which of the following items should be included when crafting a disaster recovery plan?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Redundancy",
                "correct": false,
                "explain": "Incorrect. Redundancy is a component of a high-availability design, which can prevent a disaster. However, a disaster recovery (DR) plan is what you execute when redundancy and other preventative measures have already failed."
            },
            {
                "text": "Testing exercises",
                "correct": true,
                "explain": "Correct. A disaster recovery plan is useless if it is not tested. [cite_start]A critical part of crafting and maintaining a DR plan is defining and scheduling regular testing exercises (e.g., tabletop, walk-through, full-interruption tests) to validate the plan's effectiveness and ensure personnel are familiar with their roles. [cite: 97, 103]"
            },
            {
                "text": "Autoscaling",
                "correct": false,
                "explain": "Incorrect. Autoscaling is a cloud feature for handling variable loads and is part of a resilient system design, not a core component of a DR plan itself."
            },
            {
                "text": "Competitor locations",
                "correct": false,
                "explain": "Incorrect. The location of competitors is irrelevant to an organization's own disaster recovery planning."
            }
        ]
    },
    {
        "id": 41,
        "q": "A web application server is running a legacy operating system with an unpatched RCE vulnerability. The server cannot be upgraded until the corresponding application code is changed. Which of the following compensating controls would best prevent successful exploitation?",
        "type": "single",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "Segmentation",
                "correct": false,
                "explain": "Incorrect. [cite_start]While segmenting the server from the rest of the network is a good practice to limit the blast radius if it's compromised, it does not prevent the initial exploitation of the RCE vulnerability itself. [cite: 515]"
            },
            {
                "text": "CASB",
                "correct": false,
                "explain": "Incorrect. A Cloud Access Security Broker (CASB) is used to enforce security policies for cloud-based applications and services. [cite_start]It is not the appropriate control for protecting an on-premises web server. [cite: 317]"
            },
            {
                "text": "HIPS",
                "correct": true,
                "explain": "Correct. A Host-based Intrusion Prevention System (HIPS) runs on the server itself and can monitor for and block suspicious activities that are characteristic of an exploit attempt, such as unexpected process creation, system call abuse, or buffer overflows. [cite_start]Since the server cannot be patched, a HIPS can provide a 'virtual patch' by blocking the exploitation of the known RCE vulnerability at the host level, making it the best compensating control in this scenario. [cite: 424]"
            },
            {
                "text": "UEBA",
                "correct": false,
                "explain": "Incorrect. User and Entity Behavior Analytics (UEBA) is a detective control that identifies anomalous activity over time. [cite_start]It is not a preventative control that can block the exploitation of an RCE vulnerability in real time. [cite: 715]"
            }
        ]
    },
    {
        "id": 42,
        "q": "Which of the following is the reason why security engineers often cannot upgrade the security of embedded facility automation systems?",
        "type": "single",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "They are constrained by available compute.",
                "correct": true,
                "explain": "Correct. Many embedded systems, especially older ones found in facility automation (HVAC, ICS, etc.), are highly constrained systems. They were designed with minimal CPU, memory, and storage resources, just enough to perform their specific function. [cite_start]This lack of available compute resources means they often cannot support modern security features like robust encryption, logging agents, or updated operating systems, which require more processing power and memory. [cite: 529]"
            },
            {
                "text": "They lack x86-64 processors.",
                "correct": false,
                "explain": "Incorrect. While many may not use x86-64 processors (using ARM or other architectures instead), the choice of processor architecture itself is not the primary barrier to security upgrades. The constraint is the lack of resources, regardless of architecture."
            },
            {
                "text": "They lack EEPROM.",
                "correct": false,
                "explain": "Incorrect. EEPROM (Electrically Erasable Programmable Read-Only Memory) is a type of non-volatile memory. Embedded systems do have firmware storage; the problem is the inability to safely update it or add new features due to resource constraints."
            },
            {
                "text": "They are not logic-bearing devices.",
                "correct": false,
                "explain": "Incorrect. Facility automation systems are by definition logic-bearing devices (e.g., Programmable Logic Controllers - PLCs). They execute logic to control physical processes."
            }
        ]
    },
    {
        "id": 43,
        "q": "A security analyst identified a vulnerable and deprecated runtime engine that Is supporting a public-facing banking application. The developers anticipate the transition to modern development environments will take at least a month. Which of the following controls would best mitigate the risk without interrupting the service during the transition?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "Shutting down the systems until the code is ready",
                "correct": false,
                "explain": "Incorrect. This would interrupt the service, which violates one of the core requirements of the scenario."
            },
            {
                "text": "Uninstalling the impacted runtime engine",
                "correct": false,
                "explain": "Incorrect. The application depends on this runtime engine to function. Uninstalling it would interrupt the service."
            },
            {
                "text": "Selectively blocking traffic on the affected port",
                "correct": false,
                "explain": "Incorrect. Blocking traffic to the application's port would make the service unavailable, violating the requirement not to interrupt service."
            },
            {
                "text": "Configuring IPS and WAF with signatures",
                "correct": true,
                "explain": "Correct. This is a classic use case for 'virtual patching.' Since the underlying runtime cannot be fixed immediately, placing a Web Application Firewall (WAF) and an Intrusion Prevention System (IPS) in front of the application is the best compensating control. [cite_start]These systems can be configured with specific signatures to detect and block attempts to exploit the known vulnerabilities in the deprecated runtime, thereby mitigating the risk without taking the application offline. [cite: 223, 226]"
            }
        ]
    },
    {
        "id": 44,
        "q": "A security architect wants to ensure a remote host's identity and decides that pinning the X.509 certificate to the device is the most effective solution. Which of the following must happen first?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Use Distinguished Encoding Rules (DER) for the certificate.",
                "correct": false,
                "explain": "Incorrect. The encoding of the certificate (DER vs. PEM) is a formatting detail and not the first conceptual step in the process of certificate pinning."
            },
            {
                "text": "Extract the private key from the certificate.",
                "correct": false,
                "explain": "Incorrect. Certificate pinning involves the public certificate, not the server's private key. The client never has access to the server's private key."
            },
            {
                "text": "Use an out-of-band method to obtain the certificate.",
                "correct": true,
                "explain": "Correct. Certificate pinning is the process where a client application embeds or 'pins' a copy of the server's expected public key or certificate. To do this securely, the application developer must first obtain a known-good, trusted copy of the server's certificate through a secure, out-of-band channel (i.e., not over the same network that might be subject to an on-path attack). This trusted copy is then built into the application."
            },
            {
                "text": "Compare the retrieved certificate with the embedded certificate.",
                "correct": false,
                "explain": "Incorrect. This comparison is the final step of the process that happens at runtime when the client connects to the server. The first step is to obtain the certificate to embed in the first place."
            }
        ]
    },
    {
        "id": 45,
        "q": "A company hired a third-party consultant to run a cybersecurity incident simulation in order to identify security gaps and prepare stakeholders for a potential incident. Which of the following best describes this activity?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Tabletop exercise",
                "correct": true,
                "explain": "Correct. A tabletop exercise is a discussion-based activity where stakeholders and response team members gather to walk through a simulated incident scenario. The goal is to test the existing incident response plan, identify gaps in processes and communication, and prepare personnel without affecting live production systems. [cite_start]This perfectly describes the activity. [cite: 97, 103, 755]"
            },
            {
                "text": "Walk-through review",
                "correct": false,
                "explain": "Incorrect. A walk-through review is a more general term that could apply to many processes. 'Tabletop exercise' is the specific industry term for an incident simulation."
            },
            {
                "text": "Lessons learned",
                "correct": false,
                "explain": "Incorrect. A lessons-learned session is conducted *after* a real incident or an exercise to review what went well and what didn't. The activity described is the exercise itself, not the post-mortem."
            },
            {
                "text": "Business impact analysis",
                "correct": false,
                "explain": "Incorrect. A Business Impact Analysis (BIA) is a formal process to determine the potential effects of an interruption to critical business operations. [cite_start]It is a planning activity, not an incident simulation. [cite: 85]"
            }
        ]
    },
    {
        "id": 46,
        "q": "A security officer is requiring all personnel working on a special project to obtain a security clearance requisite with the level of all information being accessed. Data on this network must be protected at the same level of each clearance holder. The need to know must be verified by the data owner. Which of the following should the security officer do to meet these requirements?",
        "type": "single",
        "category": "2.4 Given a scenario, apply security concepts to the design of access, authentication, and authorization systems.",
        "answers": [
            {
                "text": "Create a rule to authorize personnel only from certain IPs to access the files.",
                "correct": false,
                "explain": "Incorrect. This describes a component of rule-based or attribute-based access control, but it doesn't encompass the full set of requirements involving security clearances and labels."
            },
            {
                "text": "Assign labels to the files and require formal access authorization.",
                "correct": true,
                "explain": "Correct. This scenario describes Mandatory Access Control (MAC). In a MAC model, all resources (files) and subjects (users) are assigned security labels (e.g., clearance levels like Top Secret, Secret, Confidential). The system then enforces a strict policy that a subject can only access an object if their security label dominates the object's label. [cite_start]The concepts of 'security clearance' and data protection levels are the defining characteristics of MAC. [cite: 303]"
            },
            {
                "text": "Assign attributes to each file and allow authorized users to share the files.",
                "correct": false,
                "explain": "Incorrect. This is closer to Attribute-Based Access Control (ABAC), but the language of security clearances points specifically to the more rigid MAC model."
            },
            {
                "text": "Assign roles to users and authorize access to files based on the roles.",
                "correct": false,
                "explain": "Incorrect. This describes Role-Based Access Control (RBAC). [cite_start]RBAC is based on job function, not on a formal system of security clearances and data labels. [cite: 301]"
            }
        ]
    },
    {
        "id": 47,
        "q": "A security team receives alerts regarding impossible travel and possible brute-force attacks after normal business hours. After reviewing more logs, the team determines that specific users were targeted and attempts were made to transfer data to an unknown site. Which of the following should the team do to help mitigate these issues?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Create a firewall rule to prevent those users from accessing sensitive data.",
                "correct": false,
                "explain": "Incorrect. Blocking the legitimate users from their data is not the correct solution; the goal is to block the attacker who is using their credentials."
            },
            {
                "text": "Restrict uploading activity to only authorized sites.",
                "correct": false,
                "explain": "Incorrect. While a good idea, this is a broad control. The immediate issue is the compromised accounts and logins from unusual locations and times. Conditional access is a more direct mitigation."
            },
            {
                "text": "Enable packet captures to continue to run for the source and destination related to the file transfer.",
                "correct": false,
                "explain": "Incorrect. Packet capture is for investigation and analysis, not for mitigation. The question asks how to mitigate the issues."
            },
            {
                "text": "Disable login activity for those users after business hours.",
                "correct": true,
                "explain": "Correct. The scenario describes multiple issues (impossible travel, after-hours attacks) that are best mitigated with a conditional access policy. Such a policy can enforce multiple context-based rules, such as blocking logins from untrusted geographic locations (addressing impossible travel) and restricting access to outside of normal business hours. [cite_start]This is a direct and effective mitigation for the observed activity. [cite: 295, 390, 392, 393]"
            }
        ]
    },
    {
        "id": 48,
        "q": "A company recently acquired a SaaS company and performed a gap analysis. The results of the gap analysis Indicate security controls are absent throughout the SDLC and have led to several vulnerable production releases. Which of the following security tools best reduces the risk of vulnerable code being pushed to production in the future?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Static application security testing",
                "correct": true,
                "explain": "Correct. Static Application Security Testing (SAST) tools analyze an application's source code, byte code, or binary code for security vulnerabilities *before* the code is compiled and run. [cite_start]Integrating a SAST tool into the CI/CD pipeline is a foundational 'shift-left' practice that allows developers to find and fix vulnerabilities early in the SDLC, directly reducing the risk of vulnerable code reaching production. [cite: 240]"
            },
            {
                "text": "Regression testing",
                "correct": false,
                "explain": "Incorrect. Regression testing is a type of functional testing that ensures new code changes have not broken existing functionality. [cite_start]It does not specifically look for security vulnerabilities. [cite: 255]"
            },
            {
                "text": "Code signing",
                "correct": false,
                "explain": "Incorrect. Code signing provides integrity and authenticity for released software. It does not find vulnerabilities within the code itself."
            },
            {
                "text": "Sandboxing",
                "correct": false,
                "explain": "Incorrect. Sandboxing is a technique for running untrusted code in a restricted environment to see how it behaves. While useful for malware analysis, it is not the primary tool for finding vulnerabilities in your own code during development."
            }
        ]
    },
    {
        "id": 49,
        "q": "Which of the following is the best reason for obtaining file hashes from a confiscated laptop?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "To prevent metadata tampering on each file",
                "correct": false,
                "explain": "Incorrect. Hashing does not prevent tampering; it only detects it after the fact."
            },
            {
                "text": "To later validate the integrity of each file",
                "correct": true,
                "explain": "Correct. A cryptographic hash function creates a unique, fixed-size digital fingerprint of a file. By calculating the hashes of all files at the time of collection, a forensic investigator creates a baseline. At any later point, the hashes can be recalculated. [cite_start]If a hash has changed, it provides mathematical proof that the file's integrity has been compromised (i.e., the file has been altered). [cite: 108]"
            },
            {
                "text": "To generate unique identifiers for each file",
                "correct": false,
                "explain": "Incorrect. While a hash is a unique identifier, the primary forensic purpose for creating it is not just for identification but specifically for integrity validation."
            },
            {
                "text": "To preserve the chain of custody of files",
                "correct": false,
                "explain": "Incorrect. The chain of custody is the chronological documentation showing the seizure, custody, control, transfer, analysis, and disposition of evidence. Hashing provides integrity validation *within* that chain of custody, but it is not the chain of custody itself."
            }
        ]
    },
    {
        "id": 50,
        "q": "A security analyst is using data provided from a recent penetration test to calculate CVSS scores to prioritize remediation. Which of the following metric groups would the analyst need to determine to get the overall scores? (Choose three.)",
        "type": "multiple",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "Temporal",
                "correct": true,
                "explain": "Correct. The Common Vulnerability Scoring System (CVSS) is composed of three metric groups. [cite_start]The Temporal group reflects the characteristics of a vulnerability that change over time, such as the availability of an exploit or a patch. [cite: 567]"
            },
            {
                "text": "Availability",
                "correct": false,
                "explain": "Incorrect. Availability is one of the three *impact* metrics (along with Confidentiality and Integrity) that are part of the Base score, but it is not one of the three main metric groups."
            },
            {
                "text": "Integrity",
                "correct": false,
                "explain": "Incorrect. Integrity is one of the three *impact* metrics (along with Confidentiality and Availability) that are part of the Base score, but it is not one of the three main metric groups."
            },
            {
                "text": "Confidentiality",
                "correct": false,
                "explain": "Incorrect. Confidentiality is one of the three *impact* metrics (along with Integrity and Availability) that are part of the Base score, but it is not one of the three main metric groups."
            },
            {
                "text": "Base",
                "correct": true,
                "explain": "Correct. The Common Vulnerability Scoring System (CVSS) is composed of three metric groups. [cite_start]The Base group represents the intrinsic qualities of a vulnerability that are constant over time and across user environments. [cite: 567]"
            },
            {
                "text": "Environmental",
                "correct": true,
                "explain": "Correct. The Common Vulnerability Scoring System (CVSS) is composed of three metric groups. [cite_start]The Environmental group represents the characteristics of a vulnerability that are unique to a particular user's environment. [cite: 567]"
            },
            {
                "text": "Impact",
                "correct": false,
                "explain": "Incorrect. The Impact metrics (Confidentiality, Integrity, Availability) are a sub-component of the Base metric group, not one of the three main metric groups."
            },
            {
                "text": "Attack vector",
                "correct": false,
                "explain": "Incorrect. Attack Vector is one of the *exploitability* metrics that is part of the Base score, but it is not one of the three main metric groups."
            }
        ]
    },
    {
        "id": 51,
        "q": "Which of the following describes how a risk assessment is performed when an organization has a critical vendor that provides multiple products?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "At the individual product level",
                "correct": true,
                "explain": "Correct. Risk is not uniform across a vendor's entire portfolio. Different products can have different architectures, security controls, and criticality to the business. Therefore, a proper third-party risk assessment must evaluate the risk associated with each individual product the organization uses. [cite: 91, 93]"
            },
            {
                "text": "Through the selection of a random product",
                "correct": false,
                "explain": "Incorrect. Assessing a random product is not a sound risk management strategy as it could easily miss a high-risk product."
            },
            {
                "text": "Using a third-party audit report",
                "correct": false,
                "explain": "Incorrect. A third-party audit report (like a SOC 2) is a valuable input for an assessment, but it is not the assessment itself. The organization must still analyze the report in the context of the specific products it consumes."
            },
            {
                "text": "By choosing a major product",
                "correct": false,
                "explain": "Incorrect. While assessing the major product is important, this approach ignores potential risks associated with other, less prominent products from the same vendor."
            }
        ]
    },
    {
        "id": 52,
        "q": "A security engineer is performing a vulnerability management scan on multihomed Linux systems. The engineer notices that the vulnerability count is high due to the fact that each vulnerability is multiplied by the number of NICs on each system. Which of the following should the engineer do to deduplicate the vulnerabilities and to associate the vulnerabilities with a particular host?",
        "type": "single",
        "category": "2.3 Given a scenario, integrate appropriate controls in the design of a secure architecture.",
        "answers": [
            {
                "text": "Use a SCAP scanner.",
                "correct": false,
                "explain": "Incorrect. The Security Content Automation Protocol (SCAP) standardizes vulnerability reporting formats but does not inherently solve the issue of a network-based scanner duplicating results for a multihomed system."
            },
            {
                "text": "Deploy an agent.",
                "correct": true,
                "explain": "Correct. A network-based scanner sees a multihomed system as multiple distinct IP addresses. An agent-based scanner is installed on the operating system itself. It understands the system as a single host and reports vulnerabilities based on the host's software inventory, regardless of the number of network interfaces. This naturally deduplicates the findings."
            },
            {
                "text": "Initiate a discovery scan.",
                "correct": false,
                "explain": "Incorrect. A discovery scan is used to identify live hosts on a network; it does not perform vulnerability assessment or solve the deduplication problem."
            },
            {
                "text": "Perform an Nmap scan.",
                "correct": false,
                "explain": "Incorrect. Nmap is a network scanner and would face the same issue as the original scanner, identifying the host by its multiple IP addresses and potentially duplicating vulnerability findings."
            }
        ]
    },
    {
        "id": 53,
        "q": "Which of the following best describes a risk associated with using facial recognition to locally authenticate to a mobile device?",
        "type": "single",
        "category": "1.5 Summarize the information security challenges associated with artificial intelligence (AI) adoption.",
        "answers": [
            {
                "text": "Data remanence",
                "correct": false,
                "explain": "Incorrect. Data remanence is the residual representation of data that remains even after it has been supposedly erased. This is a general storage risk, not one specific to facial recognition authentication."
            },
            {
                "text": "Deepfake",
                "correct": true,
                "explain": "Correct. Facial recognition systems can be vulnerable to presentation attacks. A deepfake, which is a synthetically generated video or image of a person, could potentially be used to fool a facial recognition system into granting access. [cite_start]This is a known risk for AI-based biometric systems. [cite: 200, 201]"
            },
            {
                "text": "Metadata scraping",
                "correct": false,
                "explain": "Incorrect. Metadata scraping involves extracting information from file properties. While the image used for facial recognition has metadata, the primary attack vector against the authentication process itself is impersonation, such as through a deepfake."
            },
            {
                "text": "Biometric impersonation",
                "correct": false,
                "explain": "Incorrect. While 'biometric impersonation' is a general term for the attack, 'deepfake' is a specific and advanced technique used to achieve it, making it the more precise answer in the context of AI-related risks."
            }
        ]
    },
    {
        "id": 54,
        "q": "The principal security analyst for a global manufacturer is investigating a security incident related to abnormal behavior in the ICS network. A controller was restarted as part of the troubleshooting process, and the following issue was identified when the controller was restarted: <br><br> `SECURE BOOT FAILED:FIRMWARE MISMATCH EXPECTED UXFDC479 ACTUAL 0x79F31BD` <br><br> During the investigation, this modified firmware version was identified on several other controllers at the site. The official vendor firmware versions do not have this checksum. Which of the following stages of the MITRE ATT&CK framework for ICS includes this technique?",
        "type": "single",
        "category": "3.4 Given a scenario, implement hardware security technologies and techniques.",
        "answers": [
            {
                "text": "Evasion",
                "correct": false,
                "explain": "Incorrect. Evasion techniques are used to avoid detection by security tools. While modifying firmware could be part of an evasion strategy, its primary purpose in this context is to maintain access after reboots."
            },
            {
                "text": "Persistence",
                "correct": true,
                "explain": "Correct. The attacker has modified the firmware on the industrial controllers. This technique is used to achieve persistence, meaning the attacker's code or access will survive system reboots or other disruptions. The failed Secure Boot check is a direct result of this malicious firmware modification. This aligns with techniques like 'Modify Controller Tasking' or 'System Firmware' in the MITRE ATT&CK for ICS matrix."
            },
            {
                "text": "Collection",
                "correct": false,
                "explain": "Incorrect. Collection involves gathering data from the environment. Modifying firmware is an action taken to maintain control, not to collect data."
            },
            {
                "text": "Lateral movement",
                "correct": false,
                "explain": "Incorrect. Lateral movement involves an attacker moving from one compromised system to another within the network. The act of modifying the firmware on an already-accessed device is for persistence."
            }
        ]
    },
    {
        "id": 55,
        "q": "A web service provider has just taken on a very large contract that comes with requirements that are currently not being implemented. In order to meet contractual requirements, the company must achieve the following thresholds: 99.99% uptime, Load time in 3 seconds, Response time = <1.0 seconds. Starting with the computing environment, which of the following should a security engineer recommend to best meet the requirements? (Choose three.)",
        "type": "multiple",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "Installing a firewall at corporate headquarters",
                "correct": false,
                "explain": "Incorrect. A firewall at corporate HQ does not directly address the performance and high availability requirements of a public-facing web service."
            },
            {
                "text": "Deploying a content delivery network",
                "correct": true,
                "explain": "Correct. [cite_start]A Content Delivery Network (CDN) caches content geographically closer to users, which significantly reduces latency and improves load times, directly addressing the performance requirements. [cite: 232]"
            },
            {
                "text": "Implementing server clusters",
                "correct": true,
                "explain": "Correct. Implementing server clusters with load balancing is a fundamental technique for achieving high availability (uptime). [cite_start]If one server in the cluster fails, others can take over the load, preventing an outage and helping to meet the 99.99% uptime requirement. [cite: 233]"
            },
            {
                "text": "Employing bare-metal loading of applications",
                "correct": false,
                "explain": "Incorrect. Running applications on bare metal versus a hypervisor is an architectural choice that doesn't inherently guarantee high availability or low latency on its own. Clustering and CDNs are more direct solutions."
            },
            {
                "text": "Lowering storage input/output",
                "correct": false,
                "explain": "Incorrect. Lowering storage I/O would likely degrade performance, not improve it."
            },
            {
                "text": "Implementing RAID on the backup servers",
                "correct": false,
                "explain": "Incorrect. While RAID on backup servers is a good practice for backup reliability, it does not affect the real-time uptime or performance of the primary production web service."
            },
            {
                "text": "Utilizing redundant power for all developer workstations",
                "correct": false,
                "explain": "Incorrect. Redundant power for developer workstations has no impact on the production environment's uptime or performance."
            }
        ]
    },
    {
        "id": 56,
        "q": "An analyst is working to address a potential compromise of a corporate endpoint and discovers the attacker accessed a user's credentials. However, it is unclear if the system baseline was modified to achieve persistence. Which of the following would most likely support forensic activities in this scenario?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "Side-channel analysis",
                "correct": false,
                "explain": "Incorrect. Side-channel analysis is an advanced attack that involves gathering information from the physical implementation of a system, not a standard forensic technique for checking baseline modifications."
            },
            {
                "text": "Bit-level disk duplication",
                "correct": false,
                "explain": "Incorrect. While creating a forensic image (bit-level duplication) is a crucial first step in any investigation, it does not, by itself, identify what was changed. It only preserves the state for later analysis."
            },
            {
                "text": "Software composition analysis",
                "correct": false,
                "explain": "Incorrect. Software Composition Analysis (SCA) is a development tool used to identify third-party libraries and their known vulnerabilities. It is not used for forensic analysis of a compromised endpoint."
            },
            {
                "text": "SCAP scanner",
                "correct": true,
                "explain": "Correct. The Security Content Automation Protocol (SCAP) is a suite of standards for automating vulnerability management and security policy compliance checking. A SCAP scanner can be used to compare the current configuration of the compromised system against a known-good, secure baseline (often defined in an XCCDF file). [cite_start]This would be the most direct way to identify if the system baseline was modified to achieve persistence. [cite: 558, 562]"
            }
        ]
    },
    {
        "id": 57,
        "q": "A company is decommissioning old servers and hard drives that contain sensitive data. Which of the following best protects against data leakage?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Purging",
                "correct": false,
                "explain": "Incorrect. Purging, through methods like degaussing, renders data unrecoverable. However, physical destruction provides an even higher level of assurance."
            },
            {
                "text": "Clearing",
                "correct": false,
                "explain": "Incorrect. Clearing, or overwriting data, is a valid sanitization method but is susceptible to advanced forensic recovery techniques and may not be effective on modern drives like SSDs."
            },
            {
                "text": "Shredding",
                "correct": true,
                "explain": "Correct. For drives containing highly sensitive data, physical destruction is the most secure method of data sanitization to prevent data leakage. Shredding the hard drives into small pieces ensures that the data is completely and irreversibly unrecoverable."
            },
            {
                "text": "Degaussing",
                "correct": false,
                "explain": "Incorrect. Degaussing uses a powerful magnetic field to destroy data on magnetic media (like traditional HDDs and tapes). It is ineffective on Solid-State Drives (SSDs) and other flash media, which are common in modern servers."
            }
        ]
    },
    {
        "id": 58,
        "q": "An engineer has had scaling issues with a web application hosted on premises and would like to move to a serverless architecture. Which of the following cloud benefits would be best to utilize for this project?",
        "type": "single",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "Cost savings for hosting",
                "correct": false,
                "explain": "Incorrect. While cost savings can be a benefit of serverless, the primary technical driver for moving from a system with scaling issues is the ability to automatically handle load."
            },
            {
                "text": "Automation of resource provisioning",
                "correct": true,
                "explain": "Correct. A key benefit of serverless architecture (like AWS Lambda or Azure Functions) is that the cloud provider automatically manages the provisioning and scaling of compute resources in response to real-time demand. [cite_start]The engineer no longer has to manually provision servers or configure auto-scaling groups to handle scaling issues; the platform does it automatically. [cite: 321, 322, 323, 324]"
            },
            {
                "text": "Providing geo-redundant hosting",
                "correct": false,
                "explain": "Incorrect. While serverless functions can be deployed across multiple regions for redundancy, this is a separate architectural decision and not the inherent benefit that solves the scaling problem."
            },
            {
                "text": "Eliminating need to patch",
                "correct": false,
                "explain": "Incorrect. In a serverless model, the cloud provider patches the underlying OS and runtime, but the engineer is still responsible for patching their own application code and its dependencies. It reduces, but does not eliminate, the need to patch."
            }
        ]
    },
    {
        "id": 59,
        "q": "An organization needs to classify its systems and data in accordance with external requirements. Which of the following roles is best qualified to perform this task?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "Systems administrator",
                "correct": false,
                "explain": "Incorrect. A systems administrator implements and maintains systems, but they do not have the business context to determine the sensitivity and classification of the data those systems hold."
            },
            {
                "text": "Data owner",
                "correct": true,
                "explain": "Correct. The data owner is typically a senior member of management who is ultimately responsible for a specific subset of data. They have the business context and authority to make decisions about the data, including its classification, protection requirements, and who is allowed to access it."
            },
            {
                "text": "Data processor",
                "correct": false,
                "explain": "Incorrect. A data processor is a third-party entity that processes data on behalf of the data owner/controller. They do not have the authority to classify the data."
            },
            {
                "text": "Data custodian",
                "correct": false,
                "explain": "Incorrect. The data custodian (often the IT department) is responsible for the technical implementation of the security controls mandated by the data owner. They manage the 'how,' not the 'what' or 'why' of data classification."
            },
            {
                "text": "Data steward",
                "correct": false,
                "explain": "Incorrect. A data steward is responsible for the day-to-day management of data quality, metadata, and adherence to policies, but the ultimate responsibility for classification lies with the data owner."
            }
        ]
    },
    {
        "id": 60,
        "q": "A company is developing an application that will be used to perform e-commerce transactions for a subscription-based service. The application must be able to use previously saved payment methods to perform recurring transactions. Which of the following is the most appropriate?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Tokenization through an HSM",
                "correct": false,
                "explain": "Incorrect. An HSM (Hardware Security Module) is used to protect cryptographic keys. While it could be part of a larger secure payment solution, tokenization itself is the primary technique for handling stored payment methods, and it's typically managed by a payment gateway, not directly by an HSM."
            },
            {
                "text": "Self-encrypting disks with field-level encryption",
                "correct": false,
                "explain": "Incorrect. Encrypting data at rest is a crucial control, but it does not reduce the compliance scope in the same way tokenization does. Storing the actual credit card numbers, even encrypted, still carries a high level of risk and PCI DSS compliance overhead."
            },
            {
                "text": "NX/XN Implementation to minimize data retention",
                "correct": false,
                "explain": "Incorrect. The NX (No-Execute) bit is a hardware security feature to prevent code execution in memory and is unrelated to storing payment information."
            },
            {
                "text": "Tokenization",
                "correct": true,
                "explain": "Correct. Tokenization is the process of replacing sensitive data, such as a credit card number, with a non-sensitive equivalent referred to as a 'token'. The application stores this token instead of the actual card number. When a recurring transaction is needed, the application sends the token to the payment processor, who has securely stored the mapping back to the original card number. [cite_start]This process significantly reduces risk and PCI DSS compliance scope for the company because they never store the actual sensitive payment data. [cite: 607]"
            },
            {
                "text": "Address space layout randomization",
                "correct": false,
                "explain": "Incorrect. ASLR is a memory protection technique that randomizes the location of key data areas in memory to make exploitation more difficult. It is not related to storing payment information."
            }
        ]
    },
    {
        "id": 61,
        "q": "A security technician is trying to connect a remote site to the central office over a site-to-site VPN. The technician has verified the source and destination IP addresses are correct, but the technician is unable to get the remote site to connect. The following error message keeps repeating: <br><br> `An error has occurred during Phase 1 handshake. Deleting keys and retrying...` <br><br> Which of the following is most likely the reason the connection is failing?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "The IKE hashing algorithm uses different key lengths on each VPN device.",
                "correct": true,
                "explain": "Correct. The IPsec Phase 1 (IKE) handshake involves both sides agreeing on a set of security parameters, including an encryption algorithm, a hashing algorithm, an authentication method, and a Diffie-Hellman group. If any of these parameters do not match exactly on both devices, the Phase 1 handshake will fail, resulting in the error shown. A mismatch in the configured hashing algorithm (e.g., SHA-256 on one side and SHA-384 on the other) is a very common cause of this issue."
            },
            {
                "text": "The IPSec settings allow more than one cipher suite on both devices.",
                "correct": false,
                "explain": "Incorrect. Allowing multiple cipher suites is normal; the devices will negotiate to find one they both support. A failure occurs when there are no matching suites in their respective proposals."
            },
            {
                "text": "The Diffie-Hellman group on both sides matches but is a legacy group.",
                "correct": false,
                "explain": "Incorrect. If the DH group matches, the handshake should proceed, even if the group is considered weak. Using a legacy group is a security risk, but it would not cause the handshake to fail if it's configured on both ends."
            },
            {
                "text": "The remote VPN is attempting to connect with a protocol other than SSL/TLS.",
                "correct": false,
                "explain": "Incorrect. The error message specifically mentions a 'Phase 1 handshake,' which is terminology for the IKE protocol used by IPsec VPNs, not SSL/TLS VPNs. The issue is within the IPsec configuration itself."
            }
        ]
    },
    {
        "id": 62,
        "q": "A security analyst received the following finding from a cloud security assessment tool: `Virtual Machine Data Disk is encrypted with the default encryption key.` Because the organization hosts highly sensitive data files, regulations dictate it must be encrypted so It is unreadable to the CSP. Which of the following should be implemented to remediate the finding and meet the regulatory requirement? (Choose two.)",
        "type": "multiple",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "Disk encryption with customer-provided keys",
                "correct": true,
                "explain": "Correct. The requirement is that the data must be unreadable to the Cloud Service Provider (CSP). When using default (CSP-managed) keys, the CSP technically has access to the keys and could be compelled to decrypt the data. By using Customer-Provided Encryption Keys (CPMK/CSEK), the customer maintains sole control of the keys, ensuring the CSP cannot access the encrypted data. [cite_start]This applies to the entire disk. [cite: 337]"
            },
            {
                "text": "Disk encryption with keys from a third party",
                "correct": false,
                "explain": "Incorrect. While possible, using customer-provided keys stored in their own key management system is the more direct and common approach to meeting this requirement."
            },
            {
                "text": "Row-level encryption with a key escrow",
                "correct": false,
                "explain": "Incorrect. Row-level encryption is for databases, not entire virtual machine disks. Key escrow involves giving a third party access to keys, which may not satisfy the regulatory requirement."
            },
            {
                "text": "File-level encryption with cloud vendor-provided keys",
                "correct": false,
                "explain": "Incorrect. Using cloud vendor-provided keys does not meet the requirement that the data be unreadable to the CSP."
            },
            {
                "text": "File-level encryption with customer-provided keys",
                "correct": true,
                "explain": "Correct. Similar to disk encryption, encrypting individual files with keys that the customer manages ensures that the CSP cannot read the contents of those files, directly meeting the regulatory requirement. [cite_start]This provides a more granular level of control than just disk encryption alone. [cite: 337]"
            },
            {
                "text": "Disk-level encryption with a cross-signed certificate",
                "correct": false,
                "explain": "Incorrect. Certificates are used for authentication and identity, not for encrypting data disks. The control is about the encryption keys themselves."
            }
        ]
    },
    {
        "id": 63,
        "q": "A security analyst discovers a new device on the company's dedicated IoT subnet during the most recent vulnerability scan. The scan results show numerous open ports and insecure protocols in addition to default usernames and passwords. A camera needs to transmit video to the security server in the IoT subnet. Which of the following should the security analyst recommend to securely operate the camera?",
        "type": "single",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "Harden the camera configuration.",
                "correct": false,
                "explain": "Incorrect. While hardening the camera (changing passwords, closing ports) is a necessary step, the most critical control for an untrusted device is isolation."
            },
            {
                "text": "Send camera logs to the SIEM.",
                "correct": false,
                "explain": "Incorrect. Monitoring logs is a detective control. The primary goal should be to prevent a compromise from spreading, which is achieved through preventative controls like segmentation."
            },
            {
                "text": "Encrypt the camera's video stream.",
                "correct": false,
                "explain": "Incorrect. Encrypting the video stream protects the confidentiality of the data in transit but does not protect the network from a potentially compromised camera."
            },
            {
                "text": "Place the camera on an isolated segment.",
                "correct": true,
                "explain": "Correct. IoT devices are notoriously insecure. The best practice is to assume they can be compromised. Placing the camera on its own isolated network segment (e.g., its own VLAN) and using a firewall to strictly control traffic to and from that segment is the most effective security measure. [cite_start]This contains the device and prevents it from being used as a pivot point to attack other systems on the network, even if it is compromised. [cite: 515]"
            }
        ]
    },
    {
        "id": 64,
        "q": "The Chief Information Security Officer of a large multinational organization has asked the security risk manager to use risk scenarios during a risk analysis. Which of the following is the most likely reason for this approach?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "To connect risks to business objectives",
                "correct": false,
                "explain": "Incorrect. While connecting risk to business objectives is the ultimate goal of risk management, the use of scenarios serves a more immediate purpose of making the risk understandable."
            },
            {
                "text": "To ensure a consistent approach to risk",
                "correct": false,
                "explain": "Incorrect. A consistent framework (like FAIR or NIST RMF) ensures a consistent approach. Scenarios are a tool used within that framework."
            },
            {
                "text": "To present a comprehensive view of risk",
                "correct": false,
                "explain": "Incorrect. A risk register presents a comprehensive view. A scenario focuses on a specific event."
            },
            {
                "text": "To provide context to the relevancy of risk",
                "correct": true,
                "explain": "Correct. Abstract risk statements (e.g., 'risk of data breach') can be hard for business leaders to grasp. A risk scenario (e.g., 'An external attacker exploits a vulnerability in our public-facing web server, resulting in the exfiltration of 1 million customer records') provides a concrete story. [cite_start]This narrative approach makes the risk tangible, relevant, and easier to understand, which is essential for effective communication and decision-making, especially in a large organization. [cite: 86]"
            }
        ]
    },
    {
        "id": 65,
        "q": "A security engineer would like to control configurations on mobile devices while fulfilling the following requirements: Support and control Apple and Android devices. The device must be corporate-owned. Which of the following would enable the engineer to meet these requirements? (Choose two.)",
        "type": "multiple",
        "category": "3.2 Given a scenario, analyze requirements to enhance the security of endpoints and servers.",
        "answers": [
            {
                "text": "Create a group policy to lock down mobile devices.",
                "correct": false,
                "explain": "Incorrect. Group Policy Objects (GPOs) are primarily for managing Windows-based systems within an Active Directory environment and do not apply to Apple and Android mobile devices."
            },
            {
                "text": "Update verbiage in the acceptable use policy for the internet.",
                "correct": false,
                "explain": "Incorrect. An Acceptable Use Policy (AUP) is an administrative control that defines rules for users. It is not a technical control for managing device configurations."
            },
            {
                "text": "Implement an MDM solution.",
                "correct": true,
                "explain": "Correct. Mobile Device Management (MDM) solutions are specifically designed to manage and enforce security policies on mobile devices, including both Apple (iOS/iPadOS) and Android. [cite_start]They provide the technical means to control configurations. [cite: 432, 433]"
            },
            {
                "text": "Implement a captive portal solution.",
                "correct": false,
                "explain": "Incorrect. A captive portal is used for authenticating users to a network (often public Wi-Fi) and is not a tool for managing the configuration of the device itself."
            },
            {
                "text": "Update policy to prohibit the use of BYOD devices.",
                "correct": true,
                "explain": "Correct. The requirement states the devices must be corporate-owned. An administrative policy that explicitly prohibits the use of Bring Your Own Device (BYOD) for corporate access formally documents this requirement and provides the justification for enforcing it with technical controls like MDM."
            },
            {
                "text": "Implement a RADIUS solution.",
                "correct": false,
                "explain": "Incorrect. RADIUS is an authentication protocol used for network access control; it does not manage the configuration settings on the mobile device itself."
            }
        ]
    },
    {
        "id": 66,
        "q": "A pharmaceutical company uses a cloud provider to host thousands of independent resources in object storage. The company needs a practical and effective means of discovering data, monitoring changes, and identifying suspicious activity. Which of the following would best meet these requirements?",
        "type": "single",
        "category": "2.3 Given a scenario, integrate appropriate controls in the design of a secure architecture.",
        "answers": [
            {
                "text": "A machine-learning-based data security service",
                "correct": true,
                "explain": "Correct. Given the scale (thousands of resources) and the need to identify 'suspicious activity,' a manual or simple rule-based approach is impractical. A modern, machine-learning-based data security service (like Amazon Macie or Google Cloud DLP) is designed for this exact purpose. It can automatically discover sensitive data, monitor for changes and anomalous access patterns, and alert on suspicious activity at scale."
            },
            {
                "text": "A file integrity monitoring service",
                "correct": false,
                "explain": "Incorrect. File Integrity Monitoring (FIM) can monitor for changes but typically lacks the data discovery and behavioral analysis capabilities needed to identify suspicious activity across a large, dynamic object storage environment."
            },
            {
                "text": "A cloud configuration assessment and compliance service",
                "correct": false,
                "explain": "Incorrect. A Cloud Security Posture Management (CSPM) tool is designed to assess the configuration of cloud resources against a baseline. It would identify if a storage bucket is public, but it wouldn't analyze the data within it or the activity related to it."
            },
            {
                "text": "An automated data classification system",
                "correct": false,
                "explain": "Incorrect. While data classification is a part of the solution, a full-fledged 'machine-learning-based data security service' is more comprehensive as it includes not just classification but also ongoing monitoring and threat detection, which addresses all parts of the question."
            }
        ]
    },
    {
        "id": 67,
        "q": "A security analyst is assessing a new application written in Java. The security analyst must determine which vulnerabilities exist during runtime. Which of the following would provide the most exhaustive list of vulnerabilities while meeting the objective?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Input validation",
                "correct": false,
                "explain": "Incorrect. Input validation is a security control to be implemented, not a testing method to find vulnerabilities."
            },
            {
                "text": "Dynamic analysis",
                "correct": true,
                "explain": "Correct. The key phrase is 'during runtime.' Dynamic Application Security Testing (DAST) analyzes an application while it is running. It simulates external attacks by sending various inputs and observing the application's responses to identify vulnerabilities that are only apparent in a running state. [cite_start]This directly meets the objective. [cite: 241]"
            },
            {
                "text": "Side-channel analysis",
                "correct": false,
                "explain": "Incorrect. Side-channel analysis is a highly specialized type of attack that analyzes physical characteristics (like power consumption or timing) to extract information. It is not a general-purpose method for finding common application vulnerabilities."
            },
            {
                "text": "Fuzz testing",
                "correct": false,
                "explain": "Incorrect. Fuzz testing is a type of dynamic analysis, but DAST is the broader category that encompasses various techniques for testing a running application, making it the more exhaustive choice."
            },
            {
                "text": "Static analysis",
                "correct": false,
                "explain": "Incorrect. Static Application Security Testing (SAST) analyzes the source code without executing it. It cannot find vulnerabilities that only manifest during runtime."
            }
        ]
    },
    {
        "id": 68,
        "q": "Recently, two large engineering companies in the same line of business decided to approach cyberthreats in a united way. Which of the following best describes this unified approach?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "NDA",
                "correct": false,
                "explain": "Incorrect. A Non-Disclosure Agreement (NDA) is a legal contract to protect confidential information shared between parties. While it would likely be part of the arrangement, it doesn't describe the overall collaborative approach."
            },
            {
                "text": "SOW",
                "correct": false,
                "explain": "Incorrect. A Statement of Work (SOW) is a document that details the work to be performed in a project or service engagement. It is not used to define a collaborative partnership."
            },
            {
                "text": "SLA",
                "correct": false,
                "explain": "Incorrect. A Service Level Agreement (SLA) defines the level of service expected from a vendor. It is not used to describe a cooperative agreement between peer companies."
            },
            {
                "text": "MOU",
                "correct": true,
                "explain": "Correct. A Memorandum of Understanding (MOU) is a non-binding agreement between two or more parties that outlines the terms and details of a mutual understanding or agreement, forming a framework for future collaboration. It is the appropriate document to establish a unified, cooperative approach to cybersecurity between two companies."
            }
        ]
    },
    {
        "id": 69,
        "q": "A regulated company is in the process of refreshing its entire infrastructure. The company has a business-critical process running on an old 2008 Windows server. If this server fails, the company would lose millions of dollars in revenue. Which of the following actions should the company should take?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Accept the risk as the cost of doing business.",
                "correct": false,
                "explain": "Incorrect. Accepting a risk of this magnitude (millions of dollars) without any analysis or mitigation is irresponsible and not a proper risk management practice."
            },
            {
                "text": "Create an organizational risk register for project prioritization.",
                "correct": true,
                "explain": "Correct. The first step in managing any risk is to formally identify and document it. [cite_start]By adding this issue to a risk register, the company can properly analyze its impact and likelihood, compare it to other organizational risks, and prioritize resources (such as for a project to migrate the application off the old server) based on a formal, data-driven process. [cite: 87]"
            },
            {
                "text": "Implement network compensating controls.",
                "correct": false,
                "explain": "Incorrect. While compensating controls might be a valid mitigation strategy, the first action should be to formally document and assess the risk in a register. The decision to use compensating controls would come after the analysis."
            },
            {
                "text": "Purchase insurance to offset the cost if a failure occurred.",
                "correct": false,
                "explain": "Incorrect. Purchasing insurance (risk transference) is one possible response, but it should only be considered after the risk has been formally documented and analyzed in a risk register."
            }
        ]
    },
    {
        "id": 70,
        "q": "A security engineer needs to ensure production containers are automatically scanned for vulnerabilities before they are accepted into the production environment. Which of the following should the engineer use to automatically incorporate vulnerability scanning on every commit?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Code repository",
                "correct": false,
                "explain": "Incorrect. The code repository (like Git) stores the code but does not execute the automated scanning process itself."
            },
            {
                "text": "CI/CD pipeline",
                "correct": true,
                "explain": "Correct. A Continuous Integration/Continuous Deployment (CI/CD) pipeline is an automated workflow that builds, tests, and deploys code. A key security practice ('DevSecOps') is to integrate security tools directly into this pipeline. [cite_start]The engineer can configure the pipeline to automatically trigger a container vulnerability scanner every time new code is committed, and fail the build if vulnerabilities are found, thus preventing insecure containers from reaching production. [cite: 244, 245]"
            },
            {
                "text": "Integrated development environment",
                "correct": false,
                "explain": "Incorrect. An IDE is the tool a developer uses to write code. While plugins can provide some local scanning, the automated, central enforcement point for this requirement is the CI/CD pipeline."
            },
            {
                "text": "Container orchestrator",
                "correct": false,
                "explain": "Incorrect. A container orchestrator (like Kubernetes) manages the deployment and lifecycle of containers in production. While it might have admission controllers that can check for scan results, the scanning process itself is best integrated earlier in the CI/CD pipeline."
            }
        ]
    },
    {
        "id": 71,
        "q": "A security architect recommends replacing the company's monolithic software application with a containerized solution. Historically, secrets have been stored in the application's configuration files. Which of the following changes should the security architect make in the new system?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Use a secrets management tool.",
                "correct": true,
                "explain": "Correct. Storing secrets (like API keys, passwords, certificates) in configuration files or code is a major security anti-pattern. The modern, secure approach, especially in containerized environments, is to use a dedicated secrets management tool (e.g., HashiCorp Vault, AWS Secrets Manager). [cite_start]The application retrieves the secrets from this secure, centralized service at runtime, rather than having them stored insecurely on disk. [cite: 384]"
            },
            {
                "text": "Save secrets in key escrow.",
                "correct": false,
                "explain": "Incorrect. Key escrow is a system for storing backup copies of cryptographic keys with a third party for recovery purposes. It is not a system for managing application secrets at runtime."
            },
            {
                "text": "Store the secrets inside the Dockerfiles.",
                "correct": false,
                "explain": "Incorrect. Storing secrets in Dockerfiles is even worse than storing them in configuration files, as the Dockerfile is often checked into version control, making the secret widely visible."
            },
            {
                "text": "Run all Dockerfiles in a randomized namespace.",
                "correct": false,
                "explain": "Incorrect. Using randomized namespaces can help with process isolation but does nothing to solve the problem of securely storing and managing secrets."
            }
        ]
    },
    {
        "id": 72,
        "q": "A security engineer is assessing a new tool to segment data and communications between domains. The assessment must determine how data transmission controls can be bypassed without detection. Which of the following techniques should the security engineer use?",
        "type": "single",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "Machine-learning statistical analysis",
                "correct": false,
                "explain": "Incorrect. This technique could be used to detect a covert channel but is not the method for creating or testing for one."
            },
            {
                "text": "Fuzz testing",
                "correct": false,
                "explain": "Incorrect. Fuzz testing involves sending malformed data to find crashes and memory corruption vulnerabilities, not to test for data exfiltration bypasses."
            },
            {
                "text": "Covert channel analysis",
                "correct": true,
                "explain": "Correct. A covert channel is a communication path that bypasses intended security controls to exfiltrate data. For example, encoding data in the timing of network packets or in unused protocol headers. Analyzing the system for potential covert channels is the exact technique used to determine how data transmission controls could be bypassed without detection."
            },
            {
                "text": "Protocol analysis",
                "correct": false,
                "explain": "Incorrect. Protocol analysis involves examining how a network protocol works. While it is a necessary part of covert channel analysis, the specific goal of finding a bypass method is best described as covert channel analysis."
            }
        ]
    },
    {
        "id": 73,
        "q": "During an adversarial simulation exercise, an external team was able to gain access to sensitive information and systems without the organization detecting this activity. Which of the following mitigation strategies should the organization use to best resolve the findings?",
        "type": "single",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "Configuring a honeypot for adversary characterization",
                "correct": false,
                "explain": "Incorrect. A honeypot is used to lure and study attackers. The problem here is that existing detection capabilities failed; a honeypot doesn't fix the detection on production systems."
            },
            {
                "text": "Leveraging simulators for attackers",
                "correct": false,
                "explain": "Incorrect. This is not a standard security term or a mitigation strategy."
            },
            {
                "text": "Setting up a honey network for attackers",
                "correct": false,
                "explain": "Incorrect. A honeynet is a more complex version of a honeypot. Like a honeypot, it's a research tool, not a direct mitigation for failed detection on production systems."
            },
            {
                "text": "Utilizing decoy accounts and documents",
                "correct": true,
                "explain": "Correct. The core issue is a lack of detection. Utilizing decoy resources like honeytokens (e.g., fake AWS API keys), decoy user accounts, or honeyfiles (documents with beacons) is a modern deception technology strategy. If an attacker accesses or uses any of these decoy resources, it generates a high-fidelity alert, as no legitimate user should ever touch them. This directly addresses the failure to detect unauthorized access."
            }
        ]
    },
    {
        "id": 74,
        "q": "A help desk technician is troubleshooting an issue with an employee's laptop that will not boot into its operating system. The employee reported the laptop had been stolen but then found it one day later. The employee has asked the technician for help recovering important data. The technician has identified the following: The laptop operating system was not configured with BitLocker. The hard drive has no hardware failures. Data is present and readable on the hard drive, although it appears to be illegible. Which of the following is the most likely reason the technician is unable to retrieve legible data from the hard drive?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "The employee's password was changed, and the new password needs to be used.",
                "correct": false,
                "explain": "Incorrect. A changed password would prevent login but would not make the data on the drive 'illegible' if it wasn't encrypted."
            },
            {
                "text": "The PKI certificate was revoked, and a new one must be installed.",
                "correct": false,
                "explain": "Incorrect. PKI certificates are for authentication, not typically for encrypting the entire disk content in a way that would make it illegible after being stolen."
            },
            {
                "text": "The hard drive experienced crypto-shredding.",
                "correct": true,
                "explain": "Correct. Crypto-shredding (or cryptographic erase) is a data sanitization technique. Even though the OS-level encryption (BitLocker) was not on, the drive itself could be a Self-Encrypting Drive (SED). When a theft was reported, a remote management tool could have issued a command to the SED to securely delete its internal media encryption key. [cite_start]This action renders all data on the drive permanently illegible (cryptographically erased) without having to overwrite the entire disk. [cite: 609]"
            },
            {
                "text": "The technician is using the incorrect cipher to read the data.",
                "correct": false,
                "explain": "Incorrect. Without the correct key, the cipher used is irrelevant. The core issue is the destruction of the key, which is the result of crypto-shredding."
            }
        ]
    },
    {
        "id": 75,
        "q": "SIMULATION - This system was recently patched following the exploitation of a vulnerability by an attacker to enable data exfiltration. Despite the vulnerability being patched, it is likely that a malicious TCP service is still running and the adversary has achieved persistence by creating a systemd service. INSTRUCTIONS - Using the following credentials: Username: labadmin, Password: Passw0rd! Investigate to identify indicators of compromise and then remediate them. You will need to make at least two changes: 1. End the compromised process that is using a malicious TCP service. 2. Remove the malicious persistence agent by disabling the service's ability to start on boot.",
        "type": "simulation",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "1. `netstat -antp` or `ss -lntp` to find the process listening on an unusual port. `ps -aux` to inspect processes. The process name might be misspelled (e.g., 'sshd' vs 'sshd_malicious'). Note the Process ID (PID). 2. `kill [PID]` to terminate the malicious process. 3. `systemctl list-unit-files --type=service` to find the malicious service file. 4. `systemctl disable [malicious_service_name]` to remove the persistence mechanism. 5. Optional: `rm /etc/systemd/system/[malicious_service_name]` to delete the service file.",
                "correct": true,
                "explain": "Correct. This answer provides a logical command sequence for a hands-on simulation. First, identify the malicious process and its corresponding service using network and process listing commands. Second, terminate the running process using its PID. Third, disable the systemd service to prevent it from starting on reboot, thus removing the persistence mechanism. This directly follows the instructions given in the prompt."
            }
        ]
    },
    {
        "id": 76,
        "q": "HOTSPOT - You are tasked with integrating a new B2B client application with an existing OAuth workflow that must meet the following requirements: The application does not need to know the users credentials. An approval interaction between the users and the HTTP service must be orchestrated. The application must have limited access to users data. INSTRUCTIONS - Use the drop-down menus to select the action items for the appropriate locations. <br><br> <img src='../../assets/quiz-images/CAS-005_76.png' alt='OAuth workflow diagram'>",
        "type": "hotspot",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Authorization Server: `Grant access`. Resource Server: `Access issued tokens`. B2B client application: `Authorize access to other applications`.",
                "correct": false,
                "explain": "Incorrect mapping of OAuth roles and actions."
            },
            {
                "text": "Authorization Server: `Authorize access to other applications`. Resource Server: `Grant access`. B2B client application: `Access issued tokens`.",
                "correct": true,
                "explain": "Correct. This accurately represents the OAuth 2.0 Authorization Code Grant flow. 1. The **Resource Owner** uses the B2B client application. 2. The **B2B client application** redirects the user to the **Authorization Server** to `Authorize access`. 3. The **Authorization Server** authenticates the user and obtains their consent, then issues an authorization code back to the client application. 4. The client application exchanges this code for an access token from the Authorization Server. 5. The client application uses the access token to request data from the **Resource Server**. 6. The **Resource Server** validates the token and, if valid, `Grants access` to the protected resource. The option selected for the Resource Owner's laptop should be `Access issued tokens`, as the user's browser will ultimately handle the token."
            },
            {
                "text": "Authorization Server: `Access issued tokens`. Resource Server: `Authorize access to other applications`. B2B client application: `Grant access`.",
                "correct": false,
                "explain": "Incorrect mapping of OAuth roles and actions."
            }
        ]
    },
    {
        "id": 77,
        "q": "SIMULATION - An IPSec solution is being deployed. The configuration files for both the VPN concentrator and the AAA server are shown in the diagram. Complete the configuration files to meet the following requirements: The EAP method must use mutual certificate-based authentication (with issued client certificates). The IKEv2 cipher suite must be configured to the most secure authenticated mode of operation. The secret must contain at least one uppercase character, one lowercase character, one numeric character, and one special character, and it must meet a minimum length requirement of eight characters. INSTRUCTIONS - Click on the AAA server and VPN concentrator to complete the configuration. <br><br> <img src='../../assets/quiz-images/CAS-005_77_1.png' alt='VPN and AAA server diagram'> <br> <img src='../../assets/quiz-images/CAS-005_77_2.png' alt='VPN concentrator configuration'> <br> <img src='../../assets/quiz-images/CAS-005_77_3.png' alt='AAA server configuration'>",
        "type": "simulation",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "**VPN Concentrator:** proposals = `tls`, eap-radius secret = `P@ssw0rd!`, server = `10.1.0.10`. **AAA Server:** default_eap_type = `tls`, ip addr = `10.1.2.1`, secret = `P@ssw0rd!`.",
                "correct": true,
                "explain": "Correct. 1. For mutual certificate-based authentication, the EAP method must be `EAP-TLS`. So `tls` is the correct proposal on both the VPN concentrator and the AAA server. 2. The most secure authenticated mode of operation listed is `aes256gcm128`. GCM (Galois/Counter Mode) is an AEAD (Authenticated Encryption with Associated Data) cipher, which provides both confidentiality and authenticity, making it more secure than CBC modes. 3. A strong secret like `P@ssw0rd!` meets the complexity and length requirements. 4. The VPN concentrator's eap-radius server IP must be the AAA server's IP (`10.1.0.10`). The AAA server's configuration for the client (ip addr) must be the VPN concentrator's IP (`10.1.2.1`)."
            }
        ]
    },
    {
        "id": 78,
        "q": "SIMULATION - An incident occurred at Site A when an attacker successfully caused water pressure to increase in the pump room. The organization is concerned about reoccurrence of this attack and that similar attacks might be successful on other cyber-physical systems within the network. All devices and components reside on a flat network within the 10.1.0.0/16 space. INSTRUCTIONS - Take the appropriate actions to reduce the risk of reoccurrence of this and other environmental security vulnerabilities. Select the component(s) at Sites A and B that have environmental impact potential. Then, select the corrective action that will best reduce the risk of incident reoccurrence. <br><br> <img src='../../assets/quiz-images/CAS-005_78.png' alt='Cyber-physical system diagram'>",
        "type": "simulation",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "**Selected Components:** HVAC, PLC, Pumps (at both sites). **Corrective Action:** Isolate from the network.",
                "correct": true,
                "explain": "Correct. 1. The components with environmental impact potential are the ones that interact with the physical world: **HVAC** (Heating, Ventilation, and Air Conditioning), **PLC** (Programmable Logic Controllers, which control machinery), and **Pumps**. 2. The root cause of the problem is that these critical OT/ICS systems are on a flat network with other IT systems, making them accessible to attackers. The best corrective action to reduce risk is to **isolate** these systems from the main corporate network onto their own segmented, protected network. [cite_start]This preventative measure is stronger than detective controls like NIDS or applying patches, which might not even be possible on these legacy systems. [cite: 502, 505, 508, 515]"
            }
        ]
    },
    {
        "id": 79,
        "q": "SIMULATION - During the course of normal SOC operations, three anomalous events occurred and were flagged as potential IoCs. Evidence for each of these potential IoCs is provided. INSTRUCTIONS - Review each of the events and select the appropriate analysis and action options for each IoC. <br><br> <img src='../../assets/quiz-images/CAS-005_79_1.png' alt='IoC 1'> <br> <img src='../../assets/quiz-images/CAS-005_79_2.png' alt='IoC 2'> <br> <img src='../../assets/quiz-images/CAS-005_79_3.png' alt='IoC 3'>",
        "type": "simulation",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "**IoC 1:** Analysis: An application is performing an automatic update. Action: Close ticket as resolved. <br> **IoC 2:** Analysis: Someone is footprinting a network subnet. Action: Block ping requests across the WAN interface. <br> **IoC 3:** Analysis: An employee is using P2P services to download files. Action: Enforce endpoint controls on third-party software installations.",
                "correct": true,
                "explain": "Correct. **IoC 1:** The logs show a normal DNS query for an update server (`update.s.domain`), which is characteristic of a software auto-update. This is benign. **IoC 2:** The logs show a single source IP (`10.0.5.5`) sending ICMP ECHO requests (pings) to multiple sequential IP addresses (`10.1.2.1` through `10.1.2.5`). This is a classic ICMP sweep, a form of network footprinting or reconnaissance. Blocking inbound pings at the edge is a common mitigation. **IoC 3:** The proxy log shows a GET request to `/announce` with a `peer_id`, and the user-agent is `x-bittorrent`. This is unmistakably BitTorrent traffic, a peer-to-peer (P2P) file-sharing protocol. The appropriate action is to enforce policies that prevent the installation of unauthorized third-party software like P2P clients."
            }
        ]
    },
    {
        "id": 80,
        "q": "A security administrator needs to automate alerting. The server generates structured log files that need to be parsed to determine whether an alarm has been triggered. Given the following code function: <br><br> <img src='../../assets/quiz-images/CAS-005_80.png' alt='Python code to parse logs'> <br><br> Which of the following is most likely the log input that the code will parse?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "<img src='../../assets/quiz-images/CAS-005_80_A.png' alt='Option A'>",
                "correct": false,
                "explain": "Incorrect. This format appears to be a list of lists or a custom format, not valid JSON."
            },
            {
                "text": "<img src='../../assets/quiz-images/CAS-005_80_B.png' alt='Option B'>",
                "correct": false,
                "explain": "Incorrect. This is XML (Extensible Markup Language) format, which would require an XML parser, not `json.load()`."
            },
            {
                "text": "<img src='../../assets/quiz-images/CAS-005_80_C.png' alt='Option C'>",
                "correct": false,
                "explain": "Incorrect. This is YAML (YAML Ain't Markup Language) format. It would need a YAML library to be parsed, not the JSON library."
            },
            {
                "text": "<img src='../../assets/quiz-images/CAS-005_80_D.png' alt='Option D'>",
                "correct": true,
                "explain": "Correct. The Python code specifically uses the `json.load()` function. This function is designed to parse data formatted in JavaScript Object Notation (JSON). [cite_start]Option D is the only one written in valid JSON syntax, using curly braces `{}` for objects, quotes for keys, and colons to separate keys and values. [cite: 543]"
            }
        ]
    },
    {
        "id": 81,
        "q": "A financial technology firm works collaboratively with business partners in the industry to share threat intelligence within a central platform. This collaboration gives partner organizations the ability to obtain and share data associated with emerging threats from a variety of adversaries. Which of the following should the organization most likely leverage to facilitate this activity?(Choose two.)",
        "type": "multiple",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "CWPP",
                "correct": false,
                "explain": "Incorrect. A Cloud Workload Protection Platform (CWPP) is used to secure server workloads in hybrid cloud environments. It is not a standard for sharing threat intelligence."
            },
            {
                "text": "YARA",
                "correct": false,
                "explain": "Incorrect. YARA is a tool for creating rules to identify malware based on textual or binary patterns. While YARA rules can be a form of shared intelligence, STIX and TAXII are the standards for the overall exchange."
            },
            {
                "text": "ATT&CK",
                "correct": false,
                "explain": "Incorrect. MITRE ATT&CK is a framework for describing adversary tactics and techniques. It provides a common language but is not a protocol for automated exchange."
            },
            {
                "text": "STIX",
                "correct": true,
                "explain": "Correct. Structured Threat Information eXpression (STIX) is a standardized language and format used to represent structured cyber threat intelligence. [cite_start]It allows organizations to share information about threats, threat actors, campaigns, and indicators in a consistent, machine-readable way. [cite: 725]"
            },
            {
                "text": "TAXII",
                "correct": true,
                "explain": "Correct. Trusted Automated eXchange of Intelligence Information (TAXII) is an application layer protocol specifically designed for the communication and automated exchange of cyber threat intelligence over HTTPS. [cite_start]It is the transport mechanism used to share STIX-formatted data between threat intelligence platforms. [cite: 726]"
            },
            {
                "text": "JTAG",
                "correct": false,
                "explain": "Incorrect. Joint Test Action Group (JTAG) is a standard for hardware debugging, and it is not related to sharing cyber threat intelligence."
            }
        ]
    },
    {
        "id": 82,
        "q": "A company wants to invest in research capabilities with the goal to operationalize the research output. Which of the following is the best option for a security architect to recommend?",
        "type": "single",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "Dark web monitoring",
                "correct": false,
                "explain": "Incorrect. Dark web monitoring is a source of raw intelligence but is not a platform for operationalizing that intelligence."
            },
            {
                "text": "Threat intelligence platform",
                "correct": true,
                "explain": "Correct. A Threat Intelligence Platform (TIP) is a technology solution that collects, aggregates, correlates, and analyzes threat intelligence data from multiple sources (like OSINT, dark web monitoring, and ISACs). [cite_start]Its primary purpose is to 'operationalize' this intelligence by integrating with other security tools (like SIEMs, firewalls, and SOARs) to automate detection and response. [cite: 722]"
            },
            {
                "text": "Honeypots",
                "correct": false,
                "explain": "Incorrect. Honeypots are a source of intelligence about attacker TTPs but are not a platform for managing and operationalizing intelligence from all sources."
            },
            {
                "text": "Continuous adversary emulation",
                "correct": false,
                "explain": "Incorrect. Adversary emulation is a method for testing existing controls, not for researching and operationalizing external threat intelligence."
            }
        ]
    },
    {
        "id": 83,
        "q": "A company is concerned about the security of customer data. The IT department has configured all web applications with appropriate access controls to restrict to only authorized users. Which of the following solutions addresses this concern?",
        "type": "single",
        "category": "2.3 Given a scenario, integrate appropriate controls in the design of a secure architecture.",
        "answers": [
            {
                "text": "SIEM",
                "correct": false,
                "explain": "Incorrect. A SIEM is a monitoring and alerting tool. It can report on data access but doesn't actively prevent its loss."
            },
            {
                "text": "Vulnerability scanner",
                "correct": false,
                "explain": "Incorrect. A vulnerability scanner finds potential weaknesses but does not monitor or control the flow of data."
            },
            {
                "text": "DLP",
                "correct": true,
                "explain": "Correct. Even with proper access controls, authorized users can still intentionally or accidentally leak sensitive data. A Data Loss Prevention (DLP) solution addresses this specific concern. [cite_start]It inspects data at rest, in use, and in transit to detect sensitive content and apply policies to prevent it from being exfiltrated or shared inappropriately. [cite: 279]"
            },
            {
                "text": "Threat intelligence platform",
                "correct": false,
                "explain": "Incorrect. A TIP is used to manage intelligence about external threats; it does not directly control data flow within the organization."
            }
        ]
    },
    {
        "id": 84,
        "q": "A security analyst reviews the following report: <br><br> <img src='../../assets/quiz-images/CAS-005_84.png' alt='Product supply chain report'> <br><br> Which of the following assessments is the analyst performing?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "System",
                "correct": false,
                "explain": "Incorrect. A system assessment would focus on the configuration and vulnerabilities of a single system, not its entire provenance."
            },
            {
                "text": "Supply chain",
                "correct": true,
                "explain": "Correct. The report details the various components and entities involved in the creation of a final product, including the location of manufacture, the chassis manufacturer, the OS, the application developer, and the security vendor. [cite_start]This holistic view of all the third parties and dependencies that contribute to a product is the definition of a supply chain assessment. [cite: 92]"
            },
            {
                "text": "Quantitative",
                "correct": false,
                "explain": "Incorrect. A quantitative assessment involves assigning monetary values to risk. The report contains qualitative information, not financial data."
            },
            {
                "text": "Organizational",
                "correct": false,
                "explain": "Incorrect. An organizational assessment would look at the overall security posture of the company, including policies and procedures, not just the components of a single product."
            }
        ]
    },
    {
        "id": 85,
        "q": "A security researcher tells a company that one of its solutions is vulnerable to buffer overflow, leading to a malicious coding execution. Which of the following is the best way to avoid this vulnerability in future versions?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Testing for CSRF vulnerabilities before the application goes to production",
                "correct": false,
                "explain": "Incorrect. Cross-Site Request Forgery (CSRF) is a different class of web vulnerability and testing for it would not find buffer overflows."
            },
            {
                "text": "Using SAST tools to find vulnerabilities as part of the pipeline",
                "correct": true,
                "explain": "Correct. Buffer overflows are a type of memory corruption vulnerability that can often be identified by analyzing the application's source code. Static Application Security Testing (SAST) tools are designed to scan source code for common vulnerabilities like buffer overflows. [cite_start]Integrating SAST into the CI/CD pipeline allows these issues to be found and fixed early in development, preventing them from reaching production. [cite: 240]"
            },
            {
                "text": "Implementing canary protection in an earlier life-cycle stage",
                "correct": false,
                "explain": "Incorrect. A canary is a value placed on the stack to detect a buffer overflow, and it's a runtime protection, not a vulnerability avoidance technique during development. Also, 'canary deployment' is a release strategy, which is different."
            },
            {
                "text": "Implementing pair programming to improve development capabilities",
                "correct": false,
                "explain": "Incorrect. While pair programming can improve code quality, it is a process control, not a technical tool. Relying on humans to catch all vulnerabilities is less effective than using automated tools like SAST."
            }
        ]
    },
    {
        "id": 86,
        "q": "Users are experiencing a variety of issues when trying to access corporate resources. Examples include: Connectivity issues between local computers and file servers between branch offices, Inability to download corporate applications on mobile endpoints while working remotely, Certificate errors when accessing internal web applications. Which of the following actions are the most relevant when troubleshooting the reported issues? (Choose two.)",
        "type": "multiple",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "Review VPN throughput.",
                "correct": true,
                "explain": "Correct. The issues describedpoor connectivity between sites, inability for remote users to access resourcesare classic symptoms of problems with a Wide Area Network (WAN) or a Virtual Private Network (VPN) that connects these locations and users. [cite_start]Checking the VPN throughput and for tunnel errors is a highly relevant troubleshooting step. [cite: 448]"
            },
            {
                "text": "Check IDS rules.",
                "correct": false,
                "explain": "Incorrect. An Intrusion Detection System (IDS) is a passive monitoring tool. Misconfigured rules would lead to false alerts or missed detections, not widespread connectivity and certificate errors."
            },
            {
                "text": "Restore static content on the CDN.",
                "correct": false,
                "explain": "Incorrect. A CDN serves public-facing content and is not typically involved in internal branch office connectivity or mobile VPN access to corporate apps."
            },
            {
                "text": "Enable secure authentication using NAC.",
                "correct": false,
                "explain": "Incorrect. While NAC is a relevant security control, the issues described are more indicative of a core network or certificate problem rather than an authentication failure at the NAC level."
            },
            {
                "text": "Implement advanced WAF rules.",
                "correct": false,
                "explain": "Incorrect. A Web Application Firewall (WAF) protects web applications from attacks. It would not cause general connectivity issues between branch offices or problems downloading non-web applications."
            },
            {
                "text": "Validate MDM asset compliance.",
                "correct": true,
                "explain": "Correct. Certificate errors on internal applications and the inability of mobile devices to access resources strongly point to a potential issue with certificate management or device compliance. A Mobile Device Management (MDM) solution often pushes certificates to devices and enforces compliance policies. [cite_start]If a device is non-compliant or its certificate is expired or invalid, it could be blocked from accessing resources, explaining the observed issues. [cite: 432, 433]"
            }
        ]
    },
    {
        "id": 87,
        "q": "A network engineer recorded the following test results: <br><br> <img src='../../assets/quiz-images/CAS-005_87_1.png' alt='Network test results before'> <br><br> After a new network security appliance was deployed, the results of the network test are as follows: <br><br> <img src='../../assets/quiz-images/CAS-005_87_2.png' alt='Network test results after'> <br><br> Which of the following network infrastructure components most likely produced these results?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "IPS",
                "correct": true,
                "explain": "Correct. The 'after' results show two key changes: a significant increase in latency for all allowed traffic, and one connection being actively dropped. This is characteristic of an inline Intrusion Prevention System (IPS). An IPS must inspect the content of every packet, which adds processing overhead and increases latency. [cite_start]It also has the ability to actively block or 'drop' traffic that matches a malicious signature, explaining why the connection to 192.168.1.68 was dropped. [cite: 223]"
            },
            {
                "text": "CDN",
                "correct": false,
                "explain": "Incorrect. A Content Delivery Network (CDN) is used to decrease latency for web content, not increase it. It also doesn't typically drop traffic in this manner."
            },
            {
                "text": "VPN",
                "correct": false,
                "explain": "Incorrect. While a VPN adds latency due to encryption, it wouldn't selectively drop traffic to one internal host while allowing others unless there was a specific access rule, which is less likely than a signature match on an IPS."
            },
            {
                "text": "IDS",
                "correct": false,
                "explain": "Incorrect. An Intrusion Detection System (IDS) is a passive device. It monitors traffic (often from a network tap) and generates alerts, but it cannot actively drop packets. The dropped connection rules out an IDS."
            }
        ]
    },
    {
        "id": 88,
        "q": "A developer needs to improve the cryptographic strength of a password-storage component in a web application without completely replacing the crypto-module. Which of the following is the most appropriate technique?",
        "type": "single",
        "category": "3.7 Explain the importance of advanced cryptographic concepts.",
        "answers": [
            {
                "text": "Key splitting",
                "correct": false,
                "explain": "Incorrect. Key splitting involves dividing a single cryptographic key into multiple parts and storing them separately. [cite_start]It is used for key protection, not for strengthening password hashing. [cite: 577]"
            },
            {
                "text": "Key escrow",
                "correct": false,
                "explain": "Incorrect. Key escrow is the storage of keys with a trusted third party for recovery purposes and is not related to password hashing strength."
            },
            {
                "text": "Key rotation",
                "correct": false,
                "explain": "Incorrect. Key rotation is the practice of periodically changing cryptographic keys. It is not a technique for strengthening password storage."
            },
            {
                "text": "Key encryption",
                "correct": false,
                "explain": "Incorrect. Encrypting a key with another key (envelope encryption) is a common practice, but it doesn't apply to the process of hashing passwords."
            },
            {
                "text": "Key stretching",
                "correct": true,
                "explain": "Correct. Key stretching is a technique used to make a potentially weak key, such as a user-generated password, more secure. It does this by feeding the password into a cryptographic function and repeating the process thousands of times. [cite_start]This makes brute-force attacks much slower and more computationally expensive, thereby improving the cryptographic strength of the stored password hashes without needing to replace the entire cryptographic module. [cite: 576]"
            }
        ]
    },
    {
        "id": 89,
        "q": "A company wants to implement hardware security key authentication for accessing sensitive information systems. The goal is to prevent unauthorized users from gaining access with a stolen password. Which of the following models should the company implement to best solve this issue?",
        "type": "single",
        "category": "2.6 Given a scenario, integrate Zero Trust concepts into system architecture design.",
        "answers": [
            {
                "text": "Rule-based",
                "correct": false,
                "explain": "Incorrect. Rule-based access control uses simple if-then rules (e.g., if user is in group X, allow access). It doesn't inherently incorporate dynamic context like the presence of a hardware key."
            },
            {
                "text": "Time-based",
                "correct": false,
                "explain": "Incorrect. Time-based access control restricts access to certain times of day. While useful, it doesn't solve the core issue of a stolen password being used."
            },
            {
                "text": "Role-based",
                "correct": false,
                "explain": "Incorrect. Role-based access control grants permissions based on a user's job role. It doesn't prevent an attacker with a stolen password from assuming that role."
            },
            {
                "text": "Context-based",
                "correct": true,
                "explain": "Correct. Context-based reauthentication is a core concept of Zero Trust. This model evaluates multiple contextual factors before granting access, not just a password. These factors can include the user's location, device posture, time of day, and, crucially, the presence and successful authentication of a hardware security key. [cite_start]This directly prevents a stolen password from being sufficient for access. [cite: 353]"
            }
        ]
    },
    {
        "id": 90,
        "q": "Which of the following is the main reason quantum computing advancements are leading companies and countries to deploy new encryption algorithms?",
        "type": "single",
        "category": "3.7 Explain the importance of advanced cryptographic concepts.",
        "answers": [
            {
                "text": "Encryption systems based on large prime numbers will be vulnerable to exploitation.",
                "correct": true,
                "explain": "Correct. Much of today's widely used public-key cryptography, including RSA and Elliptic Curve Cryptography (ECC), relies on the mathematical difficulty of factoring large prime numbers. A sufficiently powerful quantum computer, using algorithms like Shor's algorithm, could solve these problems in a feasible amount of time, rendering these encryption systems insecure. [cite_start]This is the primary driver for the development and deployment of Post-Quantum Cryptography (PQC). [cite: 570, 571, 572, 574]"
            },
            {
                "text": "Zero Trust security architectures will require homomorphic encryption.",
                "correct": false,
                "explain": "Incorrect. While homomorphic encryption is an advanced cryptographic concept, it is not a general requirement for Zero Trust architecture, and the threat from quantum computing is a more fundamental driver for change."
            },
            {
                "text": "Perfect forward secrecy will prevent deployment of advanced firewall monitoring techniques.",
                "correct": false,
                "explain": "Incorrect. Perfect Forward Secrecy (PFS) is a feature of some key exchange protocols that protects past sessions from future key compromises. This is unrelated to the threat posed by quantum computers."
            },
            {
                "text": "Quantum computers will enable malicious actors to capture IP traffic in real time.",
                "correct": false,
                "explain": "Incorrect. Capturing IP traffic can be done today with standard technology. The threat from quantum computers is not in capturing the traffic, but in decrypting it."
            }
        ]
    },
    {
        "id": 91,
        "q": "A company is adopting microservice architecture in order to quickly remediate vulnerabilities and deploy to production. All of the microservices run on the same Linux platform. Significant time was spent updating the base OS before deploying code. Which of the following should the company do to make the process efficient?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Use Terraform scripts while creating golden images.",
                "correct": true,
                "explain": "Correct. A 'golden image' is a pre-configured, patched, and hardened template of an operating system or application. Instead of updating each new instance from scratch, the company can create a golden image of their Linux platform that already has all the latest updates and security configurations. Tools like Terraform can be used to automate the creation of these images (Infrastructure as Code). [cite_start]When a new microservice needs to be deployed, it starts from this already-updated golden image, making the process highly efficient and consistent. [cite: 693]"
            },
            {
                "text": "Create a cron job to run apt-update every 30 days.",
                "correct": false,
                "explain": "Incorrect. This is inefficient as it still requires each instance to be updated individually after it has been deployed. It also doesn't guarantee a consistent state at deployment time."
            },
            {
                "text": "Use snapshots to deploy code to existing compute instances.",
                "correct": false,
                "explain": "Incorrect. Snapshots are point-in-time backups of a disk. While they can be used for deployment, the concept of a standardized, reusable 'golden image' is the more appropriate and efficient solution for this scenario."
            },
            {
                "text": "Deploy a centralized update server.",
                "correct": false,
                "explain": "Incorrect. A centralized update server helps manage patching but doesn't solve the inefficiency of having to patch every new instance after it's been created. The golden image approach pre-patches the template itself."
            }
        ]
    },
    {
        "id": 92,
        "q": "During a gap assessment, an organization notes that BYOD usage is a significant risk. The organization implemented administrative policies prohibiting BYOD usage. However, the organization has not implemented technical controls to prevent the unauthorized use of BYOD assets when accessing the organization's resources. Which of the following solutions should the organization implement to best reduce the risk of BYOD devices? (Choose two.)",
        "type": "multiple",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Cloud IAM, to enforce the use of token-based MFA",
                "correct": false,
                "explain": "Incorrect. While MFA is a good control, it verifies the user, not the device. An attacker could still satisfy MFA on a personal, non-compliant device."
            },
            {
                "text": "Conditional access, to enforce user-to-device binding",
                "correct": true,
                "explain": "Correct. Conditional access policies are a powerful technical control that can evaluate the context of an access request. A policy can be created to require user-to-device binding, which means access is only granted if the authenticated user is coming from a known, corporate-managed, and compliant device. [cite_start]This directly prevents BYOD access. [cite: 391]"
            },
            {
                "text": "NAC, to enforce device configuration requirements",
                "correct": true,
                "explain": "Correct. Network Access Control (NAC) solutions can perform device posture assessments before granting network access. The NAC can check if a device is corporate-owned (e.g., by checking for a machine certificate) and meets specific configuration requirements. [cite_start]If the device is identified as a personal BYOD asset, the NAC can block it from accessing the network. [cite: 225]"
            },
            {
                "text": "PAM, to enforce local password policies",
                "correct": false,
                "explain": "Incorrect. Privileged Access Management (PAM) is for controlling administrative accounts, not for differentiating between corporate and BYOD endpoints for standard users."
            },
            {
                "text": "SD-WAN, to enforce web content filtering through external proxies",
                "correct": false,
                "explain": "Incorrect. SD-WAN and web filtering control what users can access on the internet; they do not control which devices can access the corporate network."
            },
            {
                "text": "DLP, to enforce data protection capabilities",
                "correct": false,
                "explain": "Incorrect. Data Loss Prevention (DLP) controls what happens to data, but it doesn't control which devices are allowed to connect in the first place."
            }
        ]
    },
    {
        "id": 93,
        "q": "An organization has several systems deployed in a public cloud and wants to confirm that when data retention periods are reached, the data is properly disposed of. Which of the following best meets the organization's needs?",
        "type": "single",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "Double encrypting the data using both asymmetric and symmetric keys managed by the cloud service provider",
                "correct": false,
                "explain": "Incorrect. The method of encryption doesn't guarantee disposal. If the keys are managed by the CSP, the customer has no control over their destruction."
            },
            {
                "text": "Utilizing a data-wiping software to overwrite the existing data",
                "correct": false,
                "explain": "Incorrect. In a cloud environment, customers do not have low-level access to the physical storage hardware, so they cannot run data-wiping software."
            },
            {
                "text": "Encrypting the data with customer-managed keys and then deleting both the encryption key and the volume",
                "correct": true,
                "explain": "Correct. This is the principle of crypto-shredding in the cloud. By encrypting the cloud storage volume with a key that the customer controls (a customer-managed key, or CMK), the data is protected. When the retention period is reached, the customer can delete the volume and, more importantly, securely delete the encryption key. [cite_start]Once the key is gone, the encrypted data becomes permanently unrecoverable, effectively and instantly disposing of it. [cite: 337, 342]"
            },
            {
                "text": "Asking the cloud provider for copies of certificates of destruction",
                "correct": false,
                "explain": "Incorrect. Cloud providers manage storage for thousands of customers on shared physical hardware. They cannot provide a certificate of destruction for a specific customer's logically deleted data volume."
            }
        ]
    },
    {
        "id": 94,
        "q": "A security engineer reviews an after-action report from a previous security breach and notes a long lag time between detection and containment of a compromised account. The engineer suggests using SOAR to address this concern. Which of the following best explains the engineer's goal?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "To prevent accounts from being compromised",
                "correct": false,
                "explain": "Incorrect. SOAR is a response technology. It acts after a potential compromise has been detected, it does not prevent the initial compromise."
            },
            {
                "text": "To enable log correlation using machine learning",
                "correct": false,
                "explain": "Incorrect. Log correlation and machine learning are primary functions of a SIEM or UEBA platform, which would feed alerts into a SOAR."
            },
            {
                "text": "To orchestrate additional reporting for the security operations center",
                "correct": false,
                "explain": "Incorrect. While SOAR platforms can generate reports, their main purpose is to automate actions, not just reporting."
            },
            {
                "text": "To prepare runbooks to automate future incident response",
                "correct": true,
                "explain": "Correct. A key feature of Security Orchestration, Automation, and Response (SOAR) platforms is the use of playbooks or runbooks. These are predefined, automated workflows that execute a series of response actions when a specific type of alert is received. For a compromised account, a runbook could automatically enrich the alert with user data, query other systems for related activity, and then take a containment action like disabling the account or forcing a password reset. [cite_start]This automation directly addresses the goal of reducing the time between detection and containment. [cite: 555]"
            }
        ]
    },
    {
        "id": 95,
        "q": "During an audit at an organization, auditors find that developers are able to promote code to production. The auditors request a full review of all production changes. Which of the following should the organization implement to prevent a full review in the future?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Branch protection",
                "correct": false,
                "explain": "Incorrect. Branch protection is a technical control within a code repository to prevent direct commits to a main branch, but the ultimate approval for merging and deploying should come from a formal change management process."
            },
            {
                "text": "Centralized code repositories",
                "correct": false,
                "explain": "Incorrect. Having a centralized repository is good practice, but it does not in itself provide the governance and oversight required by auditors."
            },
            {
                "text": "Interactive application security testing",
                "correct": false,
                "explain": "Incorrect. IAST is a security testing tool. It does not address the procedural and governance failure of developers promoting their own code."
            },
            {
                "text": "Change control board",
                "correct": true,
                "explain": "Correct. The audit finding points to a lack of separation of duties and formal oversight in the change management process. A Change Control Board (CCB), also known as a Change Advisory Board, is a formal group of people responsible for reviewing, evaluating, approving, delaying, or rejecting changes to a system. Implementing a CCB introduces the necessary governance and ensures that all production changes are formally reviewed and approved, which would satisfy the auditors."
            }
        ]
    },
    {
        "id": 96,
        "q": "A systems engineer is configuring SSO for a business that will be using SaaS applications for its remote-only workforce. Privileged actions in SaaS applications must be allowed only from corporate mobile devices that meet minimum security requirements, but BYOD must also be permitted for other activity. Which of the following would best meet this objective?",
        "type": "single",
        "category": "2.6 Given a scenario, integrate Zero Trust concepts into system architecture design.",
        "answers": [
            {
                "text": "Block any connections from outside the business's network security boundary.",
                "correct": false,
                "explain": "Incorrect. The workforce is remote-only, so there is no traditional network boundary to enforce."
            },
            {
                "text": "Install machine certificates on corporate devices and perform checks against the clients.",
                "correct": false,
                "explain": "Incorrect. While machine certificates are a good way to identify corporate devices, this answer is incomplete. It doesn't describe the policy engine that would use this information to make an access decision."
            },
            {
                "text": "Configure device attestations and continuous authorization controls.",
                "correct": true,
                "explain": "Correct. This scenario requires a sophisticated, context-aware access control system aligned with Zero Trust principles. Device attestation verifies the identity and security posture (health) of the device at the time of access. Continuous authorization checks this context not just at login, but throughout the session. This combination allows the system to create a policy that says, 'Allow login from any device, but only permit privileged actions if the device attests to being a corporate, compliant machine.' [cite_start]This meets all requirements. [cite: 352, 361]"
            },
            {
                "text": "Deploy application protection policies using a corporate, cloud-based MDM solution.",
                "correct": false,
                "explain": "Incorrect. While MDM and application protection policies are part of the solution for managing the devices, the core of the access decision logic lies within the conditional access system that uses device attestation and continuous authorization."
            }
        ]
    },
    {
        "id": 97,
        "q": "A systems administrator wants to reduce the number of failed patch deployments in an organization. The administrator discovers that system owners modify systems or applications in an ad hoc manner. Which of the following is the best way to reduce the number of failed patch deployments?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "Compliance tracking",
                "correct": false,
                "explain": "Incorrect. Compliance tracking would report on the failures but wouldn't prevent the unauthorized changes that are causing them."
            },
            {
                "text": "Situational awareness",
                "correct": false,
                "explain": "Incorrect. Situational awareness is a broad concept about understanding the environment. A formal change management process is the specific control needed here."
            },
            {
                "text": "Change management",
                "correct": true,
                "explain": "Correct. The root cause of the failed patch deployments is 'configuration drift' caused by system owners making ad hoc, undocumented changes. A formal change management process requires that all modifications to production systems are documented, reviewed, and approved before being implemented. [cite_start]This prevents unauthorized changes and ensures that the state of the system is known and consistent, which dramatically increases the success rate of patch deployments. [cite: 68]"
            },
            {
                "text": "Quality assurance",
                "correct": false,
                "explain": "Incorrect. Quality Assurance (QA) is a process for testing changes before deployment. While important, it doesn't solve the problem of unauthorized changes being made outside of the formal process."
            }
        ]
    },
    {
        "id": 98,
        "q": "A network engineer must ensure that always-on VPN access is enabled but restricted to company assets. Which of the following best describes what the engineer needs to do?",
        "type": "single",
        "category": "2.4 Given a scenario, apply security concepts to the design of access, authentication, and authorization systems.",
        "answers": [
            {
                "text": "Generate device certificates using the specific template settings needed.",
                "correct": true,
                "explain": "Correct. To restrict VPN access to company assets only, a device-based authentication method is required. The most common and secure way to achieve this is by issuing a unique digital certificate to each corporate device from an internal Public Key Infrastructure (PKI). The VPN gateway can then be configured to only allow connections from clients that present a valid certificate issued by the company's CA. [cite_start]This requires creating and using a specific certificate template with the correct properties (e.g., key usage for client authentication). [cite: 306, 311]"
            },
            {
                "text": "Modify signing certificates in order to support IKE version 2.",
                "correct": false,
                "explain": "Incorrect. The choice of IKE version is a protocol setting, not something controlled by the certificate itself."
            },
            {
                "text": "Create a wildcard certificate for connections from public networks.",
                "correct": false,
                "explain": "Incorrect. Wildcard certificates are for servers (to cover multiple subdomains) and are not used for authenticating client devices."
            },
            {
                "text": "Add the VPN hostname as a SAN entry on the root certificate.",
                "correct": false,
                "explain": "Incorrect. Modifying a root CA certificate is extremely risky and incorrect. The VPN hostname should be in the VPN server's certificate, not the root, and this is related to authenticating the server, not the client devices."
            }
        ]
    },
    {
        "id": 99,
        "q": "A security administrator is reviewing the following code snippet from a website component: <br><br> <img src='../../assets/quiz-images/CAS-005_99.png' alt='Obfuscated PHP code snippet'> <br><br> A review of the inc.tmp file shows the following: `214875925793253420385093450834534324525234352353455234532423534245234534523453896276563857932578395378543620382630532804508325` <br><br> Which of the following is most likely the reason for this activity?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "A content management solution plug-in has been exploited.",
                "correct": true,
                "explain": "Correct. The code snippet shows several indicators of a malicious webshell injected via a compromised plugin. The use of `is_admin()`, the `add_action('wp-head', ...)` function call (which is specific to WordPress), and the obfuscated code (`hex2bin('3c?....')`) that reads from a temporary file are all classic signs of a compromised WordPress plugin being used to maintain persistence and execute malicious code."
            },
            {
                "text": "A search engine's bots are being blocked at the firewall.",
                "correct": false,
                "explain": "Incorrect. This code is executing on the server and is indicative of a compromise, not a network block of search engine bots."
            },
            {
                "text": "The relevant stylesheet has become corrupted.",
                "correct": false,
                "explain": "Incorrect. While the code references `stylesheet`, this is likely a misdirection. The core of the code is the malicious, obfuscated function, not a corrupted CSS file."
            },
            {
                "text": "The WAF is configured to be in transparent mode.",
                "correct": false,
                "explain": "Incorrect. The mode of the WAF is irrelevant; the issue is that malicious code is present and executing on the server itself."
            }
        ]
    },
    {
        "id": 100,
        "q": "An organization wants to implement a platform to better identify which specific assets are affected by a given vulnerability. Which of the following components provides the best foundation to achieve this goal?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "SASE",
                "correct": false,
                "explain": "Incorrect. SASE (Secure Access Service Edge) is a network security architecture and does not serve as a central asset inventory."
            },
            {
                "text": "CMDB",
                "correct": true,
                "explain": "Correct. A Configuration Management Database (CMDB) is a centralized repository that stores information about an organization's hardware and software assets and the relationships between them. To identify which assets are affected by a vulnerability (e.g., a vulnerability in Apache), you first need a reliable, up-to-date inventory of all assets running that software. [cite_start]The CMDB provides this foundational inventory. [cite: 70]"
            },
            {
                "text": "SBoM",
                "correct": false,
                "explain": "Incorrect. A Software Bill of Materials (SBoM) is a list of components in a single piece of software. While useful, a CMDB is the broader platform for tracking all assets across the enterprise."
            },
            {
                "text": "SIEM",
                "correct": false,
                "explain": "Incorrect. A SIEM (Security Information and Event Management) system collects and analyzes log data. While it may be enriched with asset data from a CMDB, it is not the source of truth for the asset inventory itself."
            }
        ]
    },
    {
        "id": 101,
        "q": "Which of the following best explains why AI output could be inaccurate?",
        "type": "single",
        "category": "1.5 Summarize the information security challenges associated with artificial intelligence (AI) adoption.",
        "answers": [
            {
                "text": "Model poisoning",
                "correct": true,
                "explain": "Correct. Training data poisoning is an attack where malicious data is secretly introduced into the AI model's training set. This corrupts the model's learning process, causing it to produce inaccurate, biased, or otherwise incorrect outputs. This is a fundamental threat to the integrity of the AI model itself."
            },
            {
                "text": "Social engineering",
                "correct": false,
                "explain": "Incorrect. Social engineering attacks target humans to manipulate them into divulging information or performing actions, not the AI model directly."
            },
            {
                "text": "Output handling",
                "correct": false,
                "explain": "Incorrect. Insecure output handling is a vulnerability where the application doesn't properly sanitize the AI's output, potentially leading to issues like Cross-Site Scripting (XSS). It doesn't cause the AI's initial output to be inaccurate."
            },
            {
                "text": "Prompt injections",
                "correct": false,
                "explain": "Incorrect. Prompt injection involves tricking an AI into ignoring its intended instructions for a single request. While it leads to an inaccurate response for that query, data poisoning corrupts the entire underlying model, causing systemic inaccuracies."
            }
        ]
    },
    {
        "id": 102,
        "q": "A company runs a DAST scan on a web application. The tool outputs the following recommendations: Use Cookie prefixes. Content Security Policy - SameSite=strict is not set. Which of the following vulnerabilities has the tool identified?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "RCE",
                "correct": false,
                "explain": "Incorrect. Remote Code Execution (RCE) vulnerabilities are not mitigated by cookie attributes like SameSite."
            },
            {
                "text": "XSS",
                "correct": false,
                "explain": "Incorrect. While the HttpOnly cookie attribute helps mitigate XSS, the SameSite attribute is the primary defense against CSRF."
            },
            {
                "text": "CSRF",
                "correct": true,
                "explain": "Correct. The 'SameSite' cookie attribute is a browser security mechanism specifically designed to prevent Cross-Site Request Forgery (CSRF) attacks. CSRF tricks a victim's browser into making an unintended request to a site where they are authenticated. Setting `SameSite=strict` prevents the browser from sending the session cookie with any cross-site request, thus defeating the attack."
            },
            {
                "text": "TOCTOU",
                "correct": false,
                "explain": "Incorrect. Time-of-Check, Time-of-Use (TOCTOU) is a class of race condition vulnerabilities and is unrelated to cookie security settings."
            }
        ]
    },
    {
        "id": 103,
        "q": "Which of the following best describes the reason a network architect would enable forward secrecy on all VPN tunnels?",
        "type": "single",
        "category": "3.7 Explain the importance of advanced cryptographic concepts.",
        "answers": [
            {
                "text": "This process is a requirement to enable hardware-accelerated cryptography.",
                "correct": false,
                "explain": "Incorrect. Forward secrecy and hardware acceleration are independent concepts. You can have one without the other."
            },
            {
                "text": "This process reduces the success of attackers performing cryptanalysis.",
                "correct": true,
                "explain": "Correct. Forward Secrecy, also known as Perfect Forward Secrecy (PFS), ensures that each VPN session uses a unique, ephemeral session key that is destroyed after the session ends. This means that even if an attacker compromises the VPN server's long-term private key in the future, they cannot use it to go back and decrypt previously recorded VPN traffic. This significantly reduces the value of long-term traffic capture and cryptanalysis."
            },
            {
                "text": "The business requirements state that confidentiality is a critical success factor.",
                "correct": false,
                "explain": "Incorrect. This is too generic. All encryption provides confidentiality. Forward secrecy provides a specific enhancement to confidentiality by protecting past sessions from future key compromises."
            },
            {
                "text": "Modern cryptographic protocols list this process as a prerequisite for use.",
                "correct": false,
                "explain": "Incorrect. While highly recommended and supported by modern protocols like TLS 1.3, it is not a universal prerequisite for all VPN protocols."
            }
        ]
    },
    {
        "id": 104,
        "q": "Which of the following best explains the importance of determining organizational risk appetite when operating with a constrained budget?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Risk appetite directly impacts acceptance of high-impact, low-likelihood events.",
                "correct": true,
                "explain": "Correct. Risk appetite is the amount and type of risk that an organization is willing to pursue or retain. With a constrained budget, an organization cannot afford to mitigate every single risk. Determining the risk appetite helps leadership make informed decisions about which risks to spend limited resources on mitigating, which risks to transfer (e.g., via insurance), and which risks are acceptable to live with, especially those that are high-impact but have a very low likelihood of occurring."
            },
            {
                "text": "Organizational risk appetite varies from organization to organization.",
                "correct": false,
                "explain": "Incorrect. While true, this statement does not explain the importance of determining it in the context of a constrained budget."
            },
            {
                "text": "Budgetary pressure drives risk mitigation planning in all companies.",
                "correct": false,
                "explain": "Incorrect. While a factor, the budget doesn't drive the planning itself; the risk appetite guides how the budget is allocated within the plan."
            },
            {
                "text": "Risk appetite directly influences which breaches are disclosed publicly.",
                "correct": false,
                "explain": "Incorrect. Breach disclosure is typically governed by legal and regulatory requirements, not by the organization's risk appetite."
            }
        ]
    },
    {
        "id": 105,
        "q": "A company hired an email service provider called my-email.com to deliver company emails. The company started having several issues during the migration. A security engineer is troubleshooting and observes the following configuration snippet: <br><br> <img src='../../assets/quiz-images/CAS-005_105.png' alt='DNS record configuration'> <br><br> Which of the following should the security engineer modify to fix the issue? (Choose two.)",
        "type": "multiple",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "The email CNAME record must be changed to a type A record pointing to 192.168.1.11",
                "correct": false,
                "explain": "Incorrect. Pointing the email CNAME to the web server's IP address is incorrect."
            },
            {
                "text": "The TXT record must be changed to \"v=dmarc ip4:192.168.1.10 include:my-email.com ~all\"",
                "correct": false,
                "explain": "Incorrect. DMARC records do not use 'ip4' or 'include' tags in this manner. This syntax is for SPF."
            },
            {
                "text": "The srv01 A record must be changed to a type CNAME record pointing to the email server",
                "correct": false,
                "explain": "Incorrect. An A record must point to an IP address. Changing it to a CNAME would be syntactically incorrect in this context."
            },
            {
                "text": "The email CNAME record must be changed to a type A record pointing to 192.168.1.10",
                "correct": false,
                "explain": "Incorrect. The MX record already points to `email.company.com`. While an MX record should not point to a CNAME, the more fundamental issue is the authentication records."
            },
            {
                "text": "The TXT record must be changed to \"v=dkim ip4:192.168.1.11 include:my-email.com ~all\"",
                "correct": false,
                "explain": "Incorrect. This mixes syntax from SPF and DKIM. A DKIM record contains a public key, not IP addresses."
            },
            {
                "text": "The TXT record must be changed to \"v=spf ip4:192.168.1.10 include:my-email.com ~all\"",
                "correct": true,
                "explain": "Correct. The current TXT record is for DMARC but is syntactically flawed. To authorize the third-party email provider, a Sender Policy Framework (SPF) record is needed. The correct SPF record (`v=spf...`) should include the company's own sending IP (`ip4:192.168.1.10`) and, critically, `include:my-email.com` to authorize the third-party provider to send email on their behalf."
            },
            {
                "text": "The srv01 A record must be changed to a type CNAME record pointing to the web01 server",
                "correct": false,
                "explain": "Incorrect. Pointing the mail server's record to the web server is incorrect."
            }
        ]
    },
    {
        "id": 106,
        "q": "After a company discovered a zero-day vulnerability in its VPN solution, the company plans to deploy cloud-hosted resources to replace its current on-premises systems. An engineer must find an appropriate solution to facilitate trusted connectivity. Which of the following capabilities is the most relevant?",
        "type": "single",
        "category": "2.6 Given a scenario, integrate Zero Trust concepts into system architecture design.",
        "answers": [
            {
                "text": "Container orchestration",
                "correct": false,
                "explain": "Incorrect. Container orchestration manages the deployment of containers; it is not a network connectivity solution."
            },
            {
                "text": "Microsegmentation",
                "correct": false,
                "explain": "Incorrect. Microsegmentation is a network security technique for isolating workloads from each other. While part of a modern security architecture, it doesn't provide the core connectivity from users to resources."
            },
            {
                "text": "Conditional access",
                "correct": false,
                "explain": "Incorrect. Conditional access is an authorization policy engine that grants or denies access based on context. It is a component within a larger solution, not the connectivity solution itself."
            },
            {
                "text": "Secure access service edge",
                "correct": true,
                "explain": "Correct. Secure Access Service Edge (SASE) is a modern network architecture that converges networking (like SD-WAN) and cloud-native security functions (like Zero Trust Network Access, CASB, FWaaS) into a single, unified service. It is designed specifically to provide secure, trusted connectivity for distributed users and devices to cloud-hosted resources, making it the perfect replacement for a traditional VPN in this scenario."
            }
        ]
    },
    {
        "id": 107,
        "q": "Recent reports indicate that a software tool is being exploited. Attackers were able to bypass user access controls and load a database. A security analyst needs to find the vulnerability and recommend a mitigation. The analyst generates the following output: <br><br> <img src='../../assets/quiz-images/CAS-005_107.png' alt='Command line output showing credential discovery'> <br><br> Which of the following would the analyst most likely recommend?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Installing appropriate EDR tools to block pass-the-hash attempts",
                "correct": false,
                "explain": "Incorrect. The attack shown does not involve passing a hash; it involves using a cleartext password found in the binary."
            },
            {
                "text": "Adding additional time to software development to perform fuzz testing",
                "correct": false,
                "explain": "Incorrect. While fuzz testing is a valuable security practice, the specific vulnerability here is a hard-coded credential, which is better found through static analysis or manual review."
            },
            {
                "text": "Removing hard-coded credentials from the source code",
                "correct": true,
                "explain": "Correct. The analyst uses the `strings` command on the `dbloader.exe` binary and discovers a cleartext password (`dB10ad3r!`). The analyst then successfully uses this password with the 'admin' account to load the database. This is a classic example of a hard-coded credential vulnerability. The proper mitigation is to remove these credentials from the source code and use a secure method for secret management."
            },
            {
                "text": "Not allowing users to change their local passwords",
                "correct": false,
                "explain": "Incorrect. This recommendation is irrelevant to the vulnerability, which is within the application's code, not the user's local account."
            }
        ]
    },
    {
        "id": 108,
        "q": "The identity and access management team is sending logs to the SIEM for continuous monitoring. The deployed log collector is forwarding logs to the SIEM. However, only false positive alerts are being generated. Which of the following is the most likely reason for the inaccurate alerts?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "The compute resources are insufficient to support the SIEM.",
                "correct": false,
                "explain": "Incorrect. Insufficient resources would likely lead to dropped logs and missed alerts (false negatives), not inaccurate alerts (false positives)."
            },
            {
                "text": "The SIEM indexes are too large.",
                "correct": false,
                "explain": "Incorrect. Large indexes might slow down search performance but would not inherently cause false positive alerts."
            },
            {
                "text": "The data is not being properly parsed.",
                "correct": true,
                "explain": "Correct. A SIEM relies on parsers to correctly identify and extract specific fields (like username, source IP, event ID) from raw log messages. If the log format from the IAM system is not correctly understood by the SIEM's parser, the SIEM will misinterpret the data. This leads to correlation rules firing on incorrect information, generating a high volume of false positive alerts."
            },
            {
                "text": "The retention policy is not properly configured.",
                "correct": false,
                "explain": "Incorrect. The retention policy determines how long logs are stored. It does not affect the real-time parsing and alerting process."
            }
        ]
    },
    {
        "id": 109,
        "q": "The security team is receiving escalated support tickets stating that one of the company's publicly available websites is not loading as expected. Given the following observations: <br><br> <img src='../../assets/quiz-images/CAS-005_109.png' alt='Web server certificate status'> <br><br> Which of the following is most likely the root cause?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "A certificate signed by a global root certification authority has expired.",
                "correct": true,
                "explain": "Correct. The log shows that the certificate for `www.website.com` on server WEB27 is 418 days old. Most public SSL/TLS certificates have a validity period of one year (365 days). A certificate that is 418 days old is expired. Modern web browsers will block connections to sites with expired certificates, causing the site to not load as expected, which matches the user reports."
            },
            {
                "text": "A protocol mismatch error is expected to occur when using outdated browsers.",
                "correct": false,
                "explain": "Incorrect. The issue is with the certificate's age, not a protocol mismatch. This would affect all browsers, not just outdated ones."
            },
            {
                "text": "One certificate is being bound to multiple websites on the same server.",
                "correct": false,
                "explain": "Incorrect. The SALES10 server is using a wildcard certificate (*.sales.com) which is designed to be used for multiple subdomains on one or more servers. This is a valid configuration."
            },
            {
                "text": "Subject alternative names were not used appropriately for subdomains.",
                "correct": false,
                "explain": "Incorrect. This could be a problem, but the most direct and obvious issue in the provided data is the expired certificate on WEB27."
            }
        ]
    },
    {
        "id": 110,
        "q": "A company acquires a location with a large infrastructure of legacy devices. Because of the hardware's age and the legacy software's limitations, the OS cannot be upgraded, and the machines cannot be virtualized. These machines are not publicly facing, but they do have internet access. The following controls are currently in place: EDR, Anti-malware, Logging and monitoring, Host-based firewall, Proxied internet access. A security architect needs to supplement the existing control strategy with one that restricts unauthorized software. Which of the following controls should the architect recommend to best supplement the existing environment?",
        "type": "single",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "SIEM",
                "correct": false,
                "explain": "Incorrect. A SIEM is for log aggregation and alerting; it does not restrict software execution."
            },
            {
                "text": "Isolation",
                "correct": false,
                "explain": "Incorrect. While isolating these legacy systems is a good idea, the question specifically asks for a control to restrict unauthorized software from running."
            },
            {
                "text": "Conditional access",
                "correct": false,
                "explain": "Incorrect. Conditional access policies control user access to applications and resources based on context; they do not control which software is allowed to execute on an endpoint."
            },
            {
                "text": "Application control",
                "correct": true,
                "explain": "Correct. Application control (also known as application allowlisting or whitelisting) is a security approach that restricts which applications are permitted to run on a system. In this scenario, the architect would create a list of the specific, authorized legacy applications. The application control solution would then block any other executable from running, effectively preventing unauthorized software from being installed or executed on these vulnerable legacy systems."
            }
        ]
    },
    {
        "id": 111,
        "q": "An organization wants to create a threat model to identify vulnerabilities in its infrastructure. Which of the following should be prioritized first?",
        "type": "single",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "External-facing infrastructure with known exploited vulnerabilities",
                "correct": true,
                "explain": "Correct. When prioritizing threat modeling and remediation, the highest risk is typically associated with systems that have three characteristics: 1) They are exposed to the internet (external-facing), making them accessible to a wide range of attackers. 2) They have known vulnerabilities. 3) There are active exploits for those vulnerabilities in the wild. This combination represents a clear and present danger and should always be the top priority."
            },
            {
                "text": "Internal infrastructure with high-severity and known exploited vulnerabilities",
                "correct": false,
                "explain": "Incorrect. While high risk, an attacker would first need to breach the perimeter to exploit these vulnerabilities, making them a slightly lower priority than already-exposed external systems."
            },
            {
                "text": "External-facing infrastructure with a low risk score and no known exploited vulnerabilities",
                "correct": false,
                "explain": "Incorrect. A low risk score and lack of known exploits make this a much lower priority."
            },
            {
                "text": "External-facing infrastructure with a high risk score that can only be exploited with local access to the resource",
                "correct": false,
                "explain": "Incorrect. If an exploit requires local access, the risk from external attackers is significantly reduced, making this a lower priority than a remotely exploitable vulnerability."
            }
        ]
    },
    {
        "id": 112,
        "q": "A Chief Information Security Officer requests an action plan to remediate vulnerabilities. A security analyst reviews the output from a recent vulnerability scan and notices hundreds of unique vulnerabilities. The output includes the CVSS score, IP address, hostname, and the list of vulnerabilities. The analyst determines more information is needed in order to decide which vulnerabilities should be fixed immediately. Which of the following is the best source for this information?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Third-party risk review",
                "correct": false,
                "explain": "Incorrect. A third-party risk review assesses vendors and is not relevant for prioritizing vulnerabilities on internal systems."
            },
            {
                "text": "Business impact analysis",
                "correct": true,
                "explain": "Correct. A vulnerability's technical severity (like a CVSS score) is only one part of the risk equation. To truly prioritize remediation, the analyst needs to understand the business context and criticality of the affected asset. A Business Impact Analysis (BIA) provides this information. It identifies the organization's most critical processes and the systems that support them. By correlating the vulnerability data with the BIA, the analyst can prioritize fixing a medium-severity vulnerability on a critical production server over a critical vulnerability on a non-essential development machine."
            },
            {
                "text": "Incident response playbook",
                "correct": false,
                "explain": "Incorrect. An incident response playbook details the steps to take after an incident has occurred; it is not used for proactive vulnerability prioritization."
            },
            {
                "text": "Crisis management plan",
                "correct": false,
                "explain": "Incorrect. A crisis management plan deals with high-level coordination and communication during a major disaster, not the prioritization of routine vulnerability remediation."
            }
        ]
    },
    {
        "id": 113,
        "q": "A security operations analyst is reviewing network traffic baselines for nightly database backups. Given the following information: <br><br> <img src='../../assets/quiz-images/CAS-005_113.png' alt='Network traffic logs'> <br><br> Which of the following should the security analyst do next?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "Consult with a network engineer to determine the impact of bandwidth usage.",
                "correct": false,
                "explain": "Incorrect. The bandwidth usage is a symptom, not the core problem. The problem is the destination of the traffic."
            },
            {
                "text": "Quarantine PRDDB01 and then alert the database engineers.",
                "correct": false,
                "explain": "Incorrect. While quarantining the server might be a future step, the immediate next action should be to follow the established procedure for a potential incident."
            },
            {
                "text": "Refer to the incident response playbook for the proper response.",
                "correct": true,
                "explain": "Correct. The logs show a significant anomaly on 12/3. At 12:46 a.m., a very large amount of data (97.00GB, compared to the baseline of ~11GB) was transferred from the production database server (PRDDB01) to an unknown, external IP address (85.34.17.98) instead of the normal backup server (BACKUP01). This is a strong indicator of a data exfiltration incident. The analyst should immediately refer to the incident response playbook to follow the formally approved procedures for handling such an event."
            },
            {
                "text": "Review all the network logs for further data exfiltration.",
                "correct": false,
                "explain": "Incorrect. While reviewing logs is part of the investigation, the first step is to declare an incident and follow the response plan, which will guide the investigation in a structured way."
            }
        ]
    },
    {
        "id": 114,
        "q": "A company has a requirement in customer contracts that states applications must undergo external audits to identify vulnerabilities. Which of the following is the best action for the company to complete before hiring an external auditor?",
        "type": "single",
        "category": "1.3 Explain how compliance affects information security strategies.",
        "answers": [
            {
                "text": "Gather evidence for the audit.",
                "correct": false,
                "explain": "Incorrect. Gathering evidence happens during the audit, not before hiring the auditor."
            },
            {
                "text": "Conduct an internal audit assessment.",
                "correct": true,
                "explain": "Correct. Before bringing in expensive external auditors, it is a best practice to conduct an internal audit or a self-assessment first. This allows the company to proactively identify and remediate any obvious issues or 'low-hanging fruit.' This makes the external audit process smoother, more efficient, and more likely to result in a favorable outcome."
            },
            {
                "text": "Identify lessons learned from the audit.",
                "correct": false,
                "explain": "Incorrect. Lessons learned are identified *after* the audit is complete."
            },
            {
                "text": "Select samples for audit testing.",
                "correct": false,
                "explain": "Incorrect. The auditor, not the company, typically determines the sampling methodology to ensure impartiality."
            }
        ]
    },
    {
        "id": 115,
        "q": "During DAST scanning, applications are consistently reporting code defects in open-source libraries that were used to build web applications. Most of the code defects are from using libraries with known vulnerabilities. The code defects are causing product deployment delays. Which of the following is the best way to uncover these issues earlier in the life cycle?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Directing application logs to the SIEM for continuous monitoring",
                "correct": false,
                "explain": "Incorrect. SIEM monitoring is a runtime control and occurs after deployment. The goal is to find these issues earlier in the life cycle."
            },
            {
                "text": "Modifying the WAF polices to block against known vulnerabilities",
                "correct": false,
                "explain": "Incorrect. A WAF is a runtime, compensating control. It doesn't find the issues earlier in the development life cycle."
            },
            {
                "text": "Completing an IAST scan against the web application",
                "correct": false,
                "explain": "Incorrect. Interactive Application Security Testing (IAST) occurs during functional testing, which is later in the cycle than development. An SCA tool can find these issues even earlier."
            },
            {
                "text": "Using a software dependency management solution",
                "correct": true,
                "explain": "Correct. The problem is specifically with vulnerabilities in open-source libraries (dependencies). A Software Composition Analysis (SCA) tool, which is a type of software dependency management solution, is designed for this exact purpose. It scans the code to identify all third-party and open-source components and checks them against a database of known vulnerabilities. Integrating SCA into the IDE or the CI/CD pipeline allows developers to discover these issues as they are writing code, which is the earliest possible point in the life cycle."
            }
        ]
    },
    {
        "id": 116,
        "q": "A company's SIEM is designed to associate the companys asset inventory with user events. Given the following report: <br><br> <img src='../../assets/quiz-images/CAS-005_116.png' alt='SIEM login report'> <br><br> Which of the following should a security engineer investigate first as part of a log audit?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "An endpoint that is not submitting any logs",
                "correct": true,
                "explain": "Correct. Server 5 is listed in the asset inventory but has zero attempted, failed, or successful log-ins recorded. In a production environment, this is highly suspicious. It could indicate that the logging agent on the server has failed, has been disabled by an attacker, or that the server is offline. A non-reporting device represents a critical visibility gap and should be investigated immediately."
            },
            {
                "text": "Potential activity indicating an attacker moving laterally in the network",
                "correct": false,
                "explain": "Incorrect. While the failed Administrator log-ins are suspicious, a complete lack of logs from an asset is a more critical initial finding in a log audit."
            },
            {
                "text": "A misconfigured syslog server creating false negatives",
                "correct": false,
                "explain": "Incorrect. While a possibility, the most direct interpretation of the data is that a specific endpoint is the problem, not the entire syslog infrastructure."
            },
            {
                "text": "Unauthorized usage attempts of the administrator account",
                "correct": false,
                "explain": "Incorrect. The two failed log-ins for the Administrator account on Server 4 are certainly worth investigating, but a server that is completely silent (Server 5) represents a potentially larger and more urgent risk."
            }
        ]
    },
    {
        "id": 117,
        "q": "A developer receives feedback about code quality and efficiency. The developer needs to identify and resolve the following coding issues before submitting the code for peer review: Indexing beyond arrays, Dereferencing null pointers, Potentially dangerous data type combos, Unreachable code, Non-portable constructs. Which of the following would be most appropriate for the developer to use in this situation?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Linting",
                "correct": true,
                "explain": "Correct. A linter, or lint tool, is a static code analysis tool used to flag programming errors, bugs, stylistic errors, and suspicious constructs. The issues listedsuch as out-of-bounds indexing, null pointer dereferences, unreachable code, and non-portable constructsare exactly the types of problems that linters are designed to detect automatically. It's a standard tool for improving code quality before peer review."
            },
            {
                "text": "SBoM",
                "correct": false,
                "explain": "Incorrect. A Software Bill of Materials (SBoM) lists the third-party components in a piece of software; it does not analyze the quality of the custom-written code."
            },
            {
                "text": "DAST",
                "correct": false,
                "explain": "Incorrect. Dynamic Application Security Testing (DAST) analyzes a running application from the outside and would not be able to identify issues like unreachable code or non-portable constructs within the source code."
            },
            {
                "text": "Branch protection",
                "correct": false,
                "explain": "Incorrect. Branch protection is a feature in version control systems to enforce rules on code merges; it does not analyze the code itself."
            },
            {
                "text": "Software composition analysis",
                "correct": false,
                "explain": "Incorrect. Software Composition Analysis (SCA) is used to find vulnerabilities in third-party libraries, not to analyze the quality of the developer's own code."
            }
        ]
    },
    {
        "id": 118,
        "q": "A company wants to improve and automate the compliance of its cloud environments to meet industry standards. Which of the following resources should the company use to best achieve this goal?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "Jenkins",
                "correct": false,
                "explain": "Incorrect. Jenkins is a CI/CD automation server used for building and deploying code. It is not designed for compliance automation."
            },
            {
                "text": "Python",
                "correct": false,
                "explain": "Incorrect. Python is a general-purpose programming language. While it could be used to write compliance automation scripts, it is not a configuration management tool itself."
            },
            {
                "text": "Ansible",
                "correct": true,
                "explain": "Correct. Ansible is a powerful open-source automation tool used for configuration management, application deployment, and task automation. It uses human-readable YAML files (called playbooks) to define the desired state of systems. A company can use Ansible to create playbooks that automatically configure cloud resources to be compliant with industry standards (like CIS Benchmarks) and to remediate any configuration drift, thus automating compliance."
            },
            {
                "text": "PowerShell",
                "correct": false,
                "explain": "Incorrect. PowerShell is a command-line shell and scripting language. Like Python, it can be used to write automation scripts, but Ansible is a complete configuration management framework designed for this purpose."
            }
        ]
    },
    {
        "id": 119,
        "q": "A company wants to protect against the most common attacks and rapidly integrate with different programming languages. Which of the following technologies is most likely to meet this need?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "RASP",
                "correct": true,
                "explain": "Correct. Runtime Application Self-Protection (RASP) is a modern application security technology that integrates directly into an application's runtime environment (e.g., the Java Virtual Machine or .NET CLR). It has deep visibility into the application's logic and data flow, allowing it to detect and block attacks in real-time with high accuracy. Because it works at the runtime level, it can protect applications written in different programming languages that share the same runtime, meeting both requirements."
            },
            {
                "text": "Cloud-based IDE",
                "correct": false,
                "explain": "Incorrect. A cloud-based IDE is a development environment and does not provide runtime protection against attacks."
            },
            {
                "text": "DAST",
                "correct": false,
                "explain": "Incorrect. A Dynamic Application Security Testing (DAST) tool is a scanner that tests an application from the outside. It is not an integrated, real-time protection mechanism."
            },
            {
                "text": "NIPS",
                "correct": false,
                "explain": "Incorrect. A Network Intrusion Prevention System (NIPS) operates at the network layer. It lacks the application-specific context that a RASP has, making it less effective against application-layer attacks."
            }
        ]
    },
    {
        "id": 120,
        "q": "An organization is concerned about insider threats from employees who have individual access to encrypted material. Which of the following techniques best addresses this issue?",
        "type": "single",
        "category": "3.7 Explain the importance of advanced cryptographic concepts.",
        "answers": [
            {
                "text": "SSO with MFA",
                "correct": false,
                "explain": "Incorrect. SSO and MFA are authentication controls. They don't prevent a single, authorized insider from misusing their access."
            },
            {
                "text": "Salting and hashing",
                "correct": false,
                "explain": "Incorrect. Salting and hashing are used to protect stored passwords, not to prevent insider abuse of access to encrypted data."
            },
            {
                "text": "Account federation with hardware tokens",
                "correct": false,
                "explain": "Incorrect. This is an authentication mechanism and does not solve the problem of a single authorized user having too much power."
            },
            {
                "text": "SAE",
                "correct": false,
                "explain": "Incorrect. Simultaneous Authentication of Equals (SAE) is a secure password-based key exchange protocol used in WPA3. It does not address the insider threat problem described."
            },
            {
                "text": "Key splitting",
                "correct": true,
                "explain": "Correct. Key splitting (also related to secret sharing schemes) is a cryptographic technique where a single key is divided into multiple parts, called shares. To reconstruct the original key and access the encrypted material, a minimum number of these shares must be brought together. By distributing the shares among different employees, the organization ensures that no single individual can access the data alone. This directly mitigates the risk from a malicious insider."
            }
        ]
    },
    {
        "id": 121,
        "q": "A manufacturing plant is updating its IT services. During discussions, the senior management team created the following list of considerations: Staff turnover is high and seasonal. Extreme conditions often damage endpoints. Losses from downtime must be minimized. Regulatory data retention requirements exist. Which of the following best addresses the considerations?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "Establishing further environmental controls to limit equipment damage",
                "correct": false,
                "explain": "Incorrect. While a good idea, it may not be feasible in a manufacturing plant and doesn't address the other considerations like high staff turnover."
            },
            {
                "text": "Using a non-persistent virtual desktop interface with thin clients",
                "correct": true,
                "explain": "Correct. This solution addresses all four considerations: 1) **High Turnover**: Non-persistent VDI provides a fresh, clean desktop for each user session, simplifying onboarding/offboarding. 2) **Damaged Endpoints**: Using inexpensive, ruggedized thin clients minimizes the cost of damage, as the actual computing happens on a server in a protected data center. 3) **Minimize Downtime**: If a thin client is damaged, it can be quickly swapped out with a new one with minimal disruption. 4) **Data Retention**: Since all data is stored centrally on the VDI server, not the endpoint, it is much easier to manage, back up, and enforce retention policies."
            },
            {
                "text": "Deploying redundant file servers and configuring database journaling",
                "correct": false,
                "explain": "Incorrect. This addresses downtime and data retention for servers but does not solve the endpoint-related issues of damage and high staff turnover."
            },
            {
                "text": "Maintaining an inventory of spare endpoints for rapid deployment",
                "correct": false,
                "explain": "Incorrect. While this helps with downtime from damaged endpoints, it is less efficient than the VDI/thin client model and doesn't address the data retention or turnover issues as effectively."
            }
        ]
    },
    {
        "id": 122,
        "q": "A software vendor provides routine functionality and security updates to its global customer base. The vendor would like to ensure distributed updates are authorized, originate from only the company, and have not been modified by others. Which of the following solutions best supports these objectives?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Envelope encryption",
                "correct": false,
                "explain": "Incorrect. Envelope encryption is a method for securely encrypting large amounts of data. It does not provide origin assurance or integrity for software updates."
            },
            {
                "text": "File integrity monitoring",
                "correct": false,
                "explain": "Incorrect. File integrity monitoring is a detective control used on the client side to detect if files have changed; it does not provide the initial assurance of origin for the update package."
            },
            {
                "text": "Application control",
                "correct": false,
                "explain": "Incorrect. Application control restricts which applications can run on a system. It doesn't secure the update distribution process itself."
            },
            {
                "text": "Code signing",
                "correct": true,
                "explain": "Correct. Code signing directly addresses all the stated objectives. The vendor uses its private key to apply a digital signature to the update package. This provides: 1) **Authorization/Origin Assurance**: The customer's system can verify the signature using the vendor's public key, proving the update is from the legitimate company. 2) **Integrity**: The signature includes a hash of the update. The customer's system can verify that the update has not been modified in transit."
            }
        ]
    },
    {
        "id": 123,
        "q": "A security analyst detects a possible RAT infection on a computer in the internal network. After reviewing the details of the alert, the analyst identifies the initial vector of the attack was an email that was forwarded to multiple recipients in the same organizational unit. Which of the following should the analyst do first to minimize this type of threat in the future?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "Move from an anti-malware software to an EDR solution.",
                "correct": false,
                "explain": "Incorrect. While an EDR might provide better visibility, the root cause of the initial infection was human behavior (opening a malicious email), which is best addressed through training."
            },
            {
                "text": "Perform a penetration test to detect technology gaps on the anti-spam solution.",
                "correct": false,
                "explain": "Incorrect. While testing technical controls is valuable, the fact that users received and forwarded the malicious email points to a failure in security awareness as the primary issue to address."
            },
            {
                "text": "Configure an IPS solution in the internal network to mitigate infections.",
                "correct": false,
                "explain": "Incorrect. An internal IPS is a good defense-in-depth control, but it is reactive. Addressing the human element through training is a more proactive, preventative measure against phishing attacks."
            },
            {
                "text": "Implement a security awareness program in the organization.",
                "correct": true,
                "explain": "Correct. The initial vector was a phishing email that users not only opened but also forwarded to others. This indicates a significant gap in the users' ability to recognize and properly handle suspicious emails. Implementing a robust security awareness and training program that specifically targets phishing recognition is the most direct and effective way to minimize this type of threat in the future by addressing the human element."
            }
        ]
    },
    {
        "id": 124,
        "q": "A cloud engineer needs to identify appropriate solutions to: Provide secure access to internal and external cloud resources. Eliminate split-tunnel traffic flows. Enable identity and access management capabilities. Which of the following solutions is the most appropriate?",
        "type": "single",
        "category": "2.6 Given a scenario, integrate Zero Trust concepts into system architecture design.",
        "answers": [
            {
                "text": "Microsegmentation",
                "correct": false,
                "explain": "Incorrect. Microsegmentation provides isolation between workloads but is not a user access solution."
            },
            {
                "text": "PAM",
                "correct": false,
                "explain": "Incorrect. Privileged Access Management (PAM) is for controlling administrative accounts, not for general user access to all resources."
            },
            {
                "text": "SD-WAN",
                "correct": false,
                "explain": "Incorrect. Software-Defined WAN (SD-WAN) is a networking solution that optimizes traffic flow, but it doesn't inherently include the integrated security and IAM capabilities of SASE."
            },
            {
                "text": "SASE",
                "correct": true,
                "explain": "Correct. Secure Access Service Edge (SASE) is a cloud-native architecture that combines networking and security services into a single, unified platform. It directly meets all the requirements: 1) It provides secure access to both internal (private) and external (SaaS/web) resources. 2) By routing all user traffic through the SASE cloud for inspection (a full tunnel), it eliminates the risks of split-tunneling. 3) Identity and access management (Zero Trust Network Access) is a core component of the SASE security stack."
            }
        ]
    },
    {
        "id": 125,
        "q": "A security engineer is building a solution to disable weak CBC configurations for remote access connections to Linux systems. Which of the following should the security engineer modify?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "The /etc/openssl.conf file, updating the virtual site parameter",
                "correct": false,
                "explain": "Incorrect. The openssl.conf file is the general configuration for the OpenSSL library and is not where you configure SSH-specific ciphers."
            },
            {
                "text": "The /etc/nsswitch.conf file, updating the name server",
                "correct": false,
                "explain": "Incorrect. The nsswitch.conf file configures name service lookups and has nothing to do with cryptographic ciphers."
            },
            {
                "text": "The /etc/hosts file, updating the IP parameter",
                "correct": false,
                "explain": "Incorrect. The hosts file is for static hostname-to-IP mappings and is unrelated to SSH cipher configuration."
            },
            {
                "text": "The /etc/ssh/sshd_config file, updating the ciphers",
                "correct": true,
                "explain": "Correct. The question refers to remote access connections to Linux systems, which primarily use the Secure Shell (SSH) protocol. The SSH daemon's configuration file is `/etc/ssh/sshd_config`. To disable weak Cipher Block Chaining (CBC) mode ciphers and enforce stronger ones (like GCM or ChaCha20-Poly1305), the engineer must modify the `Ciphers` directive within this file."
            }
        ]
    },
    {
        "id": 126,
        "q": "A security engineer is reviewing the results of an annual penetration test. The report lists one of the results as 'critical severity' on several domain-joined workstations: SSL/TLS Weak Protocols Supported TLS 1.0, TLS 1.1. Which of the following should the security engineer implement to remediate this finding in the most centralized manner?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "An SCCM patch to disable weak protocols in the Schannel hive",
                "correct": false,
                "explain": "Incorrect. While SCCM can deploy scripts or configurations, GPO is the native and most direct tool for managing registry settings like this across a domain."
            },
            {
                "text": "A GPO to disable weak protocols in the Schannel hive",
                "correct": true,
                "explain": "Correct. The systems are domain-joined Windows workstations. The secure communication protocols (like TLS versions) are configured in the Windows registry within the Secure Channel (Schannel) provider hive. The most efficient and centralized way to manage registry settings across multiple domain-joined computers is by using a Group Policy Object (GPO). The engineer can create a GPO to set the appropriate registry keys to disable TLS 1.0 and 1.1 and link it to the organizational unit (OU) containing the workstations."
            },
            {
                "text": "A PowerShell script to disable weak protocols in the HKLM Schannel hive",
                "correct": false,
                "explain": "Incorrect. Running a PowerShell script on each machine individually is not a centralized solution. While you could push the script via GPO or SCCM, using the GPO's built-in registry management settings is more direct."
            },
            {
                "text": "A registry script to disable weak protocols in the Schannel hive",
                "correct": false,
                "explain": "Incorrect. Using a .reg file on each machine is not a centralized management method."
            }
        ]
    },
    {
        "id": 127,
        "q": "An analyst reviews a SIEM and generates the following report: <br><br> <img src='../../assets/quiz-images/CAS-005_127.png' alt='SIEM alert report'> <br><br> Only HOST002 is authorized for internet traffic. Which of the following statements is accurate?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "The VM002 host is misconfigured and needs to be revised by the network team.",
                "correct": true,
                "explain": "Correct. The report shows several events originating from VM002 with destinations on the internet (`web.corp.local` resolves to an internal address, but `comptia.org` is external, and the traffic to `web.corp.local` likely originated from the internet). The policy states that only HOST002 is authorized for internet traffic. Therefore, VM002 making or receiving connections from the internet indicates a misconfiguration (e.g., a wrong firewall rule or security group) that is violating policy."
            },
            {
                "text": "The HOST002 host is under attack, and a security incident should be declared.",
                "correct": false,
                "explain": "Incorrect. The activity from HOST002web navigation and a file downloadis consistent with its authorized role. There is no clear evidence of an attack on HOST002 in these logs."
            },
            {
                "text": "The SIEM platform is reporting multiple false positives on the alerts.",
                "correct": false,
                "explain": "Incorrect. These are not necessarily false positives. The alert for VM002's network connection is a true positive for a policy violation."
            },
            {
                "text": "The network connection activity is unusual, and a network infection is highly possible.",
                "correct": false,
                "explain": "Incorrect. The activity described is a policy violation due to a misconfiguration. While an infection is always a possibility, there is no direct evidence of one in these specific logs."
            }
        ]
    },
    {
        "id": 128,
        "q": "A company wants to implement a three-tier approach to separate the web, database, and application servers. A security administrator must harden the environment. Which of the following is the best solution?",
        "type": "single",
        "category": "2.6 Given a scenario, integrate Zero Trust concepts into system architecture design.",
        "answers": [
            {
                "text": "Deploying a VPN to prevent remote locations from accessing server VLANs",
                "correct": false,
                "explain": "Incorrect. A VPN provides secure remote access but does not enforce segmentation between the server tiers themselves."
            },
            {
                "text": "Configuring a SASE solution to restrict users to server communication",
                "correct": false,
                "explain": "Incorrect. SASE is a solution for securing user access to applications, not for enforcing granular controls between server tiers within a data center."
            },
            {
                "text": "Implementing microsegmentation on the server VLANs",
                "correct": true,
                "explain": "Correct. Microsegmentation is a security technique that involves creating granular, isolated network zones for individual workloads or applications. In a three-tier architecture, microsegmentation would be used to create strict firewall policies that, for example, only allow the web servers to talk to the application servers on specific ports, and only allow the application servers to talk to the database servers on specific ports. This enforces the principle of least privilege at the network layer and is the best solution for hardening this type of environment."
            },
            {
                "text": "Installing a firewall and making it the network core",
                "correct": false,
                "explain": "Incorrect. While a firewall is used, simply installing one at the core is a traditional approach. 'Microsegmentation' is the modern, more granular, and more secure strategy for this scenario."
            }
        ]
    },
    {
        "id": 129,
        "q": "A systems administrator wants to use existing resources to automate reporting from disparate security appliances that do not currently communicate. Which of the following is the best way to meet this objective?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "Configuring an API integration to aggregate the different data sets",
                "correct": true,
                "explain": "Correct. Modern security appliances almost universally provide an Application Programming Interface (API) for programmatic access to their data and functions. To automate reporting from disparate systems, the administrator can write scripts that use these APIs to pull the necessary data from each appliance into a central location for aggregation and report generation. This is a standard method for integration."
            },
            {
                "text": "Combining back-end application storage into a single, relational database",
                "correct": false,
                "explain": "Incorrect. This is impractical, likely impossible, and would violate vendor support agreements. The administrator does not have access to modify the back-end databases of commercial appliances."
            },
            {
                "text": "Purchasing and deploying commercial off-the-shelf aggregation software",
                "correct": false,
                "explain": "Incorrect. The question specifies the administrator wants to use 'existing resources,' which rules out purchasing a new commercial tool."
            },
            {
                "text": "Migrating application usage logs to on-premises storage",
                "correct": false,
                "explain": "Incorrect. Simply moving the location of the logs does not solve the problem of aggregating and reporting on data from different, non-communicating systems."
            }
        ]
    },
    {
        "id": 130,
        "q": "A vulnerability scan on a web server identified the following: <br><br> <img src='../../assets/quiz-images/CAS-005_130.png' alt='TLS cipher suite scan results'> <br><br> Which of the following actions would most likely eliminate on-path decryption attacks? (Choose two.)",
        "type": "multiple",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "Disallowing cipher suites that use ephemeral modes of operation for key agreement",
                "correct": false,
                "explain": "Incorrect. This is the opposite of the correct action. Ephemeral modes (like DHE and ECDHE) provide Forward Secrecy, which is a critical defense against decryption attacks."
            },
            {
                "text": "Removing support for CBC-based key exchange and signing algorithms",
                "correct": true,
                "explain": "Correct. All of the listed accepted cipher suites use Cipher Block Chaining (CBC) mode, which is vulnerable to padding oracle attacks like POODLE and BEAST when not implemented perfectly. Removing support for all CBC-based ciphers is a key step in hardening a TLS configuration."
            },
            {
                "text": "Adding TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA256",
                "correct": true,
                "explain": "Correct. This is a modern, strong cipher suite. ECDHE provides Forward Secrecy. AES in GCM (Galois/Counter Mode) is an AEAD (Authenticated Encryption with Associated Data) cipher that is not vulnerable to the same attacks as CBC mode. Enabling strong suites like this and disabling the weak ones is the proper way to remediate the finding."
            },
            {
                "text": "Implementing HIPS rules to identify and block BEAST attack attempts",
                "correct": false,
                "explain": "Incorrect. While a HIPS might offer some protection, fixing the root cause by disabling the vulnerable cipher suites on the server is the proper and more effective solution."
            },
            {
                "text": "Restricting cipher suites to only allow TLS_RSA_WITH_AES_128_CBC_SHA",
                "correct": false,
                "explain": "Incorrect. This would still leave a weak CBC-mode cipher enabled and, worse, would disable the DHE suite, removing the Forward Secrecy it provides."
            },
            {
                "text": "Increasing the key length to 256 for TLS_RSA_WITH_AES_128_CBC_SHA",
                "correct": false,
                "explain": "Incorrect. You cannot simply increase the key length of an existing cipher suite. You must enable a different cipher suite that uses a 256-bit key (e.g., one containing AES_256)."
            }
        ]
    },
    {
        "id": 131,
        "q": "A companys help desk is experiencing a large number of calls from the finance department stating access issues to www.bank.com. The security operations center reviewed the following security logs: <br><br> <img src='../../assets/quiz-images/CAS-005_131.png' alt='DNS and HTTP security logs'> <br><br> Which of the following is most likely the cause of the issue?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "Recursive DNS resolution is failing.",
                "correct": false,
                "explain": "Incorrect. DNS resolution is clearly working, but it's resolving to two different IP addresses for different groups of users."
            },
            {
                "text": "The DNS record has been poisoned.",
                "correct": true,
                "explain": "Correct. The logs show that users in the Finance department are resolving `www.bank.com` to a malicious IP address (`65.146.76.34`), resulting in a failed connection (HTTP 495 - SSL Certificate Error). At the same time, users in IT and Legal are resolving the same domain name to the correct IP address (`98.17.62.78`) and connecting successfully (HTTP 200). This indicates that the DNS server or cache serving the Finance department has been poisoned with a malicious entry, redirecting them to a fake site."
            },
            {
                "text": "DNS traffic is being sinkholed.",
                "correct": false,
                "explain": "Incorrect. DNS sinkholing is a security technique used to redirect malicious traffic to a controlled server for analysis. While similar in mechanism to poisoning, poisoning is the malicious act itself, which is what is causing the problem for the users."
            },
            {
                "text": "The DNS was set up incorrectly.",
                "correct": false,
                "explain": "Incorrect. A simple misconfiguration would likely affect all users, not just one department. The targeted nature of the issue points to a malicious act like poisoning."
            }
        ]
    },
    {
        "id": 132,
        "q": "A financial services organization is using AI to fully automate the process of deciding client loan rates. Which of the following should the organization be most concerned about from a regulatory perspective?",
        "type": "single",
        "category": "1.5 Summarize the information security challenges associated with artificial intelligence (AI) adoption.",
        "answers": [
            {
                "text": "Model explainability",
                "correct": true,
                "explain": "Correct. In regulated industries like finance, organizations are often required to explain how they arrived at a decision (e.g., why a loan was denied or why a certain interest rate was offered) to regulators and customers. This is to ensure the process is fair and not discriminatory. Many complex AI models, especially deep learning models, are 'black boxes,' making their decision-making process difficult or impossible to interpret. This lack of model explainability poses a significant regulatory and legal risk."
            },
            {
                "text": "Credential theft",
                "correct": false,
                "explain": "Incorrect. Credential theft is a general security risk and is not specific to the regulatory challenges of using AI for decision-making."
            },
            {
                "text": "Possible prompt injections",
                "correct": false,
                "explain": "Incorrect. Prompt injection is a technical vulnerability, but the core regulatory concern is the fairness and transparency of the automated decisions."
            },
            {
                "text": "Exposure to social engineering",
                "correct": false,
                "explain": "Incorrect. Social engineering targets people, not the AI model itself, and is not the primary regulatory concern in this context."
            }
        ]
    },
    {
        "id": 133,
        "q": "A security analyst is reviewing the following log: <br><br> <img src='../../assets/quiz-images/CAS-005_133.png' alt='Antivirus log'> <br><br> Which of the following possible events should the security analyst investigate further?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "A macro that was prevented from running",
                "correct": false,
                "explain": "Incorrect. The `doc` file was blocked, indicating the antivirus may have prevented it from being saved, but we cannot be certain it contained a macro from this log alone."
            },
            {
                "text": "A text file containing passwords that were leaked",
                "correct": false,
                "explain": "Incorrect. The log shows a `txt` file being allowed at 11:35, but there is no information to suggest it contains passwords or was leaked."
            },
            {
                "text": "A malicious file that was run in this environment",
                "correct": true,
                "explain": "Correct. At 11:27, a DLL (Dynamic Link Library) file was saved to the `c:\\temp` directory and the antivirus status was 'allow'. DLLs are a common format for malware payloads, and the `temp` directory is a frequent target for attackers. The fact that the antivirus allowed a DLL to be written to a temporary directory is a significant potential indicator of compromise that warrants immediate further investigation."
            },
            {
                "text": "A PDF that exposed sensitive information improperly",
                "correct": false,
                "explain": "Incorrect. A PDF file was allowed, but there is no evidence in the log that it contained sensitive information or that it was exposed."
            }
        ]
    },
    {
        "id": 134,
        "q": "A security operations engineer needs to prevent inadvertent data disclosure when encrypted SSDs are reused within an enterprise. Which of the following is the most secure way to achieve this goal?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Executing a script that deletes and overwrites all data on the SSD three times",
                "correct": false,
                "explain": "Incorrect. Overwriting data is a technique for traditional magnetic hard drives. It is less effective and can reduce the lifespan of Solid-State Drives (SSDs) due to wear-leveling algorithms."
            },
            {
                "text": "Wiping the SSD through degaussing",
                "correct": false,
                "explain": "Incorrect. Degaussing uses a powerful magnet to wipe data and is only effective on magnetic media. It does not work on SSDs."
            },
            {
                "text": "Securely deleting the encryption keys used by the SSD",
                "correct": true,
                "explain": "Correct. This technique is called cryptographic erase or crypto-shredding. Modern SSDs are often Self-Encrypting Drives (SEDs), where all data written is automatically encrypted by a hardware controller using a media encryption key (MEK). The most secure and efficient way to render all data on the drive permanently unrecoverable is to issue a secure command that deletes this internal MEK. Once the key is gone, the encrypted data is just random noise."
            },
            {
                "text": "Writing non-zero, random data to all cells of the SSD",
                "correct": false,
                "explain": "Incorrect. This is a form of clearing or overwriting. As with other overwrite methods, it is not the most effective or secure method for sanitizing an SSD. Cryptographic erase is superior."
            }
        ]
    },
    {
        "id": 135,
        "q": "A security professional is investigating a trend in vulnerability findings for newly deployed cloud systems. Given the following output: <br><br> <img src='../../assets/quiz-images/CAS-005_135.png' alt='Vulnerability scan findings'> <br><br> Which of the following actions would address the root cause of this issue?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Automating the patching system to update base images",
                "correct": true,
                "explain": "Correct. The report shows that all newly deployed systems have the same outdated versions of OpenSSL and Java. This strongly indicates that the organization is deploying new systems from a stale or outdated base image (template). The root cause is a flawed image management process. The correct solution is to automate the process of regularly patching and updating these base 'golden' images, so that any new system deployed will already have the latest security updates."
            },
            {
                "text": "Recompiling the affected programs with the most current patches",
                "correct": false,
                "explain": "Incorrect. This is not practical at scale and doesn't fix the underlying problem of deploying from an old base image."
            },
            {
                "text": "Disabling unused/unneeded ports on all servers",
                "correct": false,
                "explain": "Incorrect. While a good hardening practice, this does not address the software vulnerabilities that have been identified."
            },
            {
                "text": "Deploying a WAF with virtual patching upstream of the affected systems.",
                "correct": false,
                "explain": "Incorrect. A WAF with virtual patching is a compensating control, not a fix for the root cause. The proper solution is to patch the systems themselves by updating the base image."
            }
        ]
    },
    {
        "id": 136,
        "q": "A company established a new process for business analysts to receive emails that contain links for purchase requests. The new process requires links to be submitted through new emails. Which of the following is the best way to secure this process without disrupting order fulfillment?",
        "type": "single",
        "category": "3.2 Given a scenario, analyze requirements to enhance the security of endpoints and servers.",
        "answers": [
            {
                "text": "Deploying a browser isolation solution",
                "correct": true,
                "explain": "Correct. The business process requires analysts to click on links from emails, which is inherently risky. A browser isolation solution (also known as remote browser isolation or RBI) executes the web Browse session in a secure, isolated environment (often a container in the cloud or on a secure server) and streams a visual representation of the web page to the user's browser. This means any malicious code on the clicked link runs in the isolated environment and can't infect the analyst's endpoint or the corporate network. This secures the process without disrupting the workflow."
            },
            {
                "text": "Blocking all potentially malicious links",
                "correct": false,
                "explain": "Incorrect. A web filter might block known malicious links, but it could also block legitimate (but unknown) purchase request links, which would disrupt order fulfillment. It also doesn't protect against zero-day attacks."
            },
            {
                "text": "Enforcing security awareness training",
                "correct": false,
                "explain": "Incorrect. While training is important, it is not a technical control and relies on the user to always make the correct decision, which is not guaranteed. A technical solution is needed."
            },
            {
                "text": "Implementing DNS filtering",
                "correct": false,
                "explain": "Incorrect. Similar to a web filter, DNS filtering can block access to known malicious domains but could also block legitimate ones and would not protect against all threats. Browser isolation is a more robust control."
            }
        ]
    },
    {
        "id": 137,
        "q": "An organization receives OSINT reports about an increase in ransomware targeting fileshares at peer companies. The organization wants to deploy hardening policies to its servers and workstations in order to contain potential ransomware. Which of the following should an engineer do to best achieve this goal?",
        "type": "single",
        "category": "3.2 Given a scenario, analyze requirements to enhance the security of endpoints and servers.",
        "answers": [
            {
                "text": "Allow only interactive log-in for users on workstations and restrict port 445 traffic to fileshares.",
                "correct": true,
                "explain": "Correct. Ransomware often spreads laterally by exploiting file-sharing protocols like Server Message Block (SMB), which runs on TCP port 445. A key containment strategy is to configure host-based firewalls on workstations to block all incoming port 445 traffic. This prevents one infected workstation from spreading the ransomware to another workstation's local drive via SMB. Outbound traffic on port 445 should still be allowed so workstations can connect to legitimate central file servers."
            },
            {
                "text": "Enable biometric authentication mechanisms on user workstations and block port 53 traffic.",
                "correct": false,
                "explain": "Incorrect. Biometrics is an authentication control and doesn't stop ransomware that is already running. Blocking port 53 (DNS) would break most network functionality."
            },
            {
                "text": "Instruct users to use a password manager when generating new credentials and secure port 443 traffic.",
                "correct": false,
                "explain": "Incorrect. Password managers are a good practice but do not contain ransomware. Securing port 443 (HTTPS) is also unrelated to containing ransomware that spreads via file shares."
            },
            {
                "text": "Give users permission to rotate administrator passwords and deny port 80 traffic.",
                "correct": false,
                "explain": "Incorrect. User-rotated admin passwords and blocking port 80 (HTTP) are not effective controls for containing ransomware that spreads via SMB."
            }
        ]
    },
    {
        "id": 138,
        "q": "A malicious actor exploited firmware vulnerabilities and used rootkits in an attack on an organization. After the organization recovered from the incident, an engineer needs to recommend a solution that reduces the likelihood of the same type of attack in the future. Which of the following is the most relevant solution?",
        "type": "single",
        "category": "3.4 Given a scenario, implement hardware security technologies and techniques.",
        "answers": [
            {
                "text": "Enabling software integrity checks",
                "correct": false,
                "explain": "Incorrect. While a good idea, this is a generic term. Measured boot is the specific technology that performs these checks on the boot chain."
            },
            {
                "text": "Installing self-encrypting drives",
                "correct": false,
                "explain": "Incorrect. Self-encrypting drives protect data at rest but do not prevent the loading of malicious firmware or rootkits."
            },
            {
                "text": "Implementing measured boot",
                "correct": true,
                "explain": "Correct. A measured boot process uses a hardware root of trust, like a TPM, to measure the cryptographic hash of each component in the boot chain (firmware, bootloader, kernel, drivers) before it is loaded. It stores these measurements securely. This process doesn't stop malicious code from loading, but it creates a verifiable and tamper-proof log of the exact state of the system. This log can then be sent to a remote attestation server to verify the system's integrity and deny it network access if a rootkit or malicious firmware is detected. This directly addresses the attack described."
            },
            {
                "text": "Configuring host-based encryption",
                "correct": false,
                "explain": "Incorrect. Host-based encryption protects data confidentiality but does not protect the integrity of the boot process from firmware attacks or rootkits."
            }
        ]
    },
    {
        "id": 139,
        "q": "Which of the following enables the meaningful manipulation of encrypted data when the processor does not know the encryption key?",
        "type": "single",
        "category": "3.7 Explain the importance of advanced cryptographic concepts.",
        "answers": [
            {
                "text": "Simultaneous authentication of equals",
                "correct": false,
                "explain": "Incorrect. SAE is a secure key exchange protocol used in WPA3; it does not involve computation on encrypted data."
            },
            {
                "text": "Envelope encryption",
                "correct": false,
                "explain": "Incorrect. Envelope encryption is a method of encrypting data with a data key, and then encrypting the data key with a key encryption key. It does not allow for computation on the encrypted data."
            },
            {
                "text": "Authenticated encryption with associated data",
                "correct": false,
                "explain": "Incorrect. AEAD is a mode of encryption that provides both confidentiality and integrity, but it does not allow for operations to be performed on the encrypted data."
            },
            {
                "text": "Homomorphic encryption",
                "correct": true,
                "explain": "Correct. Homomorphic encryption is an advanced form of encryption that allows for specific types of computations (like addition or multiplication) to be performed directly on ciphertext. The result, when decrypted, is the same as if the operations had been performed on the original plaintext. This allows a third party (like a cloud provider) to process sensitive data without ever needing to decrypt it, which perfectly matches the description."
            }
        ]
    },
    {
        "id": 140,
        "q": "Emails that the marketing department is sending to customers are going to the customers spam folders. The security team is investigating the issue and discovers that the certificates used by the email server were reissued, but DNS records had not been updated. Which of the following should the security team update in order to fix this issue? (Choose three.)",
        "type": "multiple",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "DMARC",
                "correct": true,
                "explain": "Correct. DMARC (Domain-based Message Authentication, Reporting, and Conformance) is a policy layer that uses SPF and DKIM. It tells receiving mail servers what to do with messages that fail SPF or DKIM checks (e.g., quarantine or reject). It also provides reporting. If the underlying DKIM is broken due to a new certificate, DMARC alignment will fail, contributing to the spam classification."
            },
            {
                "text": "SPF",
                "correct": true,
                "explain": "Correct. SPF (Sender Policy Framework) is a DNS record that lists the authorized IP addresses allowed to send email for a domain. While not directly related to certificates, it's a fundamental email authentication mechanism. If not configured correctly, especially when using third-party senders, it can cause emails to be marked as spam. It's a key part of the email authentication trio."
            },
            {
                "text": "DKIM",
                "correct": true,
                "explain": "Correct. DKIM (DomainKeys Identified Mail) uses a digital signature, tied to a public key published in DNS, to verify that an email was authorized by the domain owner and has not been modified. If the certificate/key pair on the email server was reissued, the corresponding public key in the DKIM DNS record must also be updated. A mismatch will cause DKIM validation to fail, which is a major reason for emails being sent to spam."
            },
            {
                "text": "DNSSEC",
                "correct": false,
                "explain": "Incorrect. DNSSEC secures the DNS protocol itself, preventing DNS spoofing. It doesn't directly authenticate email messages."
            },
            {
                "text": "SASE",
                "correct": false,
                "explain": "Incorrect. SASE is a network security architecture and is unrelated to email authentication DNS records."
            },
            {
                "text": "SAN",
                "correct": false,
                "explain": "Incorrect. A Subject Alternative Name (SAN) is a field in a TLS certificate; it is not a DNS record type for email authentication."
            },
            {
                "text": "SOA",
                "correct": false,
                "explain": "Incorrect. A Start of Authority (SOA) record is a mandatory DNS record that contains administrative information about a DNS zone; it is not used for email authentication."
            },
            {
                "text": "MX",
                "correct": false,
                "explain": "Incorrect. An MX (Mail Exchange) record tells other servers where to send email for a domain. It directs traffic but doesn't authenticate the messages."
            }
        ]
    },
    {
        "id": 141,
        "q": "A security engineer performed a code scan that resulted in many false positives. The security engineer must find a solution that improves the quality of scanning results before application deployment. Which of the following is the best solution?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Limiting the tool to a specific coding language and tuning the rule set",
                "correct": true,
                "explain": "Correct. Static analysis (SAST) tools often generate a large number of findings, many of which can be false positives in the context of a specific application. The most effective way to improve the quality of the results is to tune the scanner. This involves disabling irrelevant or noisy rules, adjusting the severity of others, and focusing the tool on the specific languages and frameworks being used. This process reduces the noise and allows developers to focus on the true positive findings."
            },
            {
                "text": "Configuring branch protection rules and dependency checks",
                "correct": false,
                "explain": "Incorrect. These are process controls and tools for managing dependencies (SCA), but they do not address the problem of false positives coming from the primary code scanner."
            },
            {
                "text": "Using an application vulnerability scanner to identify coding flaws in production",
                "correct": false,
                "explain": "Incorrect. This describes DAST, which happens after deployment. The goal is to improve scanning results *before* deployment."
            },
            {
                "text": "Performing updates on code libraries before code development",
                "correct": false,
                "explain": "Incorrect. Updating libraries is a good practice (and handled by SCA tools), but it does not solve the problem of false positives from the SAST tool scanning the custom code."
            }
        ]
    },
    {
        "id": 142,
        "q": "A global company with a remote workforce implemented a new VPN solution. After deploying the VPN solution to several hundred users, the help desk starts receiving reports of slow access to both internally and externally available applications. A security analyst reviews the following: <br><br> `VPN client routing: 0.0.0.0/0 eth1` <br><br> Which of the following solutions should the analyst use to fix this issue?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "Move the servers to a screened subnet.",
                "correct": false,
                "explain": "Incorrect. A screened subnet (DMZ) is a network architecture choice and does not solve the performance problem caused by the VPN configuration."
            },
            {
                "text": "Enable split tunneling.",
                "correct": true,
                "explain": "Correct. The routing rule `0.0.0.0/0` indicates that the VPN is configured for full tunneling. This means *all* traffic from the user's machinewhether it's destined for an internal corporate server or an external website like Googleis being sent through the corporate VPN. This can overwhelm the VPN concentrator and corporate internet connection, causing slow performance for all applications. Enabling split tunneling would configure the VPN client to only send traffic destined for the internal corporate network through the VPN tunnel, while allowing traffic for external sites to go directly to the internet from the user's machine, resolving the performance issue."
            },
            {
                "text": "Configure an NAC solution.",
                "correct": false,
                "explain": "Incorrect. Network Access Control (NAC) is an authentication and posture-checking solution; it does not address VPN traffic routing or performance."
            },
            {
                "text": "Implement DNS over HTTPS.",
                "correct": false,
                "explain": "Incorrect. DoH encrypts DNS lookups but does not change how the application traffic is routed through the VPN."
            }
        ]
    },
    {
        "id": 143,
        "q": "A security analyst is reviewing suspicious log-in activity and sees the following data in the SIEM: <br><br> <img src='../../assets/quiz-images/CAS-005_143.png' alt='SIEM authorization log'> <br><br> Which of the following is the most appropriate action for the analyst to take?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "Update the log configuration settings on the directory server that is not being captured properly.",
                "correct": true,
                "explain": "Correct. The log shows multiple login attempts (SALES1 to Email, FINANCE1 to Payroll) that were authenticated against the LDAP-EU server, but the status is 'Unknown'. This indicates a critical visibility gap. The SIEM is not receiving or cannot parse the success/failure status from the European directory server. The most appropriate action is to fix this logging issue to ensure all authentication events are being properly captured and analyzed."
            },
            {
                "text": "Have the admin account owner change their password to avoid credential stuffing.",
                "correct": false,
                "explain": "Incorrect. While the single failed admin login is worth noting, the systemic lack of visibility from the EU server is a much larger and more urgent problem to fix."
            },
            {
                "text": "Block employees from logging in to applications that are not part of their business area.",
                "correct": false,
                "explain": "Incorrect. The logs show SALES1 accessing Payroll. While this might be a policy violation worth investigating later, fixing the broken logging from the EU server is the top priority."
            },
            {
                "text": "Implement automation to disable accounts that have been associated with high-risk activity.",
                "correct": false,
                "explain": "Incorrect. This is a reactive measure. The primary goal should be to fix the data collection problem so that high-risk activity can be accurately identified in the first place."
            }
        ]
    },
    {
        "id": 144,
        "q": "An organization determined its preparedness for a ransomware attack is inadequate. A security administrator is working on ways to improve and monitor the organization's response to ransomware attacks. Which of the following is the best action for the administrator to take?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Conduct backup testing.",
                "correct": true,
                "explain": "Correct. A backup is useless if it cannot be successfully restored. The single most important action to improve and monitor preparedness for a ransomware attack is to regularly test the backup and recovery process. This involves actually restoring data and systems from backups to a test environment to verify their integrity and ensure that the recovery procedures work as expected and can meet the Recovery Time Objective (RTO)."
            },
            {
                "text": "Define the recovery point objective.",
                "correct": false,
                "explain": "Incorrect. Defining the RPO is a planning activity that should have been done as part of the BIA. Testing the ability to meet the RPO is the action needed now."
            },
            {
                "text": "Perform a business impact analysis.",
                "correct": false,
                "explain": "Incorrect. A BIA is a planning activity to identify critical systems and their recovery requirements. The organization already knows its preparedness is inadequate; now it needs to take action to improve it."
            },
            {
                "text": "Verify the encryption key length.",
                "correct": false,
                "explain": "Incorrect. The encryption key length of the ransomware is irrelevant to the organization's ability to respond and recover from its own backups."
            }
        ]
    },
    {
        "id": 145,
        "q": "A security engineer receives an alert from the SIEM platform indicating a possible malicious action on the internal network. The engineer generates a report that outputs the logs associated with the incident: <br><br> <img src='../../assets/quiz-images/CAS-005_145.png' alt='User login logs'> <br><br> Which of the following actions best enables the engineer to investigate further?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "Consulting logs from the enterprise password manager",
                "correct": false,
                "explain": "Incorrect. Password manager logs might show when a password was retrieved, but they wouldn't provide context about the user's typical login behavior."
            },
            {
                "text": "Searching dark web monitoring resources for exposure",
                "correct": false,
                "explain": "Incorrect. While the user's credentials might be on the dark web, investigating their behavior within the network is the more immediate next step."
            },
            {
                "text": "Reviewing audit logs from privileged actions",
                "correct": false,
                "explain": "Incorrect. The logs show standard user logins, not necessarily privileged actions. A broader behavioral analysis is needed."
            },
            {
                "text": "Querying user behavior analytics data",
                "correct": true,
                "explain": "Correct. The logs show a user, JohnS, logging in at consistent times around 8:00 AM on most days. However, on 01/26, there is an anomalous login at 23:52 (11:52 PM). This deviation from the user's normal pattern is a key indicator of a potential compromise. A User Behavior Analytics (UBA) or UEBA system is designed to automatically baseline normal user activity and flag anomalous events like this. Querying the UBA/UEBA data would provide more context about this unusual login and other actions taken during that session."
            }
        ]
    },
    {
        "id": 146,
        "q": "A security engineer must integrate device attestation into user authentication and authorization workflows for mobile devices. Which of the following best meets the requirements?",
        "type": "single",
        "category": "2.6 Given a scenario, integrate Zero Trust concepts into system architecture design.",
        "answers": [
            {
                "text": "Enforcing a security boundary for all devices outside the perimeter network",
                "correct": false,
                "explain": "Incorrect. Device attestation is a concept within a Zero Trust model, where the idea of a trusted internal perimeter is diminished or eliminated."
            },
            {
                "text": "Enabling multifactor authentication using biometrics on access attempts",
                "correct": false,
                "explain": "Incorrect. MFA verifies the user's identity, but device attestation verifies the device's identity and posture. They are complementary but distinct concepts."
            },
            {
                "text": "Implementing single sign-on to centralize access control enforcement",
                "correct": false,
                "explain": "Incorrect. SSO simplifies the user login experience but is not the mechanism for performing device attestation."
            },
            {
                "text": "Configuring device profiling for patch level and jailbreak status",
                "correct": true,
                "explain": "Correct. Device attestation is the process by which a device proves its identity and security posture to a remote server. For mobile devices, this involves profiling the device to check for critical security attributes. A Mobile Device Management (MDM) or Unified Endpoint Management (UEM) solution would check if the device is running the required OS patch level, if it has been jailbroken or rooted, if required security apps are installed, etc. This profile is then used in a conditional access policy to grant or deny access, fulfilling the requirement."
            }
        ]
    },
    {
        "id": 147,
        "q": "An organization is developing an AI-enabled digital worker to help employees complete common tasks, such as template development, editing, research, and scheduling. As part of the AI workload, the organization wants to implement guardrails within the platform. Which of the following should the company do to secure the AI environment?",
        "type": "single",
        "category": "1.5 Summarize the information security challenges associated with artificial intelligence (AI) adoption.",
        "answers": [
            {
                "text": "Limit the platform's abilities to only non-sensitive functions.",
                "correct": true,
                "explain": "Correct. Implementing guardrails for an AI system means establishing strict boundaries on its capabilities and access to prevent misuse or unintended consequences. The most effective security guardrail is to enforce the principle of least privilege. By limiting the AI's functions and its access to data to the absolute minimum necessary for its tasks (e.g., preventing it from accessing sensitive HR data or financial systems), the organization significantly reduces the potential impact of a compromise or malicious prompt."
            },
            {
                "text": "Enhance the training model's effectiveness.",
                "correct": false,
                "explain": "Incorrect. Making the model more effective or accurate does not inherently make it more secure. A highly effective model could still be tricked into performing a malicious action if it has excessive permissions."
            },
            {
                "text": "Grant the system the ability to self-govern.",
                "correct": false,
                "explain": "Incorrect. This is the opposite of a security guardrail. Granting an AI excessive agency or the ability to self-govern creates a significant and unpredictable security risk."
            },
            {
                "text": "Require end-user acknowledgement of organizational policies.",
                "correct": false,
                "explain": "Incorrect. While important, user policy acknowledgement is an administrative control. The question asks how to secure the AI environment itself, which requires technical controls like limiting its permissions."
            }
        ]
    },
    {
        "id": 148,
        "q": "A security analyst discovered requests associated with IP addresses known for both legitimate and bot-related traffic. Which of the following should the analyst use to determine whether the requests are malicious?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "User-agent string",
                "correct": true,
                "explain": "Correct. The User-Agent string is an HTTP header that identifies the client software (e.g., browser type, version, and operating system) making the request. While it can be easily spoofed, automated bots and scripts often use generic, unusual, or blank user-agent strings that differ from those of standard web browsers. Analyzing the user-agent string is a common technique for differentiating bot traffic from legitimate user traffic."
            },
            {
                "text": "Byte length of the request",
                "correct": false,
                "explain": "Incorrect. The byte length of a request is not a reliable indicator of malicious intent."
            },
            {
                "text": "Web application headers",
                "correct": false,
                "explain": "Incorrect. This is too generic. The User-Agent is a specific header that is most useful for this purpose."
            },
            {
                "text": "HTML encoding field",
                "correct": false,
                "explain": "Incorrect. HTML encoding is used to represent characters and is not a reliable differentiator between human and bot traffic."
            }
        ]
    },
    {
        "id": 149,
        "q": "A security analyst received a report that an internal web page is down after a company-wide update to the web browser. Given the following error message: `Your connection is not private. Attackers might be trying to steal your information for www.internalwebsite.company.com. NET::ERR_CERT_WEAK_SIGNATURE_ALGORITHM` Which of the following is the best way to fix this issue?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "Rewriting any legacy web functions",
                "correct": false,
                "explain": "Incorrect. The error is with the server's digital certificate, not the web application's functions."
            },
            {
                "text": "Disabling all deprecated ciphers",
                "correct": true,
                "explain": "Correct. The error message `ERR_CERT_WEAK_SIGNATURE_ALGORITHM` explicitly states the problem. The digital certificate on the web server was signed using an old, insecure hashing algorithm (like SHA-1). The recent browser update now considers this algorithm to be deprecated and untrustworthy, so it is refusing to connect. The proper fix is to reissue the server's certificate from the Certificate Authority using a modern, strong signature algorithm (like SHA-256)."
            },
            {
                "text": "Blocking all non-essential ports",
                "correct": false,
                "explain": "Incorrect. The issue is with the TLS handshake on the web port (443), not with other non-essential ports."
            },
            {
                "text": "Discontinuing the use of self-signed certificates",
                "correct": false,
                "explain": "Incorrect. While using publicly trusted certificates is a best practice, the specific error here is about a weak signature algorithm, not about whether the certificate is self-signed."
            }
        ]
    },
    {
        "id": 150,
        "q": "A company receives reports about misconfigurations and vulnerabilities in a third-party hardware device that is part of its released products. Which of the following solutions is the best way for the company to identify possible issues at an earlier stage?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Performing vulnerability tests on each device delivered by the providers",
                "correct": false,
                "explain": "Incorrect. While testing delivered devices is a good idea, it happens late in the process. A proper risk management program would address these issues before the devices are even procured."
            },
            {
                "text": "Performing regular red-team exercises on the vendor production line",
                "correct": false,
                "explain": "Incorrect. This is not a feasible or practical solution."
            },
            {
                "text": "Implementing a monitoring process for the integration between the application and the vendor appliance",
                "correct": false,
                "explain": "Incorrect. This is a detective control that would find issues after integration, not at an earlier stage."
            },
            {
                "text": "Implementing a proper supply chain risk management program",
                "correct": true,
                "explain": "Correct. The issue stems from vulnerabilities in a third-party hardware component. A comprehensive Supply Chain Risk Management (SCRM) program is the strategic solution. An SCRM program includes processes for vetting vendors, requiring security attestations, reviewing bills of materials, and establishing security requirements in contracts *before* a component is ever selected or integrated into a product. This identifies and mitigates risks at the earliest possible stage."
            }
        ]
    },
    {
        "id": 151,
        "q": "A company implemented a new NAC solution based on 802.1X. However, the IT support team notices that some devices are not being enrolled in the new policies, causing access disruptions for key users. Which of the following solutions will most likely solve this issue and prevent reoccurrence?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Include the monitoring agent and digital certificate as part of the patching/updating program, keeping all the corporate devices updated and enrolled.",
                "correct": true,
                "explain": "Correct. The core issue is inconsistent enrollment in the 802.1X NAC solution, which requires a client-side agent and/or a digital certificate for authentication. By automating the deployment of these necessary components through a standard, mandatory process like the corporate patch management system, the company ensures all devices will be properly configured. This solves the problem systematically and prevents future devices from failing to enroll."
            },
            {
                "text": "Check whether the certificate is signed by a certification authority and manually deployed to each device.",
                "correct": false,
                "explain": "Incorrect. Manual deployment is inefficient, prone to error, and does not scale. It will not effectively prevent reoccurrence in a large environment."
            },
            {
                "text": "Check all the devices without proper access, enrolling them via the solution agent and authenticating to the network.",
                "correct": false,
                "explain": "Incorrect. This is a reactive, one-off fix for the currently affected devices. It does not address the root cause of the enrollment failure or prevent it from happening again with new or reimaged devices."
            },
            {
                "text": "Implement default credentials to automate RADIUS authentication and grant access to the network if the device owner is an employee.",
                "correct": false,
                "explain": "Incorrect. Using default or shared credentials would completely undermine the security benefits of an 802.1X implementation, which is designed to provide strong, individual authentication."
            }
        ]
    },
    {
        "id": 152,
        "q": "While performing threat-hunting functions, an analyst is using the Diamond Model of Intrusion Analysis. The analyst identifies the likely adversary, the infrastructure involved, and the target. Which of the following must the threat hunter document to use the model effectively?",
        "type": "single",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "Knowledge",
                "correct": false,
                "explain": "Incorrect. Knowledge is a characteristic of the adversary, not one of the four core vertices of the model."
            },
            {
                "text": "Capabilities",
                "correct": true,
                "explain": "Correct. The Diamond Model of Intrusion Analysis describes an intrusion event using four core, interconnected vertices: Adversary, Infrastructure, Capability, and Victim (Target). The analyst has identified the Adversary, Infrastructure, and Victim. The missing vertex that must be documented is the adversary's Capabilitiesthe tools and techniques they used in the attack."
            },
            {
                "text": "Phase",
                "correct": false,
                "explain": "Incorrect. 'Phase' is a concept from other models like the Cyber Kill Chain, not the Diamond Model."
            },
            {
                "text": "Methodologies",
                "correct": false,
                "explain": "Incorrect. While methodologies are part of an adversary's capabilities, 'Capability' is the formal name of the vertex in the Diamond Model."
            }
        ]
    },
    {
        "id": 153,
        "q": "A systems administrator needs to improve the security assurance in a company's cloud storage environment. The administrator determines that the best approach is to identify whether any data has been maliciously or inadvertently modified. Which of the following techniques should the systems administrator periodically use?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Interference",
                "correct": false,
                "explain": "Incorrect. Interference is a type of attack that compromises integrity; it is not a technique used to detect modification."
            },
            {
                "text": "Antitampering",
                "correct": false,
                "explain": "Incorrect. Antitampering refers to preventative controls. The question asks for a technique to identify if a modification has already occurred."
            },
            {
                "text": "Hashing",
                "correct": true,
                "explain": "Correct. The core principle of data integrity verification is hashing. The administrator can create a cryptographic hash (a unique digital fingerprint) of each file to establish a known-good baseline. By periodically recalculating the hashes and comparing them to the baseline, the administrator can definitively identify any file that has been modified."
            },
            {
                "text": "Journaling",
                "correct": false,
                "explain": "Incorrect. Journaling is a technique used by file systems and databases to ensure consistency and recoverability. It is not a method for periodically verifying the integrity of a large set of static files in cloud storage."
            }
        ]
    },
    {
        "id": 154,
        "q": "A security engineer wants to enhance the security posture of end-user systems in a zero trust environment. Given the following requirements: Reduce the ability for potentially compromised endpoints to contact C2 infrastructure. Track the requests that the malware makes to the IPs. Avoid the download of additional payloads. Which of the following should the engineer deploy to meet these requirements?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "DNS sinkholing",
                "correct": true,
                "explain": "Correct. DNS sinkholing is a security technique that redirects malicious DNS requests to a controlled server (the sinkhole) instead of the actual malicious C2 server. This meets all requirements: 1) It prevents compromised endpoints from contacting the real C2 server. 2) The sinkhole server's logs provide a clear track of which infected machines are attempting to make contact. 3) By preventing contact with the C2 server, it avoids the download of additional malicious payloads."
            },
            {
                "text": "Browser isolation",
                "correct": false,
                "explain": "Incorrect. Browser isolation protects the endpoint from web-based threats but does not prevent malware already on the system from making C2 connections."
            },
            {
                "text": "Zone transfer protection",
                "correct": false,
                "explain": "Incorrect. Zone transfer protection prevents attackers from enumerating all records in a DNS zone; it does not stop malware C2 traffic."
            },
            {
                "text": "HIDS",
                "correct": false,
                "explain": "Incorrect. A Host-based Intrusion Detection System (HIDS) can detect suspicious activity on a host but does not inherently provide the network-level redirection and logging capabilities of a DNS sinkhole."
            }
        ]
    },
    {
        "id": 155,
        "q": "Developers have been creating and managing cryptographic material on their personal laptops for use in the production environment. A security engineer needs to initiate a more secure process. Which of the following is the best strategy for the engineer to use?",
        "type": "single",
        "category": "3.4 Given a scenario, implement hardware security technologies and techniques.",
        "answers": [
            {
                "text": "Disabling the BIOS and moving to UEFI",
                "correct": false,
                "explain": "Incorrect. While UEFI is more secure than BIOS, this does not address the core problem of where cryptographic keys are being managed."
            },
            {
                "text": "Managing secrets on the vTPM hardware",
                "correct": false,
                "explain": "Incorrect. A virtual TPM (vTPM) is for virtual machines and is not the appropriate solution for centralized, high-assurance key management for a production environment."
            },
            {
                "text": "Employing shielding to prevent EMI",
                "correct": false,
                "explain": "Incorrect. Shielding protects against physical side-channel attacks and is not relevant to the insecure key management process described."
            },
            {
                "text": "Managing key material on a HSM",
                "correct": true,
                "explain": "Correct. A Hardware Security Module (HSM) is a dedicated, hardened cryptographic device designed for the secure generation, storage, and management of digital keys. It provides a high level of assurance that keys cannot be extracted. Moving key management from insecure developer laptops to a centralized, controlled HSM is the industry best practice and the best strategy to secure the process."
            }
        ]
    },
    {
        "id": 156,
        "q": "A nation-state actor is exposed for attacking large corporations by establishing persistence in smaller companies that are likely to be acquired by these large corporations. The actor then provisions user accounts in the companies for use post-acquisition. Before an upcoming acquisition, a security officer conducts threat modeling with this attack vector. Which of the following practices is the best way to investigate this threat?",
        "type": "single",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "Restricting internet traffic originating from countries in which the nation-state actor is known to operate",
                "correct": false,
                "explain": "Incorrect. Geoblocking is an unreliable control, as attackers can easily use proxies and VPNs from other countries."
            },
            {
                "text": "Comparing all existing credentials to personnel and services",
                "correct": true,
                "explain": "Correct. The threat vector involves provisioning dormant user accounts in the target company's systems before the acquisition. A key part of pre-acquisition due diligence should therefore be a thorough audit of all user accounts. This involves comparing the list of all existing user credentials in identity systems (like Active Directory) against official employee records (from HR) and service account documentation. Any account that cannot be tied to a current employee or a documented service is suspicious and could be a dormant account planted by an attacker."
            },
            {
                "text": "Auditing vendors to mitigate supply chain risk during the acquisition",
                "correct": false,
                "explain": "Incorrect. While supply chain risk is important, the specific threat described is about rogue accounts within the acquisition target itself, not its vendors."
            },
            {
                "text": "Placing a hold on all information about corporate interest in acquisitions",
                "correct": false,
                "explain": "Incorrect. While keeping acquisition plans confidential is a good business practice, it is not a technical investigation method to uncover an existing compromise."
            }
        ]
    },
    {
        "id": 157,
        "q": "After an incident response exercise, a security administrator reviews the following table: <br><br> <img src='../../assets/quiz-images/CAS-005_157.png' alt='Service criticality table'> <br><br> Which of the following should the administrator do to best support rapid incident response in the future?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "Automate alerting to IT support for phone system outages.",
                "correct": true,
                "explain": "Correct. The table shows that the Phone System has a 'Critical' criticality rating and a corresponding 'Critical' alert severity. In incident response, the goal is to reduce Mean Time to Respond (MTTR). For a critical system like this, response should be as rapid as possible. Automating the alerting process ensures that the moment a critical alert is triggered, the relevant support teams are notified immediately without manual intervention, enabling the fastest possible response."
            },
            {
                "text": "Enable dashboards for service status monitoring.",
                "correct": false,
                "explain": "Incorrect. Dashboards are useful for visualization but are a passive tool. Automated alerting is a proactive measure that pushes critical information to responders."
            },
            {
                "text": "Send emails for failed log-in attempts on the public website.",
                "correct": false,
                "explain": "Incorrect. The public website is rated 'Low' for both criticality and alert severity. While logging these events is good, focusing automation efforts on the 'Critical' rated phone system provides a better return on investment for improving response time."
            },
            {
                "text": "Configure automated isolation of human resources systems.",
                "correct": false,
                "explain": "Incorrect. The HR system is rated 'Medium,' not 'Critical.' While automated isolation (a SOAR function) is a powerful tool, priority should be given to the most critical systems first, which in this case is the phone system."
            }
        ]
    },
    {
        "id": 158,
        "q": "An organization is required to: Respond to internal and external inquiries in a timely manner. Provide transparency. Comply with regulatory requirements. The organization has not experienced any reportable breaches but wants to be prepared if a breach occurs in the future. Which of the following is the best way for the organization to prepare?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Outsourcing the handling of necessary regulatory filings to an external consultant",
                "correct": false,
                "explain": "Incorrect. While external help can be valuable, the organization must first have its own internal plan and pre-vetted materials."
            },
            {
                "text": "Integrating automated response mechanisms into the data subject access request process",
                "correct": false,
                "explain": "Incorrect. This is related to day-to-day privacy operations, not preparation for a major crisis or breach communication."
            },
            {
                "text": "Developing communication templates that have been vetted by internal and external counsel",
                "correct": true,
                "explain": "Correct. In the event of a breach, time is critical. Having to draft, review, and approve crisis communications from scratch while under pressure is a recipe for error and delay. The best way to prepare is to proactively develop communication templates for different scenarios and stakeholders (customers, regulators, employees, the public) and have these templates pre-approved by legal and compliance teams. This allows the organization to respond quickly and accurately when a crisis occurs."
            },
            {
                "text": "Conducting lessons-learned activities and integrating observations into the crisis management plan",
                "correct": false,
                "explain": "Incorrect. Lessons-learned activities happen *after* an incident or exercise. The organization is in the preparation phase."
            }
        ]
    },
    {
        "id": 159,
        "q": "An incident response team is analyzing malware and observes the following: Does not execute in a sandbox. No network IoCs. No publicly known hash match. No process injection method detected. Which of the following should the team do next to proceed with further analysis?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "Use an online virus analysis tool to analyze the sample.",
                "correct": false,
                "explain": "Incorrect. Submitting a potentially unique, targeted piece of malware to a public analysis tool could tip off the attacker and violate confidentiality."
            },
            {
                "text": "Check for an anti-virtualization code in the sample.",
                "correct": true,
                "explain": "Correct. The observation that the malware 'Does not execute in a sandbox' is a critical clue. Modern sandboxes are often virtualized environments. Sophisticated malware often includes anti-analysis techniques, such as code that checks for signs of virtualization (e.g., specific registry keys, MAC addresses, or CPU instructions). If it detects it's in a virtual machine, it will refuse to run to evade analysis. The next logical step is to perform static analysis or reverse engineering on the sample to find this anti-virtualization code."
            },
            {
                "text": "Utilize a new deployed machine to run the sample.",
                "correct": false,
                "explain": "Incorrect. Running the sample on a physical ('bare-metal') machine might make it execute, but this is a risky step to take before understanding its capabilities. First, the team should try to understand *why* it's not running in the sandbox."
            },
            {
                "text": "Search other internal sources for a new sample.",
                "correct": false,
                "explain": "Incorrect. While finding more samples is useful, the immediate task is to analyze the sample they already have."
            }
        ]
    },
    {
        "id": 160,
        "q": "Which of the following best explains the business requirement a healthcare provider fulfills by encrypting patient data at rest?",
        "type": "single",
        "category": "1.3 Explain how compliance affects information security strategies.",
        "answers": [
            {
                "text": "Securing data transfer between hospitals",
                "correct": false,
                "explain": "Incorrect. Securing data transfer involves encrypting data *in transit*, not at rest."
            },
            {
                "text": "Providing for non-repudiation of data",
                "correct": false,
                "explain": "Incorrect. Non-repudiation is typically provided by digital signatures, not by encryption."
            },
            {
                "text": "Reducing liability from identity theft",
                "correct": true,
                "explain": "Correct. Healthcare providers handle a vast amount of Protected Health Information (PHI), which is a prime target for identity theft. Regulations like HIPAA require providers to implement technical safeguards to protect this data. Encrypting patient data at rest (on servers and databases) is a critical safeguard. If an encrypted hard drive is stolen, the data remains confidential. Many breach notification laws have 'safe harbor' provisions, meaning if the lost or stolen data was encrypted, the provider may not have to publicly report the breach, thus reducing liability and reputational damage."
            },
            {
                "text": "Protecting privacy while supporting portability",
                "correct": false,
                "explain": "Incorrect. While related, the most direct business requirement fulfilled is the reduction of liability associated with a potential breach of sensitive patient information."
            }
        ]
    },
    {
        "id": 161,
        "q": "A security engineer is implementing security measures on new hardware in preparation for its launch. During the development phase, a risk related to protections at the UEFI level was found. Which of the following should the engineer recommend to reduce this risk?",
        "type": "single",
        "category": "3.4 Given a scenario, implement hardware security technologies and techniques.",
        "answers": [
            {
                "text": "Configuring paravirtualization protection",
                "correct": false,
                "explain": "Incorrect. Paravirtualization is a technique related to virtual machines and hypervisors, not a protection for the host system's UEFI firmware."
            },
            {
                "text": "Enabling Secure Boot",
                "correct": true,
                "explain": "Correct. Secure Boot is a security standard and a feature of the Unified Extensible Firmware Interface (UEFI). It is designed to protect the pre-boot process by ensuring that only trusted, digitally signed software (like the operating system bootloader) is loaded. This directly mitigates the risk of boot-level malware, like rootkits or bootkits, that target the UEFI firmware."
            },
            {
                "text": "Installing cryptography at the operational system level",
                "correct": false,
                "explain": "Incorrect. OS-level cryptography (like BitLocker) protects data at rest but does not protect the integrity of the UEFI firmware or the boot process itself."
            },
            {
                "text": "Implementing hardware root of trust",
                "correct": false,
                "explain": "Incorrect. While Secure Boot relies on a hardware root of trust, 'Enabling Secure Boot' is the specific action the engineer would recommend to mitigate a UEFI-level risk."
            }
        ]
    },
    {
        "id": 162,
        "q": "A development team must create a website to share indicators of compromise. The team wants to use APIs between industry peers to aid in configuring SIEM and SOAR. The team needs to create a free tier of service, and the senior developer insists on configuring rate limiting. Which of the following best describes the senior developer's reasoning?",
        "type": "single",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "To prevent password-spraying attacks on the services hosting the API",
                "correct": false,
                "explain": "Incorrect. While rate limiting can help against brute-force and password-spraying attacks on authentication endpoints, its primary purpose for a data-sharing API is to prevent resource exhaustion."
            },
            {
                "text": "To limit the likelihood of resource exhaustion occurring on the API server",
                "correct": true,
                "explain": "Correct. The developer is creating a free tier of service, which could be abused by a single user making an excessive number of API requests. This can overwhelm the server's CPU, memory, or bandwidth, leading to a denial of service (DoS) for all other legitimate users. Implementing rate limiting ensures fair usage by restricting the number of requests a single user can make in a given time period, thus preventing resource exhaustion."
            },
            {
                "text": "To address concerns the team has about API bandwidth utilization",
                "correct": false,
                "explain": "Incorrect. While bandwidth utilization is a component of resource exhaustion, 'resource exhaustion' is the broader and more accurate term for the risk being mitigated."
            },
            {
                "text": "To reduce attack surface exposure of the API endpoints connecting peers",
                "correct": false,
                "explain": "Incorrect. Rate limiting does not reduce the attack surface; it only throttles access to the existing surface."
            }
        ]
    },
    {
        "id": 163,
        "q": "A hotel chain wants to use point-of-sale systems to allow customers to check in and out of their rooms without employee assistance. These systems should limit access to a specific set of programs approved to run, with all other programs blocked. Which of the following should the company configure to best support this goal?",
        "type": "single",
        "category": "3.2 Given a scenario, analyze requirements to enhance the security of endpoints and servers.",
        "answers": [
            {
                "text": "Application control using a fresh image, with the applications fully configured as a baseline to build and block other applications from execution",
                "correct": true,
                "explain": "Correct. The requirement to only allow a specific set of approved programs to run is the definition of application control, specifically in an 'allowlisting' or 'whitelisting' mode. By creating a baseline image that contains only the necessary, approved applications and then configuring an application control solution to block all other executables, the company can create a secure, single-purpose kiosk system."
            },
            {
                "text": "A host-based intrusion detection system to monitor and block all suspicious activities if they occur on the systems",
                "correct": false,
                "explain": "Incorrect. A HIDS is a detective control, whereas application control is a preventative control. Preventing unauthorized programs from running in the first place is more secure than trying to detect their suspicious activity after they have already executed."
            },
            {
                "text": "Anti-malware on these systems and only approved application file locations can be bypassed",
                "correct": false,
                "explain": "Incorrect. Anti-malware is a good defense-in-depth measure, but it is reactive and signature-based. Application control is a proactive control that is more effective for creating a locked-down, kiosk-style system."
            },
            {
                "text": "Event logs to be collected from the systems for all security events and some custom application logs",
                "correct": false,
                "explain": "Incorrect. Logging is a detective control and does not prevent unauthorized applications from running."
            }
        ]
    },
    {
        "id": 164,
        "q": "A user reports application access issues to the help desk. The help desk reviews the logs for the user: <br><br> <img src='../../assets/quiz-images/CAS-005_164.png' alt='User access logs'> <br><br> Which of the following is most likely the reason for the issue?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "The user inadvertently tripped the geoblock rule in NGFW.",
                "correct": true,
                "explain": "Correct. The logs show the user successfully connecting to Email and the HR system from Los Angeles. Then, at 8:52 p.m., the user attempts to connect to the HR system again, but this time the source IP address is from Toronto. The access is denied. This is a classic 'impossible travel' scenario. A conditional access policy that uses geofencing or geoblocking likely detected the rapid change in location as suspicious and blocked the access attempt."
            },
            {
                "text": "A threat actor has compromised the user's account and attempted to log in.",
                "correct": false,
                "explain": "Incorrect. While a possibility, the most direct explanation based on the logs is the impossible travel condition triggering an automated policy. There is no other evidence of a compromise."
            },
            {
                "text": "The user is not allowed to access the human resources system outside of business hours.",
                "correct": false,
                "explain": "Incorrect. The user successfully accessed the HR system just minutes earlier (at 8:48 p.m.), so a time-based restriction is unlikely to be the cause."
            },
            {
                "text": "The user did not attempt to connect from an approved subnet.",
                "correct": false,
                "explain": "Incorrect. The logs show successful connections from both the internal subnet (10.10.2.21) and a public IP, so a subnet restriction is not the issue."
            }
        ]
    },
    {
        "id": 165,
        "q": "A company's security team is notified about vulnerabilities in the company's application. The security team determined these vulnerabilities were previously disclosed in third-party libraries. Which of the following solutions best allows the company to identify third-party vulnerabilities in the future?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Using IaC to include the newest dependencies",
                "correct": false,
                "explain": "Incorrect. Infrastructure as Code (IaC) is for managing infrastructure, not for analyzing software dependencies for vulnerabilities."
            },
            {
                "text": "Creating a bug bounty program",
                "correct": false,
                "explain": "Incorrect. A bug bounty program is a way to find vulnerabilities but is not a systematic tool for identifying known vulnerabilities in third-party components during development."
            },
            {
                "text": "Implementing a continuous security assessment program",
                "correct": false,
                "explain": "Incorrect. This is a very general term. An SCA tool is the specific solution for the problem described."
            },
            {
                "text": "Integrating a SCA tool as part of the pipeline",
                "correct": true,
                "explain": "Correct. The problem is with vulnerabilities in third-party libraries. A Software Composition Analysis (SCA) tool is designed specifically for this purpose. It scans an application's dependencies, creates a bill of materials, and checks those components against a database of known, publicly disclosed vulnerabilities. Integrating an SCA tool into the CI/CD pipeline allows these issues to be found automatically and early in the development process."
            }
        ]
    },
    {
        "id": 166,
        "q": "A global organization wants to manage all endpoint and user telemetry. The organization also needs to differentiate this data based on which office it is correlated to. Which of the following strategies best aligns with this goal?",
        "type": "single",
        "category": "2.3 Given a scenario, integrate appropriate controls in the design of a secure architecture.",
        "answers": [
            {
                "text": "Sensor placement",
                "correct": false,
                "explain": "Incorrect. While sensor placement is important for data collection, it doesn't solve the problem of differentiating the data after it has been collected in a central location."
            },
            {
                "text": "Data labeling",
                "correct": true,
                "explain": "Correct. Data labeling (or tagging) is the process of attaching metadata to data to provide context. To meet the requirement, the organization would configure its logging systems and agents to add a label or tag (e.g., 'office=NewYork', 'region=EMEA') to every log event. When the telemetry data is aggregated in a central SIEM, analysts can then easily filter, search, and create dashboards based on these labels to differentiate the data by office."
            },
            {
                "text": "Continuous monitoring",
                "correct": false,
                "explain": "Incorrect. Continuous monitoring is the overall process, not the specific technique used to differentiate the data."
            },
            {
                "text": "Centralized logging",
                "correct": false,
                "explain": "Incorrect. Centralized logging is a prerequisite, but it doesn't, by itself, provide the means to differentiate the data from different sources without a proper labeling strategy."
            }
        ]
    },
    {
        "id": 167,
        "q": "A security architect must make sure that the least number of services as possible is exposed in order to limit an adversary's ability to access the systems. Which of the following should the architect do first?",
        "type": "single",
        "category": "2.3 Given a scenario, integrate appropriate controls in the design of a secure architecture.",
        "answers": [
            {
                "text": "Enforce Secure Boot.",
                "correct": false,
                "explain": "Incorrect. Secure Boot protects the integrity of the boot process but does not reduce the number of running services."
            },
            {
                "text": "Perform attack surface reduction.",
                "correct": true,
                "explain": "Correct. The principle of limiting an adversary's access by exposing the minimum number of services is the definition of attack surface reduction (or attack surface management). This is a proactive, strategic process that involves identifying and disabling or protecting all potential points of entry for an attacker. This should be the architect's first and primary activity to meet the goal."
            },
            {
                "text": "Disable third-party integrations.",
                "correct": false,
                "explain": "Incorrect. Disabling third-party integrations is one possible tactic within a larger attack surface reduction strategy, but it is not the first or only action."
            },
            {
                "text": "Limit access to the systems.",
                "correct": false,
                "explain": "Incorrect. Limiting access (e.g., with firewall rules) is a critical step, but it is part of the implementation of an attack surface reduction plan. The first step is the analysis and planning involved in attack surface reduction itself."
            }
        ]
    },
    {
        "id": 168,
        "q": "A security officer performs due diligence activities before implementing a third-party solution into the enterprise environment. The security officer needs evidence from the third party that a data subject access request handling process is in place. Which of the following is the security officer most likely seeking to maintain compliance?",
        "type": "single",
        "category": "1.3 Explain how compliance affects information security strategies.",
        "answers": [
            {
                "text": "Information security standards",
                "correct": false,
                "explain": "Incorrect. While related, information security standards like ISO 27001 are broad. The specific requirement for handling data subject access requests points directly to privacy regulations."
            },
            {
                "text": "E-discovery requirements",
                "correct": false,
                "explain": "Incorrect. E-discovery relates to providing data for legal proceedings and is different from a data subject's right to access their own data."
            },
            {
                "text": "Privacy regulations",
                "correct": true,
                "explain": "Correct. The term 'data subject' and the concept of a 'data subject access request' (DSAR) are central components of modern privacy regulations like the GDPR (General Data Protection Regulation) and CCPA (California Consumer Privacy Act). These regulations grant individuals (data subjects) the right to request access to the personal data an organization holds about them. The security officer is performing due diligence to ensure the third-party vendor can comply with these legal and regulatory obligations."
            },
            {
                "text": "Certification requirements",
                "correct": false,
                "explain": "Incorrect. While a certification might attest to compliance, the underlying driver for the requirement is the privacy regulation itself."
            },
            {
                "text": "Reporting frameworks",
                "correct": false,
                "explain": "Incorrect. Reporting frameworks like SOC 2 can be used to provide evidence, but the core requirement comes from privacy laws."
            }
        ]
    },
    {
        "id": 169,
        "q": "An administrator needs to craft a single certificate-signing request for a web-server certificate. The server should be able to use the following identities to mutually authenticate other resources over TLS: www.int.comptia.org, webserver01.int.comptia.org, 10.5.100.10. Which of the following certificate fields must be set properly to support this objective?",
        "type": "single",
        "category": "2.4 Given a scenario, apply security concepts to the design of access, authentication, and authorization systems.",
        "answers": [
            {
                "text": "Subject alternative name",
                "correct": true,
                "explain": "Correct. A single digital certificate can be valid for multiple identities (like different hostnames or IP addresses) by listing them in the Subject Alternative Name (SAN) extension. Modern browsers and applications prioritize the SAN field over the legacy Common Name (CN) field. To have one certificate cover all three listed identities, they must all be included as SAN entries."
            },
            {
                "text": "Organizational unit",
                "correct": false,
                "explain": "Incorrect. The Organizational Unit (OU) field is part of the certificate's subject name but is for informational purposes and does not define the identities the certificate can be used for."
            },
            {
                "text": "Extended key usage",
                "correct": false,
                "explain": "Incorrect. The Extended Key Usage (EKU) field defines the purpose of the certificate (e.g., Server Authentication, Client Authentication). It does not list the hostnames or IPs."
            },
            {
                "text": "Certificate extension",
                "correct": false,
                "explain": "Incorrect. This is too generic. The SAN and EKU are both types of certificate extensions, but SAN is the specific one needed to list multiple identities."
            }
        ]
    },
    {
        "id": 170,
        "q": "A security analyst reviews the following event timeline from an EDR solution: <br><br> <img src='../../assets/quiz-images/CAS-005_170.png' alt='EDR event timeline'> <br><br> Which of the following has most likely occurred and needs to be fixed?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "The DLP has failed to block malicious exfiltration, and data tagging is not being utilized properly.",
                "correct": false,
                "explain": "Incorrect. While data was shared, the root cause of the compromise appears to be a flaw in the EDR's scanning logic, not a DLP failure."
            },
            {
                "text": "A NIDS bypass was utilized by a threat actor, and updates must be installed by the administrator.",
                "correct": false,
                "explain": "Incorrect. The log is from an EDR (host-based) solution, not a NIDS (network-based) solution."
            },
            {
                "text": "A logic flaw has introduced a TOCTOU vulnerability and must be addressed by the vendor.",
                "correct": true,
                "explain": "Correct. The timeline shows a classic Time-of-Check to Time-of-Use (TOCTOU) vulnerability, which is a type of race condition. At 4:09, the EDR initiates a scan on the file (the 'Time of Check'). However, at 4:10, before the scan is complete, the file is allowed to execute. The file then launches a script and shares another file. It is not until 4:19 that the scan finally completes and finds malware (the 'Time of Use'). The logic flaw in the EDR allowed the malicious file to be used before the check was complete. This is a vendor issue that needs to be fixed."
            },
            {
                "text": "A potential insider threat is being investigated and will be addressed by the senior management team.",
                "correct": false,
                "explain": "Incorrect. While an insider might have initiated the event, the technical root cause demonstrated in the logs is the TOCTOU vulnerability in the security software."
            }
        ]
    },
    {
        "id": 171,
        "q": "A hospital provides tablets to its medical staff to enable them to more quickly access and edit patients' charts. The hospital wants to ensure that if a tablet is identified as lost or stolen and a remote command is issued, the risk of data loss can be mitigated within seconds. The tablets are configured as follows to meet hospital policy: Full disk encryption is enabled. 'Always On' corporate VPN is enabled. eFuse-backed keystore is enabled/ready. Wi-Fi 6 is configured with SAE. Location services is disabled. Application allow list is unconfigured. Assuming the hospital policy cannot be changed, which of the following is the best way to meet the hospital's objective?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Revoke the user VPN and Wi-Fi certificates",
                "correct": false,
                "explain": "Incorrect. Revoking certificates would prevent the device from connecting to the network, but it would not erase the data already stored on the device."
            },
            {
                "text": "Cryptographically erase FDE volumes",
                "correct": true,
                "explain": "Correct. The requirement is to mitigate the risk of data loss within seconds. Cryptographic erase (or crypto-shredding) is the fastest and most effective way to achieve this. Since the tablets have Full Disk Encryption (FDE) and an eFuse-backed keystore, a remote command can be sent (via the always-on VPN) to securely and instantly delete the encryption key from the hardware keystore. Once the key is gone, the encrypted data on the disk is rendered permanently unrecoverable."
            },
            {
                "text": "Issue new MFA credentials to all users",
                "correct": false,
                "explain": "Incorrect. Changing MFA credentials for all users is disruptive and does not address the data stored on the specific lost device."
            },
            {
                "text": "Configure the application allow list",
                "correct": false,
                "explain": "Incorrect. Configuring an allow list is a preventative measure for new devices; it does not help sanitize a device that is already lost."
            }
        ]
    },
    {
        "id": 172,
        "q": "A compliance officer is facilitating a business impact analysis and wants business unit leaders to collect meaningful data. Several business unit leaders want more information about the types of data the officer needs. Which of the following data types would be the most beneficial for the compliance officer? (Choose two.)",
        "type": "multiple",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Inventory details",
                "correct": false,
                "explain": "Incorrect. While a list of systems is useful, the BIA's primary focus is on the business processes, not just the technical inventory."
            },
            {
                "text": "Applicable contract obligations",
                "correct": false,
                "explain": "Incorrect. Contract obligations are an input to the BIA but are not the primary data collected during it."
            },
            {
                "text": "Costs associated with downtime",
                "correct": true,
                "explain": "Correct. A key goal of a Business Impact Analysis (BIA) is to quantify the impact of an outage. Collecting data on the financial costs associated with the downtime of a process (e.g., lost revenue, fines, reputational damage) is a critical piece of information for prioritizing recovery efforts."
            },
            {
                "text": "Network diagrams",
                "correct": false,
                "explain": "Incorrect. Network diagrams are technical documents that are not part of the data collection for a BIA, which is a business-focused activity."
            },
            {
                "text": "Contingency plans",
                "correct": false,
                "explain": "Incorrect. Contingency plans are developed *after* the BIA is complete and are based on its findings. They are an output, not an input."
            },
            {
                "text": "Critical processes",
                "correct": true,
                "explain": "Correct. The first step and most fundamental piece of information in any Business Impact Analysis (BIA) is the identification and prioritization of the organization's critical business processes. Understanding which processes are most essential to the organization's survival is the foundation for all subsequent analysis."
            }
        ]
    },
    {
        "id": 173,
        "q": "An ISAC supplied recent threat intelligence information about pictures used on social media that provide reconnaissance of systems in use in secure facilities. In response, the Chief Information Security Officer (CISO) wants several configuration changes implemented via the MDM to ensure the following: Camera functions and location services are blocked for corporate mobile devices. All social media is blocked on the corporate and guest wireless networks. Which of the following is the CISO practicing to safeguard against the threat?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "Adversary emulation",
                "correct": false,
                "explain": "Incorrect. Adversary emulation involves simulating an attacker's TTPs to test defenses. The CISO is implementing preventative controls, not testing them."
            },
            {
                "text": "Operational security",
                "correct": true,
                "explain": "Correct. Operational Security (OPSEC) is a risk management process that focuses on preventing potential adversaries from discovering critical or sensitive information. The threat is that adversaries are gaining intelligence from photos posted on social media. The CISO's responseblocking cameras, location services, and social media accessis a direct attempt to deny the adversary this intelligence, which is the core principle of OPSEC."
            },
            {
                "text": "Open-source intelligence",
                "correct": false,
                "explain": "Incorrect. Open-Source Intelligence (OSINT) is the practice of collecting information from publicly available sources. The ISAC used OSINT to discover the threat, but the CISO is practicing OPSEC to defend against it."
            },
            {
                "text": "Social engineering",
                "correct": false,
                "explain": "Incorrect. Social engineering is the act of manipulating people. While the threat involves social media, the CISO's response is a technical and policy control, not an action against social engineering."
            }
        ]
    },
    {
        "id": 174,
        "q": "A company needs to define a new road map for improving secure coding practices in the software development life cycle and implementing better security standards. Which of the following is the best way for the company to achieve this goal?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Performing a Software Assurance Maturity Model assessment and generating a road map as a final result",
                "correct": true,
                "explain": "Correct. A Software Assurance Maturity Model (like OWASP SAMM or BSIMM) is a formal framework used to assess an organization's existing software security practices against a defined set of best practices. The assessment identifies strengths and weaknesses and provides a clear, data-driven basis for creating a strategic road map for improvement. This is the most structured and effective way to achieve the goal."
            },
            {
                "text": "Conducting a threat-modeling exercise for the main applications and developing a road map based on the necessary security implementations",
                "correct": false,
                "explain": "Incorrect. While threat modeling is a valuable activity for individual applications, a maturity model assessment provides a more holistic view of the entire development life cycle and is better suited for creating a strategic, organization-wide road map."
            },
            {
                "text": "Developing a new road map, including secure coding best practices, based on the security area road map and annual goals defined by the Chief Information Security Officer",
                "correct": false,
                "explain": "Incorrect. This is a top-down approach that lacks the detailed, data-driven insights that would come from a formal maturity assessment."
            },
            {
                "text": "Using the best practices in the OWASP secure coding manual to define a new road map",
                "correct": false,
                "explain": "Incorrect. The OWASP manual provides a list of best practices, but it doesn't provide a framework for assessing the company's current state or for building a prioritized road map. A maturity model like SAMM does."
            }
        ]
    },
    {
        "id": 175,
        "q": "A security architect wants to develop a baseline of security configurations. These configurations automatically will be utilized every time a new virtual machine is created. Which of the following technologies should the security architect deploy to accomplish this goal?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "Snort",
                "correct": false,
                "explain": "Incorrect. Snort is a network intrusion detection and prevention system; it does not manage system configurations."
            },
            {
                "text": "CASB",
                "correct": false,
                "explain": "Incorrect. A Cloud Access Security Broker (CASB) is used to enforce security policies for cloud application usage, not to configure virtual machine baselines."
            },
            {
                "text": "Ansible",
                "correct": true,
                "explain": "Correct. Ansible is a configuration management and automation tool. The architect can write an Ansible playbook that defines the desired security baseline (e.g., installing specific software, setting permissions, hardening services). This playbook can then be run automatically every time a new virtual machine is provisioned, ensuring all new systems are built to the correct, secure baseline. This is a core use case for tools like Ansible, Puppet, or Chef."
            },
            {
                "text": "CMDB",
                "correct": false,
                "explain": "Incorrect. A Configuration Management Database (CMDB) is a repository for storing information about IT assets. It is the record of the configurations, not the tool used to apply them."
            }
        ]
    },
    {
        "id": 176,
        "q": "A company wants to modify its process to comply with privacy requirements after an incident involving PII data in a development environment. In order to perform functionality tests, the QA team still needs to use valid data in the specified format. Which of the following best addresses the risk without impacting the development life cycle?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Encrypting the data before moving Into the QA environment",
                "correct": false,
                "explain": "Incorrect. Encrypted data would not be in a valid format for functionality testing, as the application would not be able to process it."
            },
            {
                "text": "Truncating the data to make it not personally identifiable",
                "correct": false,
                "explain": "Incorrect. Truncating data (e.g., showing only the last four digits of a social security number) might change its format, potentially breaking functionality tests that require a specific data structure."
            },
            {
                "text": "Using a large language model to generate synthetic data",
                "correct": true,
                "explain": "Correct. The requirement is to have data that is realistic and maintains a valid format but is not real PII. Using a large language model (LLM) or other tools to generate high-quality synthetic data is the ideal solution. This creates a dataset that looks and feels real, allowing the QA team to perform effective functionality tests without introducing the risk of using actual sensitive PII in a non-production environment."
            },
            {
                "text": "Utilizing tokenization for sensitive fields",
                "correct": false,
                "explain": "Incorrect. Tokenization replaces sensitive data with a non-sensitive token. While this protects the PII, the tokens themselves might not be in the correct format for all types of functionality testing. Synthetic data generation is a more robust solution for creating a complete and realistic test dataset."
            }
        ]
    },
    {
        "id": 177,
        "q": "A global organization is reviewing potential vendors to outsource a critical payroll function. Each vendor's plan includes using local resources in multiple regions to ensure compliance with all regulations. The organization's Chief Information Security Officer is conducting a risk assessment on the potential outsourcing vendors' subprocessors. Which of the following best explains the need for this risk assessment?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Risk mitigations must be more comprehensive than the existing payroll provider.",
                "correct": false,
                "explain": "Incorrect. While desirable, this is not the fundamental legal and regulatory reason for assessing subprocessors."
            },
            {
                "text": "Due care must be exercised during all procurement activities.",
                "correct": false,
                "explain": "Incorrect. While true, this is a general principle. There is a more specific reason related to data protection regulations."
            },
            {
                "text": "The responsibility of protecting PII remains with the organization.",
                "correct": true,
                "explain": "Correct. Under privacy regulations like GDPR, the ultimate responsibility and accountability for protecting personal data (like payroll information) always remains with the data controllerthe organization that collected the data. Even when they outsource processing to a vendor (the data processor), and that vendor uses its own vendors (subprocessors), the original organization is still liable for any breaches. Therefore, they must conduct due diligence and risk assessments on the entire supply chain, including subprocessors, to meet their legal obligations."
            },
            {
                "text": "Specific regulatory requirements must be met in each jurisdiction.",
                "correct": false,
                "explain": "Incorrect. While true, this explains why the vendor is using local resources. It doesn't explain why the CISO must assess those resources. The reason for the assessment is that the organization retains the ultimate responsibility."
            }
        ]
    },
    {
        "id": 178,
        "q": "An organization plans to deploy new software. The project manager compiles a list of roles that will be involved in different phases of the deployment life cycle. Which of the following should the project manager use to track these roles?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "CMDB",
                "correct": false,
                "explain": "Incorrect. A Configuration Management Database (CMDB) tracks IT assets and their configurations, not human roles and responsibilities in a project."
            },
            {
                "text": "Recall tree",
                "correct": false,
                "explain": "Incorrect. This is not a standard project management term for tracking roles."
            },
            {
                "text": "ITIL",
                "correct": false,
                "explain": "Incorrect. ITIL (Information Technology Infrastructure Library) is a framework of best practices for IT service management. It is not a tool for tracking roles in a specific project."
            },
            {
                "text": "RACI matrix",
                "correct": true,
                "explain": "Correct. A RACI matrix is a project management tool used to clarify and define roles and responsibilities for tasks and deliverables. RACI stands for Responsible, Accountable, Consulted, and Informed. It is the perfect tool for a project manager to document which roles are involved in each phase of a deployment and what their level of involvement is."
            }
        ]
    },
    {
        "id": 179,
        "q": "An organization decides to move to a distributed workforce model. Several legacy systems exist on premises and cannot be migrated because of existing compliance requirements. However, all new systems are required to be cloud-based. Which of the following would best ensure network access security?",
        "type": "single",
        "category": "2.6 Given a scenario, integrate Zero Trust concepts into system architecture design.",
        "answers": [
            {
                "text": "Utilizing a VPN for all users who require legacy system access",
                "correct": true,
                "explain": "Correct. The organization has a hybrid environment with both on-premises legacy systems and cloud-based systems, and a distributed workforce. A traditional VPN provides a secure, encrypted tunnel for remote users to connect to the on-premises network and access the legacy systems that cannot be moved to the cloud. This is a foundational component of securing access in such a hybrid, distributed model."
            },
            {
                "text": "Shifting all legacy systems to the existing public cloud infrastructure",
                "correct": false,
                "explain": "Incorrect. The scenario explicitly states that the legacy systems *cannot* be migrated due to compliance requirements."
            },
            {
                "text": "Configuring an SDN to block malicious traffic to on-premises networks",
                "correct": false,
                "explain": "Incorrect. While Software-Defined Networking (SDN) can be part of a solution, a VPN is the specific technology that provides secure remote access for the distributed workforce."
            },
            {
                "text": "Deploying microsegmentation with a firewall acting as the core router",
                "correct": false,
                "explain": "Incorrect. Microsegmentation is for securing east-west traffic within the data center. It does not provide secure access for remote users."
            }
        ]
    },
    {
        "id": 180,
        "q": "A web application server that provides services to hybrid modern and legacy financial applications recently underwent a scheduled upgrade to update common libraries, including OpenSSL. Multiple users are now reporting failed connection attempts to the server. The technician performing initial triage identified the following: Client applications more than five years old appear to be the most affected. Web server logs show initial connection attempts by affected hosts. For the failed connections, logs indicate 'cipher unavailable.' Which of the following is most likely to safely remediate this situation?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "The server needs to be configured for backward compatibility to SSL 3.0 applications.",
                "correct": false,
                "explain": "Incorrect. Re-enabling SSL 3.0 would be extremely insecure and should never be done."
            },
            {
                "text": "The client applications need to be modified to support AES in Galois/Counter Mode or equivalent",
                "correct": true,
                "explain": "Correct. The situation described is a classic cipher suite mismatch problem. The server's OpenSSL library was upgraded, and as part of this upgrade, old, insecure cipher suites that the legacy clients rely on were likely disabled. The server log 'cipher unavailable' confirms this. The correct, long-term, and secure solution is to update the old client applications so they can support modern, strong, authenticated encryption (AEAD) ciphers like AES-GCM, which the newly upgraded server now requires."
            },
            {
                "text": "The client TLS configuration must be set to enforce electronic codebook modes of operation",
                "correct": false,
                "explain": "Incorrect. Electronic Codebook (ECB) is an old and insecure mode of operation and should never be enforced."
            },
            {
                "text": "The server-side digital signature algorithm needs to be modified to support elliptic curve cryptography",
                "correct": false,
                "explain": "Incorrect. The issue is with the symmetric cipher suite used for the TLS session, not the server's digital signature algorithm."
            }
        ]
    },
    {
        "id": 181,
        "q": "An organization recently migrated data to a new file management system. The architect decides to use a discretionary authorization model on the new system. Which of the following best explains the architects choice?",
        "type": "single",
        "category": "2.4 Given a scenario, apply security concepts to the design of access, authentication, and authorization systems.",
        "answers": [
            {
                "text": "The responsibility of migrating data to the new file management system was outsourced to the vendor providing the platform.",
                "correct": false,
                "explain": "Incorrect. Who migrated the data is irrelevant to the choice of access control model."
            },
            {
                "text": "The permissions were not able to be migrated to the new system, and several stakeholders were made responsible for granting appropriate access.",
                "correct": true,
                "explain": "Correct. The defining characteristic of a Discretionary Access Control (DAC) model is that the owner of a resource has the discretion to grant or deny access to other users. The scenario states that permissions couldn't be migrated, and now multiple stakeholders (who would become the data owners) are responsible for granting access. This decentralized, owner-based permission management is exactly how a DAC model works."
            },
            {
                "text": "The legacy file management system did not support modern authentication techniques despite the business requirements.",
                "correct": false,
                "explain": "Incorrect. Authentication techniques are separate from the authorization model (DAC, MAC, RBAC)."
            },
            {
                "text": "The data custodians were selected by business stakeholders to ensure backups of the file management system are maintained off site.",
                "correct": false,
                "explain": "Incorrect. Data custodians are responsible for the technical maintenance of the system (like backups), not for granting permissions to the data."
            }
        ]
    },
    {
        "id": 182,
        "q": "An organization recently acquired another company that is running a different EDR solution. A SOC analyst wants to automate the isolation of endpoints that are found to be compromised. Which of the following workflows best mitigates the risk of false positives and reduces the spread of malicious code?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "Using a SOAR solution to look up entities via a TIP platform and isolate endpoints via APIs",
                "correct": true,
                "explain": "Correct. This workflow provides the best balance of automation and accuracy. A Security Orchestration, Automation, and Response (SOAR) platform can ingest alerts from both EDR solutions. It can then use automation to enrich these alerts by querying a Threat Intelligence Platform (TIP) for additional context. Based on this enriched, higher-fidelity data, it can then use APIs to instruct the appropriate EDR solution to isolate the endpoint. This automates the response while using intelligence to reduce the risk of isolating a machine due to a false positive."
            },
            {
                "text": "Setting a policy on each EDR management console to isolate all endpoints that trigger any alerts",
                "correct": false,
                "explain": "Incorrect. This would be very prone to false positives, potentially causing major business disruption by isolating non-compromised machines."
            },
            {
                "text": "Reviewing all alerts manually in the various portals and taking action to isolate them",
                "correct": false,
                "explain": "Incorrect. This is a manual process that would be slow and inefficient, failing to quickly reduce the spread of malicious code."
            },
            {
                "text": "Automating the suppression of all alerts that are not critical and sending an email asking SOC analysts to review these alerts",
                "correct": false,
                "explain": "Incorrect. Suppressing alerts increases risk. The goal is to automate the response to valid alerts, not to ignore them."
            }
        ]
    },
    {
        "id": 183,
        "q": "While reviewing recent incident reports a security officer discovers that several employees were contacted by the same individual who impersonated a recruiter. Which of the following best describes this type of correlation?",
        "type": "single",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "Spear-phishing campaign",
                "correct": true,
                "explain": "Correct. This activity is a campaign, which is a series of related attacks against a specific organization. Because it is targeted at specific employees (likely from their LinkedIn profiles) and uses a tailored lure (recruiter impersonation), it is classified as spear phishing. Correlating these individual incidents reveals the larger campaign."
            },
            {
                "text": "Threat modeling",
                "correct": false,
                "explain": "Incorrect. Threat modeling is a proactive process to identify potential threats and vulnerabilities. The security officer is analyzing events that have already occurred."
            },
            {
                "text": "Red-team assessment",
                "correct": false,
                "explain": "Incorrect. A red-team assessment is a planned exercise to test an organization's defenses. The activity described is a real attack."
            },
            {
                "text": "Attack pattern analysis",
                "correct": false,
                "explain": "Incorrect. While analyzing the attack pattern is part of the process, 'spear-phishing campaign' is the specific name for the correlated set of events described."
            }
        ]
    },
    {
        "id": 184,
        "q": "A news organization wants to implement workflows that allow users to request that untruthful data be retraced and scrubbed from online publications to comply with the right to be forgotten. Which of the following regulations is the organization most likely trying to address?",
        "type": "single",
        "category": "1.3 Explain how compliance affects information security strategies.",
        "answers": [
            {
                "text": "GDPR",
                "correct": true,
                "explain": "Correct. The 'right to be forgotten' (also known as the right to erasure) is a cornerstone of the European Union's General Data Protection Regulation (GDPR). It gives individuals the right to have their personal data erased under certain circumstances. A news organization implementing a workflow for this purpose is most likely doing so to comply with GDPR requirements."
            },
            {
                "text": "COPPA",
                "correct": false,
                "explain": "Incorrect. The Children's Online Privacy Protection Act (COPPA) is a US law that governs the online collection of personal information from children under 13."
            },
            {
                "text": "CCPA",
                "correct": false,
                "explain": "Incorrect. While the California Consumer Privacy Act (CCPA) has a 'right to delete,' the phrase 'right to be forgotten' is most famously and directly associated with GDPR."
            },
            {
                "text": "DORA",
                "correct": false,
                "explain": "Incorrect. The Digital Operational Resilience Act (DORA) is an EU regulation focused on the cybersecurity and operational resilience of financial entities."
            }
        ]
    },
    {
        "id": 185,
        "q": "An analyst wants to conduct a risk assessment on a new application that is being deployed. Given the following information: Total budget allocation for the new application is unavailable. Recovery time objectives have not been set. Downtime loss calculations cannot be provided. Which of the following statements describes the reason a qualitative assessment is the best option?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "The analyst has previous work experience in application development",
                "correct": false,
                "explain": "Incorrect. The analyst's experience does not dictate the type of risk assessment to be used."
            },
            {
                "text": "Sufficient metrics are not available to conduct other risk assessment types",
                "correct": true,
                "explain": "Correct. A quantitative risk assessment requires hard financial data, such as the monetary value of an asset, the cost of downtime per hour, and the expected cost of a single loss. The scenario explicitly states that this financial data is unavailable. A qualitative risk assessment, on the other hand, uses descriptive categories like High, Medium, and Low to evaluate risk based on subjective analysis. Given the lack of metrics, a qualitative assessment is the only feasible option."
            },
            {
                "text": "An organizational risk register tracks all risks and mitigations across business units",
                "correct": false,
                "explain": "Incorrect. A risk register is where the results of either a qualitative or quantitative assessment would be stored. Its existence doesn't determine which type of assessment is performed."
            },
            {
                "text": "The organization wants to find the monetary value of any outages",
                "correct": false,
                "explain": "Incorrect. If the organization wanted to find the monetary value, they would need to perform a quantitative assessment, but the scenario states the data needed for one is not available."
            }
        ]
    },
    {
        "id": 186,
        "q": "A software company deployed a new application based on its internal code repository. Several customers are reporting anti-malware alerts on workstations used to test the application. Which of the following is the most likely cause of the alerts?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Misconfigured code commit",
                "correct": false,
                "explain": "Incorrect. A misconfigured commit process is unlikely to cause anti-malware alerts."
            },
            {
                "text": "Unsecure bundled libraries",
                "correct": true,
                "explain": "Correct. Modern applications are built using numerous third-party and open-source libraries. It is very common for a developer to unknowingly include a library that has a known vulnerability or contains code that exhibits malware-like behavior (e.g., keylogging, network scanning). Anti-malware solutions often use signatures or heuristics that would flag this legitimate-but-vulnerable application, causing the alerts."
            },
            {
                "text": "Invalid code signing certificate",
                "correct": false,
                "explain": "Incorrect. An invalid code signing certificate would cause a warning from the operating system about an untrusted publisher, not typically an anti-malware alert."
            },
            {
                "text": "Data leakage",
                "correct": false,
                "explain": "Incorrect. Data leakage is an outcome of a potential vulnerability, not the cause of an anti-malware alert upon installation."
            }
        ]
    },
    {
        "id": 187,
        "q": "A security engineer is reviewing the following vulnerability scan report: <br><br> <img src='../../assets/quiz-images/CAS-005_187.png' alt='Vulnerability scan report'> <br><br> Which of the following should the engineer prioritize for remediation?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "Apache HTTP Server",
                "correct": false,
                "explain": "Incorrect. Although it has the highest CVSS score (9.7), the report states this server is not public-facing, which significantly reduces the immediate risk compared to exposed systems."
            },
            {
                "text": "OpenSSH",
                "correct": true,
                "explain": "Correct. When prioritizing vulnerabilities, both severity and exposure must be considered. The OpenSSH vulnerability on `comptia-rhe101` has a very high CVSS score (9.2) AND it is on a public-facing system. This combination of high technical severity and high accessibility makes it the highest-risk finding and the top priority for remediation."
            },
            {
                "text": "Google Chrome",
                "correct": false,
                "explain": "Incorrect. This vulnerability is on a non-public-facing system and has a lower CVSS score (8.5) than the OpenSSH vulnerability."
            },
            {
                "text": "Migration to TLS 1.3",
                "correct": false,
                "explain": "Incorrect. While a valid finding, the weak TLS protocol support on `web1.example.com` has a lower CVSS score (8.5) than the public-facing OpenSSH vulnerability (9.2)."
            }
        ]
    },
    {
        "id": 188,
        "q": "A company notices that cloud environment costs increased after using a new serverless solution based on API requests. Many invalid requests from unknown IPs were found, often within a short time. Which of the following solutions would most likely solve this issue, reduce cost, and improve security?",
        "type": "single",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "Using digital certificates for known customers and performing API authorization through those certificates",
                "correct": false,
                "explain": "Incorrect. While certificate-based authentication is strong, it can be complex to manage for a large customer base and doesn't address the issue of volumetric attacks from unknown IPs."
            },
            {
                "text": "Defining request rate limits and comparing new requests from unknown IPs with a list of known-malicious IPs",
                "correct": false,
                "explain": "Incorrect. This is part of a good solution, but it's incomplete. It lacks an authentication component for legitimate users."
            },
            {
                "text": "Setting authentication processes for the API requests as well as proper rate limits according to regular usage",
                "correct": true,
                "explain": "Correct. This is a comprehensive, two-part solution. First, requiring authentication (e.g., via API keys) ensures that only legitimate, paying customers can make valid requests. This immediately improves security. Second, implementing rate limiting prevents any single user (legitimate or malicious) from overwhelming the service with a high volume of requests, which solves the cost increase problem caused by the invalid requests and protects against denial-of-service attacks."
            },
            {
                "text": "Only allowing API requests coming from regions with known customers",
                "correct": false,
                "explain": "Incorrect. Geoblocking is an unreliable control and can inadvertently block legitimate customers who may be traveling or using VPNs."
            }
        ]
    },
    {
        "id": 189,
        "q": "A large organization deployed a generative AI platform for its global user population to use. Based on feedback received during beta testing, engineers have identified issues with user interface latency and page-loading performance for international users. The infrastructure is currently maintained within two separate data centers, which are connected using high-availability networking and load balancers. Which of the following is the best way to address the performance issues?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "Configuring the application to use a CDN",
                "correct": true,
                "explain": "Correct. The problem is high latency for international users, which is caused by the physical distance between the users and the organization's data centers. A Content Delivery Network (CDN) solves this by caching the application's static assets (like images, CSS, and JavaScript files) in points of presence (PoPs) all around the world. When an international user accesses the application, these assets are served from a nearby PoP instead of the distant data center, dramatically reducing latency and improving page-loading performance."
            },
            {
                "text": "Implementing RASP to enable large language models queuing",
                "correct": false,
                "explain": "Incorrect. RASP (Runtime Application Self-Protection) is a security tool and has nothing to do with improving network latency."
            },
            {
                "text": "Remote journaling within a third data center",
                "correct": false,
                "explain": "Incorrect. Remote journaling is a database replication technique for disaster recovery and does not improve front-end performance for global users."
            },
            {
                "text": "Traffic shaping through the use of a SASE",
                "correct": false,
                "explain": "Incorrect. SASE is a secure access architecture. While it can optimize routing, a CDN is the specific technology designed to solve the problem of latency for globally distributed static content."
            }
        ]
    },
    {
        "id": 190,
        "q": "A company reduced its staff 60 days ago, and applications are now starting to fail. The security analyst is investigating to determine if there is malicious intent for the application failures. The security analyst reviews the following logs: <br><br> <img src='../../assets/quiz-images/CAS-005_190.png' alt='SSH login logs'> <br><br> Which of the following is the most likely reason for the application failures?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "The users account was set as a service account",
                "correct": true,
                "explain": "Correct. The logs show multiple successful logins from different source IPs (`user01`, `user07`, `user03`) and multiple failed logins for a single account, `user10`. This pattern suggests that `user10` is likely a service account whose password was used by several applications or scheduled tasks. Since the staff reduction was 60 days ago, it's highly probable that `user10` belonged to a terminated employee. The company's password policy likely forced a password change or disabled the account after 60 days, causing all the applications and services that relied on that account's credentials to start failing."
            },
            {
                "text": "The user's home directory was deleted",
                "correct": false,
                "explain": "Incorrect. A deleted home directory would cause issues after a successful login, but the primary issue shown here is failed logins for a specific account."
            },
            {
                "text": "The user does not have sudo access.",
                "correct": false,
                "explain": "Incorrect. Lack of sudo access would cause permission errors, not login failures."
            },
            {
                "text": "The root password has been changed",
                "correct": false,
                "explain": "Incorrect. The logs show logins for specific user accounts, not the root account."
            }
        ]
    },
    {
        "id": 191,
        "q": "A security analyst detected unusual network traffic related to program updating processes. The analyst collected artifacts from compromised user workstations. The discovered artifacts were binary files with the same name as existing valid binaries but with different hashes. Which of the following solutions would most likely prevent this situation from reoccurring?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Improving patching processes",
                "correct": false,
                "explain": "Incorrect. The issue is not a lack of patching, but the fact that malicious files are masquerading as legitimate update files."
            },
            {
                "text": "Implementing digital signature",
                "correct": true,
                "explain": "Correct. The attack involves replacing legitimate binaries with malicious ones of the same name. A digital signature (achieved through code signing) would prevent this. The updating process would first check the digital signature of the received binary. If the binary is malicious, its hash will not match the hash in the signature, or the signature itself will be invalid. The system would then reject the update, preventing the execution of the malicious file."
            },
            {
                "text": "Performing manual updates via USB ports",
                "correct": false,
                "explain": "Incorrect. Manual updates are inefficient and introduce their own set of risks. This does not solve the core problem of verifying file authenticity."
            },
            {
                "text": "Allowing only files from internal sources",
                "correct": false,
                "explain": "Incorrect. This is difficult to enforce and doesn't guarantee that an internal source hasn't been compromised. Digital signatures provide a much stronger guarantee of integrity and authenticity."
            }
        ]
    },
    {
        "id": 192,
        "q": "Source code snippets for two separate malware samples are shown below: <br><br> <img src='../../assets/quiz-images/CAS-005_192.png' alt='Two malware code samples'> <br><br> Which of the following describes the most important observation about the two samples?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "Telemetry is first buffered and then transmitted in paranoid mode",
                "correct": false,
                "explain": "Incorrect. This is a misinterpretation of the code; 'paranoid' appears to be a string literal, not a transmission mode."
            },
            {
                "text": "The samples were probably written by the same developer.",
                "correct": true,
                "explain": "Correct. This question is about code stylometry, which is the analysis of programming style to attribute authorship. Both samples share distinct characteristics: they use a custom function named `knockEmDown`, similar variable naming conventions (`target`, `targetSys`, `c2`, `remote`), and a similar logic of calling a function and then sending its status to a C2 server. This high degree of similarity strongly suggests they were written by the same person or group."
            },
            {
                "text": "Both samples use IP connectivity for command and control",
                "correct": false,
                "explain": "Incorrect. While true, this is a very generic observation about malware. The unique, shared function name is a much more important observation for attribution."
            },
            {
                "text": "Sample 1 is the target agent while Sample 2 is the C2 server.",
                "correct": false,
                "explain": "Incorrect. Both samples appear to be client-side agents that are sending telemetry *to* a C2 server (`c2.sendTelemetry`, `remote.sendC2`). Sample 2 is not the server itself."
            }
        ]
    },
    {
        "id": 193,
        "q": "A systems engineer is configuring a system baseline for servers that will provide email services. As part of the architecture design, the engineer needs to improve performance of the systems by using an access vector cache, facilitating mandatory access control, and protecting against: Unauthorized reading and modification of data and programs, Bypassing application security mechanisms, Privilege escalation, Interference with other processes. Which of the following is the most appropriate for the engineer to deploy?",
        "type": "single",
        "category": "3.2 Given a scenario, analyze requirements to enhance the security of endpoints and servers.",
        "answers": [
            {
                "text": "SELinux",
                "correct": true,
                "explain": "Correct. Security-Enhanced Linux (SELinux) is a security architecture and kernel module for Linux that provides a mechanism for supporting Mandatory Access Control (MAC) policies. It meets all the listed requirements: it uses an Access Vector Cache (AVC) to improve performance, it is a MAC system, and its core purpose is to prevent processes from accessing files and resources they are not explicitly authorized for, thus protecting against privilege escalation, bypass attempts, and interference."
            },
            {
                "text": "Privileged access management",
                "correct": false,
                "explain": "Incorrect. A Privileged Access Management (PAM) solution is for managing and auditing the use of administrative accounts. It does not provide the low-level, process-to-file mandatory access control that SELinux does."
            },
            {
                "text": "Self-encrypting disks",
                "correct": false,
                "explain": "Incorrect. SEDs protect data at rest but do not provide the runtime process controls described."
            },
            {
                "text": "NIPS",
                "correct": false,
                "explain": "Incorrect. A Network Intrusion Prevention System (NIPS) operates at the network layer, not on the host to control process interactions."
            }
        ]
    },
    {
        "id": 194,
        "q": "A company migrated a critical workload from its data center to the cloud. The workload uses a very large data set that requires computational-intensive data processing. The business unit that uses the workload is projecting the following growth pattern: Storage requirements will double every six months. Computational requirements will fluctuate throughout the year. Average computational requirements will double every year. Which of the following should the company do to address the business unit's requirements?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "Deploy a cloud-based CDN for storage and a load balancer for compute",
                "correct": false,
                "explain": "Incorrect. A CDN is for caching and distributing content, not for primary storage of a large data set for computation."
            },
            {
                "text": "Combine compute and storage in vertically autoscaling mode",
                "correct": false,
                "explain": "Incorrect. Vertical scaling (making one server bigger) has limits and is often less cost-effective and resilient than horizontal scaling. Also, storage and compute have different scaling patterns and should be managed independently."
            },
            {
                "text": "Implement a load balancer for computing and storage resources",
                "correct": false,
                "explain": "Incorrect. You typically don't 'load balance' storage in this manner. Storage needs to scale its capacity, not balance requests across identical copies."
            },
            {
                "text": "Plan for a horizontally scaling computing and storage infrastructure",
                "correct": true,
                "explain": "Correct. This scenario is a perfect use case for cloud elasticity and horizontal scaling. The storage requirements show steady, rapid growth, which can be handled by scalable cloud storage services (like Amazon S3 or Azure Blob Storage). The computational requirements fluctuate and grow, which is best handled by a horizontally scaling architecture using an auto-scaling group of virtual machines behind a load balancer. This allows the company to add more compute instances to meet peak demand and remove them to save costs during lulls, while also allowing the storage to grow independently."
            }
        ]
    },
    {
        "id": 195,
        "q": "A security analyst received a notification from a cloud service provider regarding an attack detected on a web server. The cloud service provider shared the following information about the attack: The attack came from inside the network. The attacking source IP was from the internal vulnerability scanners. The scanner is not configured to target the cloud servers. Which of the following actions should the security analyst take first?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "Create an allow list for the vulnerability scanner IPs in order to avoid false positives",
                "correct": false,
                "explain": "Incorrect. The scanner should not be targeting the cloud servers in the first place. Allowlisting the traffic would legitimize the misconfiguration."
            },
            {
                "text": "Configure the scan policy to avoid targeting an out-of-scope host",
                "correct": false,
                "explain": "Incorrect. The information states the scanner is *already* not configured to target the cloud servers. This implies something else is wrong."
            },
            {
                "text": "Set network behavior analysis rules.",
                "correct": false,
                "explain": "Incorrect. While useful, this is a general monitoring improvement, not the first action to take in response to this specific alert."
            },
            {
                "text": "Quarantine the scanner sensor to perform a forensic analysis",
                "correct": true,
                "explain": "Correct. The information presents a major contradiction: the attack traffic is coming from an internal vulnerability scanner, but that scanner is not configured to scan the target. This is a strong indicator that the vulnerability scanner itself has been compromised by an attacker and is being used as a pivot point to attack other systems on the network. The first and most critical action is to treat the scanner as a compromised host, isolate (quarantine) it from the network to stop the attack, and begin a forensic analysis to determine the extent of the compromise."
            }
        ]
    },
    {
        "id": 196,
        "q": "A company implemented a NIDS and a NIPS on the most critical environments. Since this implementation the company has been experiencing network connectivity issues. Which of the following should the security architect recommend for a new NIDS/NIPS implementation?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "Implementing the NIDS with a port mirror in the core switch and the NIPS in the main firewall",
                "correct": true,
                "explain": "Correct. This architecture correctly separates the roles of the two devices to avoid connectivity issues. A Network Intrusion Detection System (NIDS) is a passive, out-of-band device. Connecting it to a mirrored (SPAN) port on a switch allows it to see all traffic without being in the actual data path, so it cannot cause connectivity issues. A Network Intrusion Prevention System (NIPS) must be inline to block traffic. Integrating it with the main firewall (or placing it directly behind it) is a standard inline deployment that allows it to inspect and prevent threats while minimizing added points of failure."
            },
            {
                "text": "Implementing the NIDS and the NIPS together with the main firewall",
                "correct": false,
                "explain": "Incorrect. Placing both inline can increase complexity and the potential for failure. The NIDS should be out-of-band."
            },
            {
                "text": "Implementing a NIDS without a NIPS to increase the detection capability",
                "correct": false,
                "explain": "Incorrect. This would remove the prevention capability, which is a key security control."
            },
            {
                "text": "Implementing the NIDS in the bastion host and the NIPS in the branch network router",
                "correct": false,
                "explain": "Incorrect. A NIDS is a network device, not something installed on a single host. Placing a NIPS at a branch router may not protect the critical environments effectively."
            }
        ]
    },
    {
        "id": 197,
        "q": "The material findings from a recent compliance audit indicate a company has an issue with excessive permissions. The findings show that employees changing roles or departments results in privilege creep. Which of the following solutions are the best ways to mitigate this issue? (Choose two.)",
        "type": "multiple",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "Setting different access controls defined by business area",
                "correct": false,
                "explain": "Incorrect. This describes the general goal but is not a specific, actionable control."
            },
            {
                "text": "Implementing a role-based access policy",
                "correct": true,
                "explain": "Correct. Privilege creep occurs when users accumulate permissions over time as they move between jobs. A Role-Based Access Control (RBAC) policy helps mitigate this. When an employee changes roles, their old role (and all its associated permissions) should be removed, and their new role (with its specific permissions) should be assigned. This enforces the principle of least privilege."
            },
            {
                "text": "Designing a least-needed privilege policy",
                "correct": false,
                "explain": "Incorrect. This is another name for the principle of least privilege. Implementing RBAC and periodic reviews are the *actions* taken to enforce this principle."
            },
            {
                "text": "Establishing a mandatory vacation policy",
                "correct": false,
                "explain": "Incorrect. Mandatory vacations are a control used to detect fraud, not to manage privilege creep."
            },
            {
                "text": "Performing periodic access reviews",
                "correct": true,
                "explain": "Correct. Even with RBAC, mistakes can happen. A periodic access review is a critical detective and corrective control. It involves having managers or data owners regularly review the access rights of their employees to ensure they are still appropriate for their current job roles. This process identifies and allows for the removal of excessive permissions accumulated through privilege creep."
            },
            {
                "text": "Requiring periodic job rotation",
                "correct": false,
                "explain": "Incorrect. Job rotation is a control to detect fraud and provide cross-training; it does not solve the problem of users accumulating permissions."
            }
        ]
    },
    {
        "id": 198,
        "q": "A security analyst is reviewing a SIEM and generates the following report: <br><br> <img src='../../assets/quiz-images/CAS-005_198.png' alt='SIEM log report showing parsing issue'> <br><br> Later, the incident response team notices an attack was executed on the VM001 host. Which of the following should the security analyst do to enhance the alerting process on the SIEM platform?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "Include the EDR solution on the SIEM as a new log source",
                "correct": false,
                "explain": "Incorrect. While adding more log sources is good, the fundamental problem shown in the log is that the existing logs are not being parsed or correlated correctly."
            },
            {
                "text": "Perform a log correlation on the SIEM solution",
                "correct": false,
                "explain": "Incorrect. The analyst should create correlation *rules*, but the root issue is with the format of the log data itself."
            },
            {
                "text": "Improve parsing of data on the SIEM",
                "correct": true,
                "explain": "Correct. The log entry for the 'Malware detection' event is poorly formatted. It appears to be a raw, unstructured string containing multiple pieces of information (`10.1.1.1,192.168.2.2,VM001,1822 Malware detection, 8:11:12`) crammed into a single field. Because the SIEM cannot properly parse this, it cannot extract the critical event type ('Malware detection') and trigger the appropriate high-priority alert. Improving the log parser for this data source would allow the SIEM to recognize this as a critical event and alert on it properly in the future."
            },
            {
                "text": "Create a new rule set to detect malware",
                "correct": false,
                "explain": "Incorrect. You cannot create an effective rule to detect malware if the SIEM cannot even parse the log event that identifies the malware in the first place."
            }
        ]
    },
    {
        "id": 199,
        "q": "A security administrator is performing a gap assessment against a specific OS benchmark. The benchmark requires the following configurations be applied to endpoints: Full disk encryption, Host-based firewall, Time synchronization, Password policies, Application allow listing, Zero Trust application access. Which of the following solutions best addresses the requirements? (Choose two.)",
        "type": "multiple",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "MDM",
                "correct": true,
                "explain": "Correct. A Mobile Device Management (MDM) or a more modern Unified Endpoint Management (UEM) solution is designed to enforce configuration policies on endpoints. It can enforce settings like requiring full disk encryption, configuring the host-based firewall, and managing password policies."
            },
            {
                "text": "CASB",
                "correct": false,
                "explain": "Incorrect. A CASB enforces policies on cloud application usage, not on endpoint OS configurations."
            },
            {
                "text": "SBoM",
                "correct": false,
                "explain": "Incorrect. A Software Bill of Materials (SBoM) lists the components of a piece of software; it is not a configuration enforcement tool."
            },
            {
                "text": "SCAP",
                "correct": true,
                "explain": "Correct. The Security Content Automation Protocol (SCAP) is a suite of standards used to automate vulnerability management and security policy compliance. A SCAP scanner can be used to perform the gap assessment by comparing the endpoint's configuration against a benchmark (defined in an XCCDF file), and it can be used with remediation tools to automatically apply the required configurations. It is the perfect tool for assessing and enforcing a formal benchmark."
            },
            {
                "text": "SASE",
                "correct": false,
                "explain": "Incorrect. SASE is a network security architecture and does not enforce host-level configuration baselines."
            },
            {
                "text": "HIDS",
                "correct": false,
                "explain": "Incorrect. A Host-based Intrusion Detection System (HIDS) detects suspicious activity but does not enforce configuration settings."
            }
        ]
    },
    {
        "id": 200,
        "q": "A security analyst is reviewing the following authentication logs: <br><br> <img src='../../assets/quiz-images/CAS-005_200.png' alt='Authentication logs showing password spray'> <br><br> Which of the following should the analyst do first?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "Disable User2s account.",
                "correct": false,
                "explain": "Incorrect. User2's account shows four failed login attempts from a single machine (VM01). While this could be a brute-force attempt, the pattern across the whole log is more indicative of a password spray."
            },
            {
                "text": "Disable User12s account",
                "correct": false,
                "explain": "Incorrect. User12 had a single successful login, which is not suspicious on its own."
            },
            {
                "text": "Disable User8s account",
                "correct": false,
                "explain": "Incorrect. User8 had one failed login and one successful login from the same machine (VM08). This is not the most suspicious activity in the log."
            },
            {
                "text": "Disable User1s account",
                "correct": true,
                "explain": "Correct. The logs show a classic password spraying attack. At the exact same second (8:01:23 AM), an attacker tried the same (likely common) password against multiple user accounts (`User1`, `User8`, `User12`, `User2`). This attack resulted in a successful login for `User1` and `User12`. Since `User1` was successfully compromised, their account poses an immediate threat to the environment and should be disabled first to contain the incident."
            }
        ]
    },
    {
        "id": 201,
        "q": "A game developer wants to reach new markets and is advised by legal counsel to include specific age-related sign-up requirements. Which of the following best describes the legal counsel's concerns?",
        "type": "single",
        "category": "1.3 Explain how compliance affects information security strategies.",
        "answers": [
            {
                "text": "GDPR",
                "correct": false,
                "explain": "Incorrect. While GDPR has rules regarding the age of consent for data processing, COPPA is the US law specifically focused on online services directed at children."
            },
            {
                "text": "LGPD",
                "correct": false,
                "explain": "Incorrect. LGPD is Brazil's General Data Protection Law. Unless the new market is specifically Brazil, this is less likely to be the primary concern than the broader US law."
            },
            {
                "text": "PCI DSS",
                "correct": false,
                "explain": "Incorrect. The Payment Card Industry Data Security Standard (PCI DSS) applies to the handling of credit card information, not age verification for games."
            },
            {
                "text": "COPPA",
                "correct": true,
                "explain": "Correct. The Children's Online Privacy Protection Act (COPPA) is a United States federal law that governs the online collection of personal information from children under the age of 13. It requires websites and online services to obtain verifiable parental consent before collecting personal information from children. A game developer is a prime example of an online service that would need to be very concerned with COPPA compliance, making this the most likely reason for legal counsel's advice."
            }
        ]
    },
    {
        "id": 202,
        "q": "Which of the following AI concerns is most adequately addressed by input sanitization?",
        "type": "single",
        "category": "1.5 Summarize the information security challenges associated with artificial intelligence (AI) adoption.",
        "answers": [
            {
                "text": "Model inversion",
                "correct": false,
                "explain": "Incorrect. Model inversion attacks attempt to reconstruct sensitive training data by repeatedly querying the model. This is not prevented by input sanitization."
            },
            {
                "text": "Prompt injection",
                "correct": true,
                "explain": "Correct. Prompt injection is an attack where an adversary crafts malicious input to manipulate a large language model (LLM), causing it to ignore its previous instructions or perform unintended actions. Input sanitization, which is the process of cleaning, filtering, and validating user-provided data, is a direct defense against this by stripping out the malicious instructions from the prompt before it reaches the model."
            },
            {
                "text": "Data poisoning",
                "correct": false,
                "explain": "Incorrect. Data poisoning targets the model's training data, not the live input prompts from users. It is a supply chain attack on the model itself."
            },
            {
                "text": "Non-explainable model",
                "correct": false,
                "explain": "Incorrect. This refers to the 'black box' nature of some AI models and is a characteristic, not an attack that can be prevented by sanitizing input."
            }
        ]
    },
    {
        "id": 203,
        "q": "A company that operates in different countries has local email infrastructure for each of its business units. A breach occurred in which email communications were intercepted between the headquarters and one of the overseas business units. During an investigation, the security analyst finds the following email log: <br><br> <img src='../../assets/quiz-images/CAS-005_203.png' alt='ESMTP log showing TLS failure'> <br><br> Which of the following actions should the security analyst take to best address the issue?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "Revoke the expired TLS certificate and replace it with a valid one",
                "correct": false,
                "explain": "Incorrect. While the certificate is expired (issued in 2018), the more critical security failure is that the system continued the communication in cleartext after the TLS negotiation failed. Simply replacing the certificate doesn't fix this fallback behavior."
            },
            {
                "text": "Disable the NTLM authentication and replace it with TLS 1.2",
                "correct": false,
                "explain": "Incorrect. NTLM is listed as an available authentication method, but it is separate from the TLS encryption failure. The core issue is the failure of STARTTLS."
            },
            {
                "text": "Change the TLS configuration from opportunistic to enforced",
                "correct": true,
                "explain": "Correct. The log shows the server attempting encryption with STARTTLS, but the 'TLS Negotiation failed' error is followed by a successful `MAIL FROM` command, indicating the email was sent in cleartext. This is known as opportunistic TLS. To prevent interception, the configuration should be changed to mandatory or enforced TLS, which would cause the connection to be dropped entirely if the TLS handshake fails, rather than falling back to an insecure, unencrypted connection."
            },
            {
                "text": "Create a new TLS certificate using a stronger algorithm and larger key",
                "correct": false,
                "explain": "Incorrect. While a good practice, this does not fix the fundamental configuration flaw that allows the server to send email in cleartext when encryption fails."
            }
        ]
    },
    {
        "id": 204,
        "q": "During a recent audit, a company's systems were assessed. Given the following information: <br><br> <img src='../../assets/quiz-images/CAS-005_204.png' alt='System audit status table'> <br><br> Which of the following is the best way to reduce the attack surface?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Deploying an EDR solution to all impacted machines in manufacturing",
                "correct": false,
                "explain": "Incorrect. An EDR is a detective and responsive control. A preventative control is needed to reduce the attack surface."
            },
            {
                "text": "Segmenting the manufacturing network with a firewall and placing the rules in monitor mode",
                "correct": false,
                "explain": "Incorrect. Monitor mode is for detection, not prevention. To reduce the attack surface, the firewall rules would need to be in blocking mode."
            },
            {
                "text": "Setting up an IDS inline to monitor and detect any threats to the software",
                "correct": false,
                "explain": "Incorrect. An IDS is a passive detection system and cannot be placed inline (that would be an IPS). It detects threats but does not reduce the attack surface."
            },
            {
                "text": "Implementing an application-aware firewall and writing strict rules for the application access",
                "correct": true,
                "explain": "Correct. The ProductionControl system is running End-of-Life (EOL) software, which means it can no longer be patched and presents a significant risk. The best way to reduce the attack surface for this system is to implement a compensating control. An application-aware firewall (like a WAF or NGFW) can be used to create very strict rules that only allow the specific, known-good traffic required for the application to function, while blocking everything else. This significantly reduces the likelihood that an attacker can exploit the unpatched EOL software."
            }
        ]
    },
    {
        "id": 205,
        "q": "A global manufacturing company has an internal application that is critical to making products. This application cannot be updated and must be available in the production area. A security architect is implementing security for the application. Which of the following best describes the action the architect should take?",
        "type": "single",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "Disallow wireless access to the application.",
                "correct": false,
                "explain": "Incorrect. This might be part of a solution, but it doesn't solve the core problem of protecting an un-updatable application from threats on the wired network."
            },
            {
                "text": "Deploy intrusion detection capabilities using a network tap",
                "correct": false,
                "explain": "Incorrect. Intrusion detection is a detective control. A preventative control is more effective for protecting a critical, vulnerable system."
            },
            {
                "text": "Create an acceptable use policy for the use of the application",
                "correct": false,
                "explain": "Incorrect. An AUP is an administrative control and does not provide technical protection for the application."
            },
            {
                "text": "Create a separate network for users who need access to the application",
                "correct": true,
                "explain": "Correct. Since the application is critical but cannot be updated, it represents a significant, un-patchable risk. The best practice for securing such a legacy system is to use network segmentation. By creating a separate, isolated network segment (an enclave) for the application and its users, and placing strict firewall controls between that segment and the rest of the corporate network, the architect can severely limit the application's exposure to threats. This contains the risk associated with the vulnerable application."
            }
        ]
    },
    {
        "id": 206,
        "q": "A company wants to perform threat modeling on an internally developed, business-critical application. The Chief Information Security Officer (CISO) is most concerned that the application should maintain 99.999% availability and authorized users should only be able to gain access to data they are explicitly authorized to view. Which of the following threat-modeling frameworks directly addresses the CISOs concerns about this system?",
        "type": "single",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "CAPEC",
                "correct": false,
                "explain": "Incorrect. CAPEC (Common Attack Pattern Enumeration and Classification) is a dictionary of common attack patterns; it is not a methodology for threat modeling an entire system."
            },
            {
                "text": "STRIDE",
                "correct": true,
                "explain": "Correct. STRIDE is a threat modeling methodology that helps identify and classify threats into six categories. The CISO's concerns map directly to these categories: 1) 'Denial of Service' addresses the 99.999% availability requirement. 2) 'Information Disclosure' and 'Elevation of Privilege' address the requirement that users only access data they are authorized to view. The other categories are Spoofing, Tampering, and Repudiation."
            },
            {
                "text": "ATT&CK",
                "correct": false,
                "explain": "Incorrect. The MITRE ATT&CK framework is a knowledge base of adversary tactics and techniques. It's useful for understanding how attackers operate but is not a system-centric threat modeling framework like STRIDE."
            },
            {
                "text": "TAXII",
                "correct": false,
                "explain": "Incorrect. TAXII is a protocol for exchanging threat intelligence; it is not a threat modeling framework."
            }
        ]
    },
    {
        "id": 207,
        "q": "A company's internal network is experiencing a security breach and the threat actor is still active. Due to business requirements, users in this environment are allowed to utilize multiple machines at the same time. Given the following log snippet: <br><br> <img src='../../assets/quiz-images/CAS-005_207.png' alt='EDR log of blocked processes'> <br><br> Which of the following accounts should a security analyst disable to best contain the incident without impacting valid users?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "user-a",
                "correct": false,
                "explain": "Incorrect. user-a attempted to run `mmc.exe` and `appwiz.exe`, which are legitimate Windows administration tools. This could be a sysadmin doing their job."
            },
            {
                "text": "user-b",
                "correct": false,
                "explain": "Incorrect. user-b attempted to run `setup.exe` and `msconfig.exe`, which could be legitimate software installation or system configuration tasks."
            },
            {
                "text": "user-c",
                "correct": false,
                "explain": "Incorrect. user-c attempted to run `appwiz.cpl` (Add/Remove Programs) and `cmd.exe` (Command Prompt), which could be legitimate administrative activity."
            },
            {
                "text": "user-d",
                "correct": true,
                "explain": "Correct. The activity from user-d is the most suspicious and indicative of an active threat actor. At 11:18, they attempt to run `firefox.exe` (potentially to download tools) and immediately at 11:19, they attempt to run `cmd.com`. `cmd.com` is a legacy command interpreter that is highly unusual to see in a modern environment; its use is a strong indicator of an attacker attempting to use living-off-the-land techniques to bypass security controls that monitor the more common `cmd.exe`. Disabling this account is the most direct way to contain the suspected active threat."
            }
        ]
    },
    {
        "id": 208,
        "q": "A security team is responding to malicious activity and needs to determine the scope of impact. The malicious activity appears to affect a certain version of an application used by the organization. Which of the following actions best enables the team to determine the scope of impact?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "Performing a port scan",
                "correct": false,
                "explain": "Incorrect. A port scan would identify open ports but not the specific application versions running on those ports."
            },
            {
                "text": "Inspecting egress network traffic",
                "correct": false,
                "explain": "Incorrect. Inspecting egress traffic might help identify already-compromised hosts communicating outbound, but it won't identify all potentially vulnerable hosts."
            },
            {
                "text": "Reviewing the asset inventory",
                "correct": true,
                "explain": "Correct. To determine the scope of impact for a vulnerability affecting a specific application version, the response team's first step is to identify all assets running that version. A well-maintained asset inventory, ideally from a Configuration Management Database (CMDB), would allow the team to quickly query for all hosts with the vulnerable application installed, thus defining the full scope of potentially impacted systems."
            },
            {
                "text": "Analyzing user behavior",
                "correct": false,
                "explain": "Incorrect. User behavior analysis is useful for detecting anomalies but is not the way to get a definitive list of all systems running a specific software version."
            }
        ]
    },
    {
        "id": 209,
        "q": "An organization recently implemented a policy that requires all passwords to be rotated every 90 days. An administrator sees a large volume of failed sign-on logs from multiple servers that are often accessed by users. The administrator determines users are disconnecting from the RDP session but not logging off. Which of the following should the administrator do to prevent account lockouts?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Increase the account lockout threshold",
                "correct": false,
                "explain": "Incorrect. This would only delay the lockout; it doesn't fix the root cause of the failed logon attempts."
            },
            {
                "text": "Enforce password complexity",
                "correct": false,
                "explain": "Incorrect. Password complexity is unrelated to the problem of stale, disconnected sessions causing lockouts."
            },
            {
                "text": "Automate logout of inactive sessions",
                "correct": true,
                "explain": "Correct. The problem is that users change their password, but their old, disconnected RDP sessions on various servers are still running and trying to authenticate with the old, cached credentials. This causes multiple failed logon attempts and triggers an account lockout. By configuring a group policy to automatically log out inactive or disconnected sessions after a certain period, the administrator ensures these stale sessions are terminated, preventing them from causing lockouts after a password change."
            },
            {
                "text": "Extend the allowed session length",
                "correct": false,
                "explain": "Incorrect. Extending the session length would make the problem worse, allowing the stale sessions to persist for longer."
            }
        ]
    },
    {
        "id": 210,
        "q": "A security review revealed that not all of the client proxy traffic is being captured. Which of the following architectural changes best enables the capture of traffic for analysis?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "Adding an additional proxy server to each segmented VLAN",
                "correct": false,
                "explain": "Incorrect. This would increase complexity and still wouldn't guarantee all traffic is captured if clients can bypass the proxy."
            },
            {
                "text": "Setting up a reverse proxy for client logging at the gateway",
                "correct": false,
                "explain": "Incorrect. A reverse proxy is used to protect servers by handling incoming requests from clients. It does not capture outbound traffic from clients."
            },
            {
                "text": "Configuring a span port on the perimeter firewall to ingest logs",
                "correct": true,
                "explain": "Correct. A SPAN (Switched Port Analyzer) port, also known as a mirror port, on a network device like a firewall or core switch can be configured to send a copy of all network traffic passing through it to a specific monitoring device (like an IDS or a packet capture tool). By configuring a SPAN port on the perimeter firewall, which all client traffic must pass through to reach the internet, the organization can ensure that all outbound traffic is captured for analysis, even if some clients have misconfigured or bypassed the proxy server."
            },
            {
                "text": "Enabling client device logging and system event auditing",
                "correct": false,
                "explain": "Incorrect. While useful, client-side logging can be tampered with or disabled. Capturing traffic at a central network chokepoint like the firewall provides a more reliable and complete picture."
            }
        ]
    },
    {
        "id": 211,
        "q": "A subcontractor develops safety critical avionics software for a major aircraft manufacturer. After an incident, a third-party investigator recommends the company begin to employ formal methods in the development life cycle. Which of the following findings from the investigation most directly supports the investigator's recommendation?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "The systems bill of materials failed to include commercial and open-source libraries.",
                "correct": false,
                "explain": "Incorrect. This finding would support a recommendation to implement Software Composition Analysis (SCA), not formal methods."
            },
            {
                "text": "The company lacks dynamic and interactive application security testing standards.",
                "correct": false,
                "explain": "Incorrect. This finding would support a recommendation to implement DAST or IAST, not formal methods."
            },
            {
                "text": "The codebase lacks traceability to functional and non-functional requirements.",
                "correct": true,
                "explain": "Correct. Formal methods are a set of mathematically rigorous techniques used to specify, develop, and verify software and hardware systems. A key part of this process is creating a formal specification of the system's requirements and then using mathematical proof to verify that the implementation correctly meets that specification. The finding that the codebase lacks traceability to its requirements directly points to a failure that formal methods are designed to solve. For safety-critical software like avionics, this level of mathematical assurance is essential."
            },
            {
                "text": "The implemented software inefficiently manages compute and memory resources.",
                "correct": false,
                "explain": "Incorrect. This finding would support a recommendation for performance testing or code refactoring, not necessarily formal methods."
            }
        ]
    },
    {
        "id": 212,
        "q": "A security architect is onboarding a new EDR agent on servers that traditionally do not have internet access. In order for the agent to receive updates and report back to the management console, some changes must be made. Which of the following should the architect do to best accomplish this requirement? (Choose two.)",
        "type": "multiple",
        "category": "3.2 Given a scenario, analyze requirements to enhance the security of endpoints and servers.",
        "answers": [
            {
                "text": "Create a firewall rule to only allow traffic from the subnet to the internet via a proxy.",
                "correct": true,
                "explain": "Correct. The principle of least privilege dictates that these servers should not have direct, unrestricted internet access. The firewall rule should be configured to force all outbound traffic from this server subnet to go through an explicit proxy server. This creates a single, controlled chokepoint for the traffic."
            },
            {
                "text": "Configure a proxy policy that blocks all traffic on port 443",
                "correct": false,
                "explain": "Incorrect. This would block the EDR agent's communication, as it almost certainly uses HTTPS on port 443."
            },
            {
                "text": "Configure a proxy policy that allows only fully qualified domain names needed to communicate to a portal",
                "correct": true,
                "explain": "Correct. After forcing traffic to the proxy, a policy must be created on the proxy server itself. This policy should be an allowlist that only permits connections to the specific, fully qualified domain names (FQDNs) of the EDR vendor's management and update portals. All other outbound connections should be blocked. This provides the necessary access for the EDR agent while maintaining the security principle of least privilege."
            },
            {
                "text": "Create a firewall rule to only allow traffic from the subnet to the internet via port 443.",
                "correct": false,
                "explain": "Incorrect. This is too permissive. It would allow the servers to connect to any destination on the internet over port 443, not just the required EDR portals."
            },
            {
                "text": "Create a firewall rule to only allow traffic from the subnet to the internet to fully qualified names that are not identified as malicious by the firewall vendor",
                "correct": false,
                "explain": "Incorrect. This is still too permissive. The policy should be a strict allowlist of only the required domains, not a blocklist of known-bad domains."
            },
            {
                "text": "Configure a proxy policy that blocks only lists of known-bad fully qualified domain names",
                "correct": false,
                "explain": "Incorrect. A blocklist (denylisting) approach is much less secure than an allowlist (whitelisting) approach. The policy should deny all by default and only permit the known-good FQDNs."
            }
        ]
    },
    {
        "id": 213,
        "q": "Due to an infrastructure optimization plan, a company has moved from a unified architecture to a federated architecture divided by region. Long-term employees now have a better experience, but new employees are experiencing major performance issues when traveling between regions. The company is reviewing the following information: <br><br> <img src='../../assets/quiz-images/CAS-005_213.png' alt='Access logs for two employees'> <br><br> Which of the following is the most effective action to remediate the issue?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Creating a new user entry in the affected region for the affected employee",
                "correct": false,
                "explain": "Incorrect. This would be a manual, inefficient workaround and would result in the user having multiple identities, which goes against best practices."
            },
            {
                "text": "Synchronizing all regions' user identities and ensuring ongoing synchronization",
                "correct": true,
                "explain": "Correct. The logs show that Employee 1, likely a long-term employee, can access systems in both the Americas and Europe. Employee 2, a new employee, can access systems in the Americas but is denied in Europe. This indicates that when the architecture was split, only existing user identities were federated or synchronized. New user identities, like Employee 2's, are only being created in their home region. The most effective solution is to implement a process that ensures all user identities are synchronized across all regional identity stores, and that this synchronization is ongoing for any new or modified accounts."
            },
            {
                "text": "Restarting European region physical access control systems",
                "correct": false,
                "explain": "Incorrect. The issue is with the user's digital identity, not a fault in the physical access control system itself. Restarting it would not solve the problem."
            },
            {
                "text": "Resyncing single sign-on application with connected security appliances",
                "correct": false,
                "explain": "Incorrect. The issue is with the backend identity stores, not the SSO application's connection to them. The SSO application is likely working correctly but simply cannot find Employee 2's identity in the European directory."
            }
        ]
    },
    {
        "id": 214,
        "q": "A company hosts a platform-as-a-service solution with a web-based front end, through which customers interact with data sets. A security administrator needs to deploy controls to prevent application-focused attacks. Which of the following most directly supports the administrators objective?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "Improving security dashboard visualization on SIEM",
                "correct": false,
                "explain": "Incorrect. Dashboards are for detection and visibility, not prevention of attacks."
            },
            {
                "text": "Rotating API access and authorization keys every two months",
                "correct": false,
                "explain": "Incorrect. While key rotation is a good practice, it doesn't prevent application-layer attacks like SQL injection or XSS."
            },
            {
                "text": "Implementing application load balancing and cross-region availability",
                "correct": false,
                "explain": "Incorrect. These controls provide availability and resilience but do not directly prevent application-focused attacks."
            },
            {
                "text": "Creating WAF policies for relevant programming languages",
                "correct": true,
                "explain": "Correct. A Web Application Firewall (WAF) is a security control specifically designed to protect web applications from application-layer attacks like SQL injection, Cross-Site Scripting (XSS), and others. By creating and tuning WAF policies relevant to the application's programming language and frameworks, the administrator can effectively prevent a wide range of common application-focused attacks."
            }
        ]
    },
    {
        "id": 215,
        "q": "A software engineer is creating a CI/CD pipeline to support the development of a web application. The DevSecOps team is required to identify syntax errors. Which of the following is the most relevant to the DevSecOps team's task?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Static application security testing",
                "correct": true,
                "explain": "Correct. Static Application Security Testing (SAST) tools analyze source code without executing it. A key function of these tools, in addition to finding security vulnerabilities, is to identify basic programming errors, including syntax errors, that would prevent the code from compiling or running correctly. This is often the very first check in a CI/CD pipeline."
            },
            {
                "text": "Software composition analysis",
                "correct": false,
                "explain": "Incorrect. SCA tools identify vulnerabilities in third-party libraries, they do not check for syntax errors in the custom code."
            },
            {
                "text": "Runtime application self-protection",
                "correct": false,
                "explain": "Incorrect. RASP is a runtime protection technology; it does not check for syntax errors during the build process."
            },
            {
                "text": "Web application vulnerability scanning",
                "correct": false,
                "explain": "Incorrect. This refers to DAST, which scans a running application. If the code had syntax errors, it wouldn't be able to run in the first place."
            }
        ]
    },
    {
        "id": 216,
        "q": "A security officer received several complaints from users about excessive MFA push notifications at night. The security team investigates and suspects malicious activities regarding user account authentication. Which of the following is the best way for the security officer to restrict MFA notifications?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Provisioning FIDO2 devices",
                "correct": true,
                "explain": "Correct. The attack described is an 'MFA fatigue' or 'push bombing' attack, where an attacker who has a user's password repeatedly triggers MFA push notifications, hoping the user will get annoyed and accidentally approve one. FIDO2/WebAuthn is a phishing-resistant authentication standard that mitigates this. It requires the user to be in possession of a physical hardware key (the FIDO2 device) and often requires a user interaction (like touching the key). This breaks the attacker's ability to remotely trigger and benefit from push notifications."
            },
            {
                "text": "Deploying a text message based on MFA",
                "correct": false,
                "explain": "Incorrect. SMS-based MFA is considered less secure than push notifications and is vulnerable to SIM-swapping attacks. It would not solve the fatigue attack problem."
            },
            {
                "text": "Enabling OTP via email",
                "correct": false,
                "explain": "Incorrect. Email-based OTP is also a weak form of MFA. If the attacker has the user's password, they may also have access to their email."
            },
            {
                "text": "Configuring prompt-driven MFA",
                "correct": false,
                "explain": "Incorrect. 'Prompt-driven MFA' is another term for the push notifications that are currently being abused. This would not solve the problem."
            }
        ]
    },
    {
        "id": 217,
        "q": "A security analyst is troubleshooting the reason a specific user is having difficulty accessing company resources. The analyst reviews the following information: <br><br> <img src='../../assets/quiz-images/CAS-005_217.png' alt='MFA and sign-in status log'> <br><br> Which of the following is most likely the cause of the issue?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "The local network access has been configured to bypass MFA requirements.",
                "correct": true,
                "explain": "Correct. The log for user ACCT1 shows a successful login with 'Allowed' status from the internal IP `192.168.4.18`, but the 'MFA satisfied?' column says 'No'. All other successful logins required MFA. This indicates that a conditional access policy has been configured to trust the local network and bypass MFA requirements for users connecting from that location. This is a common, though potentially risky, configuration to improve user experience in the office."
            },
            {
                "text": "A network geolocation is being misidentified by the authentication server.",
                "correct": false,
                "explain": "Incorrect. The geolocations appear to be correctly identified (Germany, France). The blocked access for SALES1 from Germany when their assigned location is France is likely a correct policy enforcement, not a misidentification."
            },
            {
                "text": "Administrator access from an alternate location is blocked by company policy.",
                "correct": false,
                "explain": "Incorrect. There is no information to suggest any of these are administrator accounts. The logs for SALES1 and ACCT1 show them being blocked from an alternate location, which is likely a correct policy at work."
            },
            {
                "text": "Several users have not configured their mobile devices to receive OTP codes.",
                "correct": false,
                "explain": "Incorrect. Most of the users are clearly satisfying MFA, indicating their devices are configured correctly. The one exception (ACCT1 on the local network) points to a policy bypass, not a configuration failure."
            }
        ]
    },
    {
        "id": 218,
        "q": "An organization is looking for gaps in its detection capabilities based on the APTs that may target the industry. Which of the following should the security analyst use to perform threat modeling?",
        "type": "single",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "ATT&CK",
                "correct": true,
                "explain": "Correct. The MITRE ATT&CK framework is a globally accessible knowledge base of adversary tactics and techniques based on real-world observations. It provides a common vocabulary for describing how threat actors, including specific APT groups, operate. A security analyst can use the framework to understand the TTPs used by APTs that target their industry and then map those TTPs against their own detection capabilities to identify gaps."
            },
            {
                "text": "OWASP",
                "correct": false,
                "explain": "Incorrect. The Open Web Application Security Project (OWASP) focuses specifically on web application vulnerabilities (like the OWASP Top 10). It is not as broad as ATT&CK for modeling advanced adversary behavior across an enterprise."
            },
            {
                "text": "CAPEC",
                "correct": false,
                "explain": "Incorrect. CAPEC (Common Attack Pattern Enumeration and Classification) is a dictionary of attack patterns but is less comprehensive and widely used for modeling adversary TTPs than the ATT&CK framework."
            },
            {
                "text": "STRIDE",
                "correct": false,
                "explain": "Incorrect. STRIDE is a threat modeling methodology used during the design phase to identify potential threats to a system based on general categories (Spoofing, Tampering, etc.). It is not a knowledge base of observed adversary TTPs."
            }
        ]
    },
    {
        "id": 219,
        "q": "A security analyst needs to ensure email domains that send phishing attempts without previous communications are not delivered to mailboxes. The following email headers are being reviewed: <br><br> <img src='../../assets/quiz-images/CAS-005_219.png' alt='Email header log'> <br><br> Which of the following is the best action for the security analyst to take?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "Block messages from hr-saas.com because it is not a recognized domain",
                "correct": false,
                "explain": "Incorrect. Blocking an entire SaaS provider's domain could have significant business impact if it's a legitimate service used by the company."
            },
            {
                "text": "Reroute all messages with unusual security warning notices to the IT administrator",
                "correct": false,
                "explain": "Incorrect. This is a reactive measure and would create a large volume of work for the administrator. A preventative block is better."
            },
            {
                "text": "Quarantine all messages with sales-mail.com in the email header",
                "correct": true,
                "explain": "Correct. The first email shows a 'Sending domain' of `sales.com` but a 'Reply-to domain' of `sales-mail.com`. This mismatch is a classic indicator of a phishing or spoofing attempt. The attacker is trying to make the email look like it came from the legitimate `sales.com` but wants the victim's reply to go to their malicious `sales-mail.com` domain. Quarantining all messages from this suspicious reply-to domain is the most appropriate action."
            },
            {
                "text": "Block vendor.com for repeated attempts to send suspicious messages",
                "correct": false,
                "explain": "Incorrect. The emails from `vendor.com` have matching sending and reply-to domains. While one subject line is suspicious, blocking the entire domain of what could be a legitimate vendor is too drastic based on this limited information."
            }
        ]
    },
    {
        "id": 220,
        "q": "A systems administrator needs to identify new attacks that could be carried out against the environment. The administrator plans to proactively seek out and observe new attacks. Which of the following is the best way to accomplish this goal?",
        "type": "single",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "Configuring an IPS",
                "correct": false,
                "explain": "Incorrect. An Intrusion Prevention System (IPS) is designed to block known attacks, not to proactively seek out and observe new ones."
            },
            {
                "text": "Implementing sandboxing",
                "correct": false,
                "explain": "Incorrect. Sandboxing is a technique for analyzing suspicious files in an isolated environment. It doesn't attract or observe new attacks from the wild."
            },
            {
                "text": "Scanning for IoCs",
                "correct": false,
                "explain": "Incorrect. Scanning for Indicators of Compromise (IoCs) is a reactive measure to find evidence of past or current attacks, not to observe new ones."
            },
            {
                "text": "Deploying a honeypot",
                "correct": true,
                "explain": "Correct. A honeypot is a decoy computer system designed to be an attractive target for attackers. It is intentionally configured to be vulnerable to attract attacks. By deploying a honeypot and monitoring it, the administrator can proactively observe the latest attack techniques, tools, and malware being used by attackers in the wild, providing valuable intelligence without risking production systems."
            }
        ]
    },
    {
        "id": 221,
        "q": "A company experienced a data breach, resulting in the disclosure of extremely sensitive data regarding a merger. As a regulated entity, the company must comply with reporting and disclosure requirements. The company is concerned about its public image and shareholder values. Which of the following best supports the organization in addressing its concerns?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Data subject access request",
                "correct": false,
                "explain": "Incorrect. A DSAR is a process for individuals to request their data; it is not a plan for managing a major corporate crisis."
            },
            {
                "text": "Business impact analysis",
                "correct": false,
                "explain": "Incorrect. A BIA is a planning activity conducted before an incident to assess potential impacts. It does not guide the response to a current crisis."
            },
            {
                "text": "Supply chain management program",
                "correct": false,
                "explain": "Incorrect. An SCRM program manages risks from third parties and is not a plan for responding to a breach."
            },
            {
                "text": "Crisis management plan",
                "correct": true,
                "explain": "Correct. A crisis management plan is a strategic document that outlines how an organization will respond to a major event that threatens its operations, reputation, or financial stability. A data breach involving sensitive merger information is a significant crisis. The crisis management plan would define the roles, responsibilities, and communication strategies for engaging with regulators, shareholders, the public, and the media to manage the company's public image and meet disclosure requirements in a controlled manner."
            }
        ]
    },
    {
        "id": 222,
        "q": "Company A acquired Company B and needs to determine how the acquisition will impact the attack surface of the organization as a whole. Which of the following is the best way to achieve this goal? (Choose two.)",
        "type": "multiple",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "Implementing DLP controls preventing sensitive data from leaving Company B's network",
                "correct": false,
                "explain": "Incorrect. Implementing controls is a remediation step that would happen after the assessment of the attack surface."
            },
            {
                "text": "Documenting third-party connections used by Company B",
                "correct": true,
                "explain": "Correct. An organization's attack surface includes all of its external connections. When acquiring a new company, it is critical to identify and document all of that company's existing third-party connections (e.g., to vendors, partners, and cloud services), as each of these represents a potential new entry point for an attacker into the combined organization."
            },
            {
                "text": "Reviewing the privacy policies currently adopted by Company B",
                "correct": false,
                "explain": "Incorrect. Reviewing policies is a compliance activity, not a technical assessment of the attack surface."
            },
            {
                "text": "Requiring data sensitivity labeling for all files shared with Company B",
                "correct": false,
                "explain": "Incorrect. Data labeling is a data governance control and does not help in determining the network and system-level attack surface."
            },
            {
                "text": "Forcing a password reset requiring more stringent passwords for users on Company B's network",
                "correct": false,
                "explain": "Incorrect. Improving password policy is a good security hygiene step but is not part of the initial assessment to understand the new attack surface."
            },
            {
                "text": "Performing an architectural review of Company B's network",
                "correct": true,
                "explain": "Correct. A thorough architectural review is fundamental to understanding the new attack surface. This involves analyzing network diagrams, data flows, and identifying all internally and externally facing assets of the acquired company. This review provides a comprehensive picture of the systems and pathways that Company A is inheriting and must now protect."
            }
        ]
    },
    {
        "id": 223,
        "q": "After an incident occurred, a team reported during the lessons-learned review that the team: Lost important information for further analysis. Did not utilize the chain of communication. Did not follow the right steps for a proper response. Which of the following solutions is the best way to address these findings?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "Requesting budget for better forensic tools to improve technical capabilities for incident response operations",
                "correct": false,
                "explain": "Incorrect. While better tools might help, the core findings point to procedural and process failures (communication, following steps), not a lack of tools."
            },
            {
                "text": "Building playbooks for different scenarios and performing regular table-top exercises",
                "correct": true,
                "explain": "Correct. The findings indicate a lack of structured, repeatable processes for incident response. A playbook provides a detailed, step-by-step guide for responding to a specific type of incident (e.g., ransomware, phishing). It defines the correct steps, communication channels, and data collection procedures. Regularly practicing these playbooks through tabletop exercises ensures the team knows how to use them effectively. This directly addresses all the reported failures."
            },
            {
                "text": "Requiring professional incident response certifications for each new team member",
                "correct": false,
                "explain": "Incorrect. While certifications provide good foundational knowledge, they do not replace the need for organization-specific procedures and practice."
            },
            {
                "text": "Publishing the incident response policy and enforcing it as part of the security awareness program",
                "correct": false,
                "explain": "Incorrect. A policy is a high-level document. The team needs detailed, actionable procedures, which are found in playbooks."
            }
        ]
    },
    {
        "id": 224,
        "q": "A security analyst is reviewing the following code in the public repository for potential risk concerns: <br><br> <img src='../../assets/quiz-images/CAS-005_224.png' alt='Code snippet with hardcoded token'> <br><br> Which of the following should the security analyst recommend first to remediate the vulnerability?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Developing role-based security awareness training",
                "correct": false,
                "explain": "Incorrect. While training developers not to hardcode secrets is important, the immediate priority is to address the existing exposed secret."
            },
            {
                "text": "Revoking the secret used in the solution",
                "correct": true,
                "explain": "Correct. The code shows a hardcoded access token (`spat-hfeiw...`) that has been committed to a public repository. This secret must be considered compromised. The very first and most urgent step is to revoke this token in the system where it is used to immediately invalidate it and prevent an attacker from using it to gain unauthorized access."
            },
            {
                "text": "Purging code from public view",
                "correct": false,
                "explain": "Incorrect. Even if the code is removed from the current view, the secret will still exist in the repository's commit history and on various clones and forks. The only way to neutralize the threat is to revoke the secret itself."
            },
            {
                "text": "Scanning the application with SAST",
                "correct": false,
                "explain": "Incorrect. A SAST scan would find the hardcoded secret, but the analyst has already found it manually. The first remediation step is to revoke the compromised secret, not to run another scan."
            }
        ]
    },
    {
        "id": 225,
        "q": "After remote desktop capabilities were deployed in the environment various vulnerabilities were noticed: Exfiltration of intellectual property, Unencrypted files, Weak user passwords. Which of the following is the best way to mitigate these vulnerabilities? (Choose two.)",
        "type": "multiple",
        "category": "3.2 Given a scenario, analyze requirements to enhance the security of endpoints and servers.",
        "answers": [
            {
                "text": "Implementing data loss prevention",
                "correct": true,
                "explain": "Correct. A Data Loss Prevention (DLP) solution is specifically designed to address the risk of intellectual property exfiltration. It can monitor and block the transfer of sensitive data outside of the network, including over remote desktop sessions."
            },
            {
                "text": "Deploying file integrity monitoring",
                "correct": false,
                "explain": "Incorrect. FIM detects changes to files but does not prevent their exfiltration or enforce password policies."
            },
            {
                "text": "Restricting access to critical file services only",
                "correct": false,
                "explain": "Incorrect. While a good practice, this does not address the issues of unencrypted files or weak passwords."
            },
            {
                "text": "Deploying directory-based group policies",
                "correct": false,
                "explain": "Incorrect. While group policies can enforce some settings, enabling modern authentication is a more direct fix for weak passwords, and DLP is the specific tool for exfiltration."
            },
            {
                "text": "Enabling modern authentication that supports MFA",
                "correct": true,
                "explain": "Correct. The vulnerability of 'weak user passwords' is best mitigated by moving away from password-only authentication. Enabling modern authentication methods that require Multifactor Authentication (MFA) adds a critical layer of security, ensuring that a weak or stolen password alone is not enough to gain access."
            },
            {
                "text": "Implementing a version control system",
                "correct": false,
                "explain": "Incorrect. A version control system is for managing source code and is not relevant to securing remote desktop access."
            },
            {
                "text": "Implementing a CMDB platform",
                "correct": false,
                "explain": "Incorrect. A CMDB is an asset inventory and is not a security control to mitigate the listed vulnerabilities."
            }
        ]
    },
    {
        "id": 226,
        "q": "An audit finding reveals that a legacy platform has not retained logs for more than 30 days. The platform has been segmented due to its interoperability with newer technology. As a temporary solution, the IT department changed the log retention to 120 days. Which of the following should the security engineer do to ensure the logs are being properly retained?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "Configure a scheduled task nightly to save the logs.",
                "correct": false,
                "explain": "Incorrect. This is a fragile, manual approach that doesn't provide the benefits of centralized management, correlation, and secure long-term storage."
            },
            {
                "text": "Configure event-based triggers to export the logs at a threshold.",
                "correct": false,
                "explain": "Incorrect. Waiting for a threshold could result in log loss if the system fails before the threshold is met. A continuous stream is better."
            },
            {
                "text": "Configure the SIEM to aggregate the logs.",
                "correct": true,
                "explain": "Correct. The legacy platform has limited local storage for logs. The best practice is to configure a log forwarding agent (like syslog-ng or a vendor agent) on the legacy system to send a real-time stream of its logs to a central Security Information and Event Management (SIEM) system. The SIEM is designed for secure, long-term log aggregation and retention from disparate sources, which solves the retention problem and also allows the security team to correlate these logs with events from other systems."
            },
            {
                "text": "Configure a Python script to move the logs into a SQL database.",
                "correct": false,
                "explain": "Incorrect. This is a custom-built solution that would be difficult to maintain and would lack the advanced security and analysis features of a commercial or open-source SIEM."
            }
        ]
    },
    {
        "id": 227,
        "q": "A company recently experienced an incident in which an advanced threat actor was able to shim malicious code against the hardware stack of a domain controller. The forensic team cryptographically validated that both the underlying firmware of the box and the operating system had not been compromised. However, the attacker was able to exfiltrate information from the server using a steganographic technique within LDAP. Which of the following is the best way to reduce the risk of reoccurrence?",
        "type": "single",
        "category": "3.4 Given a scenario, implement hardware security technologies and techniques.",
        "answers": [
            {
                "text": "Enforcing allow lists for authorized network ports and protocols",
                "correct": false,
                "explain": "Incorrect. The attacker is using a legitimate, required protocol (LDAP) for exfiltration. A simple port/protocol allowlist would not stop this."
            },
            {
                "text": "Measuring and attesting to the entire boot chain",
                "correct": true,
                "explain": "Correct. The scenario describes a sophisticated attack that bypassed firmware and OS integrity checks, suggesting a compromise occurred in an unmeasured part of the boot process (like option ROMs or peripheral firmware). A measured boot process, which uses a hardware root of trust (like a TPM) to cryptographically measure every single component from the moment the power is turned on (firmware, drivers, bootloader, kernel, etc.), creates a complete and trustworthy record of the system's state. Remote attestation can then validate this record. This comprehensive measurement of the entire boot chain is the best way to detect the type of low-level shimming attack described."
            },
            {
                "text": "Rolling the cryptographic keys used for hardware security modules",
                "correct": false,
                "explain": "Incorrect. There is no indication that the HSM keys were compromised. The issue is a compromise of the boot process integrity."
            },
            {
                "text": "Using code signing to verify the source of OS updates",
                "correct": false,
                "explain": "Incorrect. The forensic team already validated that the OS was not compromised, so verifying OS updates would not have prevented this attack."
            }
        ]
    },
    {
        "id": 228,
        "q": "A company designs policies and procedures for hardening containers deployed in the production environment. However, a security assessment reveals that deployed containers are not complying with the security baseline. Which of the following solutions best addresses this issue throughout early life-cycle stages?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Installing endpoint agents on each container and setting them to report when configurations drift from the baseline",
                "correct": false,
                "explain": "Incorrect. This is a detective control that finds non-compliance in production. The goal is to address the issue in the early life-cycle stages."
            },
            {
                "text": "Finding hardened container images and enforcing them as the baseline for new deployments",
                "correct": false,
                "explain": "Incorrect. While using hardened base images is a good practice, it doesn't guarantee that the final deployed container will be compliant. The CI/CD pipeline is the enforcement point."
            },
            {
                "text": "Creating a pipeline to check the containers through security gates and validating the baseline controls before the final deployment",
                "correct": true,
                "explain": "Correct. The problem is that non-compliant containers are reaching production. The best way to solve this early in the life cycle is to integrate automated checks into the Continuous Integration/Continuous Deployment (CI/CD) pipeline. This involves adding a 'security gate' to the pipeline that automatically scans the container image for compliance with the hardening baseline before it can be promoted to the production environment. If the container fails the compliance check, the build fails, and it is never deployed."
            },
            {
                "text": "Running security assessments regularly and checking for the security baseline on containers already in production",
                "correct": false,
                "explain": "Incorrect. This is a detective measure that finds the problem after it has already occurred. A CI/CD pipeline check is a preventative measure."
            }
        ]
    },
    {
        "id": 229,
        "q": "A security architect for a global organization with a distributed workforce recently received funding to deploy a CASB solution. Which of the following most likely explains the choice to use a proxy-based CASB?",
        "type": "single",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "The capability to block unapproved applications and services is possible.",
                "correct": true,
                "explain": "Correct. A key advantage of a proxy-based Cloud Access Security Broker (CASB), whether forward or reverse, is its ability to monitor and control traffic in real-time. This allows it to enforce policies on both sanctioned (approved) and unsanctioned (unapproved) cloud applications. An API-based CASB can only see and control sanctioned apps that it has been integrated with. A proxy-based CASB can see all cloud traffic and is therefore capable of identifying and blocking access to unapproved applications, a critical feature for managing shadow IT."
            },
            {
                "text": "Privacy compliance obligations are bypassed when using a user-based deployment.",
                "correct": false,
                "explain": "Incorrect. Deploying a CASB introduces privacy considerations; it does not bypass them."
            },
            {
                "text": "Protecting and regularly rotating API secret keys requires a significant time commitment.",
                "correct": false,
                "explain": "Incorrect. This describes a challenge with API-based CASBs, but it doesn't explain the positive reason for choosing a proxy-based one."
            },
            {
                "text": "Corporate devices cannot receive certificates when not connected to on-premises devices.",
                "correct": false,
                "explain": "Incorrect. Modern endpoint management solutions can deploy certificates to devices regardless of their location."
            }
        ]
    },
    {
        "id": 230,
        "q": "A user tried to access a web page at http://10.1.1.1. Previously the web page did not require authentication, and now the browser is prompting for credentials. Which of the following actions would best prevent the issue from reoccurring and reduce the likelihood of credential exposure?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "Implementing 802.1x EAP-TTLS on access points to reduce the risk of evil twins",
                "correct": false,
                "explain": "Incorrect. While a good security practice for wireless networks, this does not solve the problem of an internal web server being impersonated."
            },
            {
                "text": "Transitioning internal services to use DNS security",
                "correct": false,
                "explain": "Incorrect. DNS security (DNSSEC) helps prevent spoofing of domain names, but the user is accessing the site via its IP address directly, bypassing DNS."
            },
            {
                "text": "Modifying web server configuration and utilizing X509 certificates for authentication",
                "correct": true,
                "explain": "Correct. The user is accessing an internal site via an unencrypted HTTP connection to an IP address. An attacker on the local network could easily intercept this request and redirect the user to a malicious server that prompts for credentials (an on-path or spoofing attack). The best way to prevent this is to secure the connection using TLS. This involves: 1) Installing a trusted X.509 (TLS/SSL) certificate on the legitimate web server. 2) Configuring the server to redirect all HTTP traffic to HTTPS. This ensures the user's connection is encrypted and they can verify the server's identity via its certificate, preventing impersonation and credential exposure."
            },
            {
                "text": "Installing new rules for the IDS to detect impersonation attacks",
                "correct": false,
                "explain": "Incorrect. An IDS is a detective control. Implementing TLS is a preventative control that is much more effective."
            }
        ]
    },
    {
        "id": 231,
        "q": "A compliance officer is reviewing the data sovereignty laws in several countries where the organization has no presence. Which of the following is the most likely reason for reviewing these laws?",
        "type": "single",
        "category": "1.3 Explain how compliance affects information security strategies.",
        "answers": [
            {
                "text": "The organization is performing due diligence of potential tax issues.",
                "correct": false,
                "explain": "Incorrect. Data sovereignty laws relate to where data can be stored and processed, not typically to tax issues."
            },
            {
                "text": "The organization has been subject to legal proceedings in countries where it has a presence.",
                "correct": false,
                "explain": "Incorrect. The question states the officer is reviewing laws in countries where the organization has *no* presence."
            },
            {
                "text": "The organization is concerned with new regulatory enforcement in other countries.",
                "correct": true,
                "explain": "Correct. Data sovereignty laws require that the personal data of a country's citizens be stored and processed within that country's borders. Even if an organization has no physical presence in a country, if it collects and processes data from citizens of that country (e.g., through a global website), it may be subject to that country's data sovereignty laws. The compliance officer is likely performing due diligence to understand these extraterritorial legal obligations."
            },
            {
                "text": "The organization has suffered brand reputation damage from incorrect media coverage.",
                "correct": false,
                "explain": "Incorrect. This is a public relations issue, not a compliance issue related to data sovereignty."
            }
        ]
    },
    {
        "id": 232,
        "q": "Audit findings indicate several user endpoints are not utilizing full disk encryption. During the remediation process, a compliance analyst reviews the testing details for the endpoints and notes the endpoint device configuration does not support full disk encryption. Which of the following is the most likely reason the device must be replaced?",
        "type": "single",
        "category": "3.4 Given a scenario, implement hardware security technologies and techniques.",
        "answers": [
            {
                "text": "The HSM is outdated and no longer supported by the manufacturer",
                "correct": false,
                "explain": "Incorrect. An HSM is an external device for key management and is not typically part of a standard user endpoint."
            },
            {
                "text": "The vTPM was not properly initialized and is corrupt.",
                "correct": false,
                "explain": "Incorrect. A vTPM is for virtual machines, not physical endpoint devices."
            },
            {
                "text": "The HSM is vulnerable to common exploits and a firmware upgrade is needed",
                "correct": false,
                "explain": "Incorrect. Again, an HSM is not part of a standard endpoint."
            },
            {
                "text": "The motherboard was not configured with a TPM from the OEM supplier",
                "correct": true,
                "explain": "Correct. Modern full disk encryption solutions, like Windows BitLocker, integrate with a Trusted Platform Module (TPM) chip on the device's motherboard. The TPM securely stores the encryption keys, protecting them from being extracted if the drive is removed from the laptop. If the endpoint's motherboard was not manufactured with a TPM, it cannot support the most secure mode of full disk encryption, making the device non-compliant and requiring its replacement."
            },
            {
                "text": "The HSM does not support sealing storage",
                "correct": false,
                "explain": "Incorrect. Again, an HSM is not the relevant component here; the TPM is."
            }
        ]
    },
    {
        "id": 233,
        "q": "A company's security policy states that any publicly available server must be patched within 12 hours after a patch is released. A recent IIS zero-day vulnerability was discovered that affects all versions of the Windows Server OS. <br><br> <img src='../../assets/quiz-images/CAS-005_233.png' alt='Server inventory table'> <br><br> Which of the following hosts should a security analyst patch first once a patch is available?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "1",
                "correct": false,
                "explain": "Incorrect. Host 1 is externally available and runs IIS, but it is protected by a WAF, which acts as a compensating control, slightly lowering its priority compared to Host 4."
            },
            {
                "text": "2",
                "correct": false,
                "explain": "Incorrect. Host 2 is not externally available and does not have IIS installed, so it is not vulnerable."
            },
            {
                "text": "3",
                "correct": false,
                "explain": "Incorrect. Host 3 is externally available and runs IIS, but it is protected by a WAF, which acts as a compensating control, slightly lowering its priority compared to Host 4."
            },
            {
                "text": "4",
                "correct": true,
                "explain": "Correct. When prioritizing patching, you must consider exposure, vulnerability, and lack of compensating controls. Host 4 is the highest priority because: 1) It is 'Externally available', making it accessible to attackers. 2) It has 'IIS installed', making it vulnerable to the zero-day. 3) It is *not* 'Behind WAF?', meaning it has no compensating controls to protect it. This combination of factors makes it the most at-risk server and the first one that must be patched."
            },
            {
                "text": "5",
                "correct": false,
                "explain": "Incorrect. Host 5 is not externally available and does not have IIS installed, so it is not vulnerable."
            },
            {
                "text": "6",
                "correct": false,
                "explain": "Incorrect. Host 6 is externally available, but it does not have IIS installed, so it is not vulnerable to the IIS zero-day."
            }
        ]
    },
    {
        "id": 234,
        "q": "A central bank implements strict risk mitigations for the hardware supply chain, including an allow list for specific countries of origin. Which of the following best describes the cyberthreat to the bank?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Ability to obtain components during wartime",
                "correct": false,
                "explain": "Incorrect. This is a geopolitical and logistics risk, but not primarily a cyberthreat."
            },
            {
                "text": "Fragility to DDoS and other availability attacks",
                "correct": false,
                "explain": "Incorrect. DDoS attacks are a threat, but they are not directly related to the hardware supply chain's country of origin."
            },
            {
                "text": "Physical implants and tampering",
                "correct": true,
                "explain": "Correct. A primary concern in hardware supply chain security, especially for high-value targets like a central bank, is the threat of physical tampering. A nation-state adversary could intercept hardware components during manufacturing or shipping and install malicious physical implants (hardware backdoors) that are nearly impossible to detect. By restricting the procurement of hardware to a small list of trusted countries of origin, the bank is attempting to mitigate this specific cyberthreat."
            },
            {
                "text": "Non-conformance to accepted manufacturing standards",
                "correct": false,
                "explain": "Incorrect. This is a quality control issue, not a direct cyberthreat like a malicious implant."
            }
        ]
    },
    {
        "id": 235,
        "q": "An organization has noticed an increase in phishing campaigns utilizing typosquatting. A security analyst needs to enrich the data for commonly used domains against the domains used in phishing campaigns. The analyst uses a log forwarder to forward network logs to the SIEM. Which of the following would allow the security analyst to perform this analysis?",
        "type": "single",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "Use a cron job to regularly update and compare domains.",
                "correct": false,
                "explain": "Incorrect. A cron job could be part of a solution, but it is not the analysis tool itself. A specialized script or SIEM feature is needed."
            },
            {
                "text": "Create a parser that matches domains.",
                "correct": false,
                "explain": "Incorrect. A parser extracts data from logs. It doesn't perform the comparative analysis needed to find typosquatted domains."
            },
            {
                "text": "Develop a query that filters out all matching domain names.",
                "correct": false,
                "explain": "Incorrect. Filtering out matching names would hide the legitimate traffic, but it wouldn't help find the typosquatted variations."
            },
            {
                "text": "Implement a dashboard on the SIEM that shows the percentage of traffic by domain.",
                "correct": true,
                "explain": "Correct. To find typosquatted domains, an analyst needs to compare the domains being accessed by users to a list of legitimate, commonly used domains. This often involves calculating the 'edit distance' (e.g., Levenshtein distance) between domains. Specialized threat hunting tools and some advanced SIEMs have features for this. A python script that takes the list of logged domains, compares each to the list of legitimate domains, calculates the edit distance, and flags domains that are very similar but not identical would be an effective way to perform this analysis."
            }
        ]
    },
    {
        "id": 236,
        "q": "A security analyst wants to use lessons learned from a prior incident response to reduce dwell time in the future. The analyst is using the following data points: <br><br> <img src='../../assets/quiz-images/CAS-005_236.png' alt='Web filter and SIEM log'> <br><br> Which of the following would the analyst most likely recommend?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "Adjusting the SIEM to alert on attempts to visit phishing sites",
                "correct": true,
                "explain": "Correct. The logs show that the web filter correctly identified `p4yr0ll.com` as a malicious site and blocked the connection. However, the 'Alert status' for this event is 'No'. This is a critical gap. The web filter did its job, but because it didn't send an alert to the SIEM, the security team was not aware of the attempted compromise. To reduce dwell time, the analyst should recommend configuring the web filter to send alerts for blocked malicious sites to the SIEM and creating a rule in the SIEM to treat these alerts as high-priority incidents."
            },
            {
                "text": "Allowing TRACE method traffic to enable better log correlation",
                "correct": false,
                "explain": "Incorrect. The TRACE method is a debugging tool and is often disabled for security reasons. Allowing it would increase the attack surface, not reduce dwell time."
            },
            {
                "text": "Enabling alerting on all suspicious administrator behavior",
                "correct": false,
                "explain": "Incorrect. While alerting on `admin1`'s visit to `hacking.com` is good, the more significant missed opportunity in the logs is the failure to alert on the blocked phishing attempt, which could have been the start of a more serious incident."
            },
            {
                "text": "Utilizing allow lists on the WAF for all users using GET methods",
                "correct": false,
                "explain": "Incorrect. This is not a practical solution and does not address the core issue, which is a lack of alerting on known-bad activity."
            }
        ]
    },
    {
        "id": 237,
        "q": "After a penetration test on the internal network the following report was generated: <br><br> <img src='../../assets/quiz-images/CAS-005_237.png' alt='Penetration test results'> <br><br> Which of the following should be recommended to remediate the attack?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Deleting SQLSV",
                "correct": false,
                "explain": "Incorrect. While the SQL server was involved, deleting it is a drastic step. The root of the domain compromise lies with the Kerberos ticket."
            },
            {
                "text": "Reimaging ADMIN01$",
                "correct": false,
                "explain": "Incorrect. While the admin host was the entry point, the critical damage was the compromise of the domain's 'golden ticket' key. Reimaging the host will not fix the compromised domain."
            },
            {
                "text": "Rotating KRBTGT password",
                "correct": true,
                "explain": "Correct. The report shows that the penetration tester compromised an admin host and then successfully collected the hash of the `KRBTGT` account. This is the Kerberos Ticket Granting Ticket service account. The hash of this account is the 'golden ticket' key for the entire domain. Possessing this allows an attacker to forge Kerberos tickets for any user or service. The report shows they used this to gain control of the domain. The only way to remediate a golden ticket attack is to reset the password of the `KRBTGT` account, and then reset it a second time, which effectively invalidates all existing Kerberos tickets in the domain."
            },
            {
                "text": "Resetting the local domain",
                "correct": false,
                "explain": "Incorrect. 'Resetting the local domain' is a vague and overly destructive term. The specific, targeted remediation for a golden ticket attack is to rotate the KRBTGT password twice."
            }
        ]
    },
    {
        "id": 238,
        "q": "A security engineer is given the following requirements: An endpoint must only execute internally signed applications. Administrator accounts cannot install unauthorized software. Attempts to run unauthorized software must be logged. Which of the following best meets these requirements?",
        "type": "single",
        "category": "3.2 Given a scenario, analyze requirements to enhance the security of endpoints and servers.",
        "answers": [
            {
                "text": "Maintaining appropriate account access through directory management and controls",
                "correct": false,
                "explain": "Incorrect. While managing administrator accounts is important, it does not provide the application-level execution control required."
            },
            {
                "text": "Implementing a CSPM platform to monitor updates being pushed to applications",
                "correct": false,
                "explain": "Incorrect. A CSPM is for monitoring cloud configurations, not for controlling application execution on endpoints."
            },
            {
                "text": "Deploying an EDR solution to monitor and respond to software installation attempts",
                "correct": false,
                "explain": "Incorrect. While an EDR can monitor and respond, a dedicated application control solution is more specifically designed to enforce execution policies based on rules like digital signatures."
            },
            {
                "text": "Configuring application control with blocked hashes and enterprise-trusted root certificates",
                "correct": true,
                "explain": "Correct. This solution meets all requirements. An application control solution can be configured in an allowlist mode. By configuring it to trust applications signed by the enterprise's own code-signing certificate (which chains up to a trusted root), it ensures only internally signed applications can run. This prevents administrators from running unauthorized software. The solution would also be configured to log any attempt to run an unauthorized application (one that is not signed or is signed by an untrusted party), fulfilling the logging requirement."
            }
        ]
    },
    {
        "id": 239,
        "q": "After an organization met with its ISAC, the organization decided to test the resiliency of its security controls against a small number of advanced threat actors. Which of the following will enable the security administrator to accomplish this task?",
        "type": "single",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "Adversary emulation",
                "correct": true,
                "explain": "Correct. Adversary emulation is a type of security testing where the red team mimics the specific Tactics, Techniques, and Procedures (TTPs) of a known threat actor, such as a specific APT group discussed by the ISAC. This allows the organization to test the resilience of its controls against a realistic, targeted attack, which is exactly what the task requires."
            },
            {
                "text": "Reliability factors",
                "correct": false,
                "explain": "Incorrect. Reliability factors are used to gauge the trustworthiness of threat intelligence sources, not to test security controls."
            },
            {
                "text": "Deployment of a honeypot",
                "correct": false,
                "explain": "Incorrect. A honeypot is a passive decoy system used to attract and study attackers. It does not actively test the controls on production systems."
            },
            {
                "text": "Internal reconnaissance",
                "correct": false,
                "explain": "Incorrect. Internal reconnaissance is one phase of an attack; it is not the overall methodology for testing controls against a specific adversary."
            }
        ]
    },
    {
        "id": 240,
        "q": "After a cybersecurity incident, a security analyst was able to collect a binary that the attacker used on the compromised server. Then the analyst ran the following command: <br><br> <img src='../../assets/quiz-images/CAS-005_240.png' alt='Strings command output on a binary'> <br><br> Which of the following options describes what the analyst is trying to do?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "To reconstruct the timeline of commands executed by the binary",
                "correct": false,
                "explain": "Incorrect. The `strings` command does not show the order of execution. It simply dumps all printable strings from the file."
            },
            {
                "text": "To extract IoCs from the binary used on the attack",
                "correct": true,
                "explain": "Correct. The `strings` command is a common and simple first step in static malware analysis. It extracts all human-readable ASCII and Unicode strings from a binary file. Analysts use this to quickly find potential Indicators of Compromise (IoCs) like IP addresses (`192.168.1.2`), domain names (`evil.info`), file paths (`c:\\windows\\system32\\temps.xml`), and commands (`cmd.exe whoami`) that can be used for further investigation and detection."
            },
            {
                "text": "To replicate the attack in a secure environment",
                "correct": false,
                "explain": "Incorrect. Replicating the attack would involve running the binary in a sandbox (dynamic analysis), not just reading strings from it."
            },
            {
                "text": "To debug the binary to analyze low-level instructions",
                "correct": false,
                "explain": "Incorrect. Debugging a binary requires a debugger tool (like GDB or OllyDbg) to step through the code's assembly instructions. The `strings` command does not do this."
            }
        ]
    },
    {
        "id": 241,
        "q": "A senior security engineer flags the following log file snippet as having likely facilitated an attacker's lateral movement in a recent breach: <br><br> <img src='../../assets/quiz-images/CAS-005_241.png' alt='DNS AXFR log snippet'> <br><br> Which of the following solutions, if implemented, would mitigate the risk of this issue reoccurring?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "Disabling DNS zone transfers",
                "correct": true,
                "explain": "Correct. The log shows a DNS query of type `AXFR`. An AXFR query is a request for a full DNS zone transfer, which asks the DNS server to return all of the records it has for a specific domain. Attackers use this for reconnaissance to quickly map out an organization's internal network infrastructure. By default, DNS servers should be configured to disable or severely restrict zone transfers, only allowing them to occur between trusted, primary, and secondary DNS servers. Disabling open zone transfers would have mitigated this reconnaissance activity."
            },
            {
                "text": "Restricting DNS traffic to UDP/53",
                "correct": false,
                "explain": "Incorrect. While most standard DNS queries use UDP port 53, zone transfers require the reliability of TCP and use TCP port 53. Restricting all DNS to UDP would break legitimate zone transfers and not solve the unauthorized request issue."
            },
            {
                "text": "Implementing DNS masking on internal servers",
                "correct": false,
                "explain": "Incorrect. DNS masking is not a standard security term or technique."
            },
            {
                "text": "Permitting only clients from internal networks to query DNS",
                "correct": false,
                "explain": "Incorrect. The query source `19.27.214.22` could very well be an internal (though untrusted) client. The issue is the type of query (`AXFR`) being allowed, not necessarily the source of the query."
            }
        ]
    },
    {
        "id": 242,
        "q": "To prevent data breaches, security leaders at a company decide to expand user education to: Create a healthy security culture. Comply with regulatory requirements. Improve incident reporting. Which of the following would best meet their objective?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "Performing a DoS attack",
                "correct": false,
                "explain": "Incorrect. Performing a DoS attack on your own company is not an educational tool."
            },
            {
                "text": "Scheduling regular penetration tests",
                "correct": false,
                "explain": "Incorrect. Penetration tests are for assessing technical controls, not for educating the general user population."
            },
            {
                "text": "Simulating a phishing campaign",
                "correct": true,
                "explain": "Correct. Simulating a phishing campaign is a powerful security awareness and training tool. It provides a safe, controlled way to test users' ability to spot malicious emails, gives them practical experience, and provides metrics to track improvement. It directly supports improving incident reporting (by teaching users how to report phishing) and helps meet compliance requirements for security training, thus fostering a better security culture."
            },
            {
                "text": "Deploying fake ransomware",
                "correct": false,
                "explain": "Incorrect. Deploying any kind of fake malware, even if intended to be harmless, is extremely risky and not a standard or recommended method for user education."
            }
        ]
    },
    {
        "id": 243,
        "q": "An external SaaS solution user reports a bug associated with the role-based access control module. This bug allows users to bypass system logic associated with client segmentation in the multitenant deployment model. When assessing the bug report, the developer finds that the same bug was previously identified and addressed in an earlier release. The developer then determines the bug was reintroduced when an existing software component was integrated from a prior version of the platform. Which of the following is the best way to prevent this scenario?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Regression testing",
                "correct": true,
                "explain": "Correct. Regression testing is the process of re-running functional and non-functional tests to ensure that previously developed and tested software still performs correctly after a change. The scenario describes a 'regression'a bug that was fixed has reappeared. A comprehensive regression testing suite, which includes tests for previously fixed security bugs, would have caught this reintroduced vulnerability before it was released to production."
            },
            {
                "text": "Code signing",
                "correct": false,
                "explain": "Incorrect. Code signing provides integrity and authenticity; it does not test for functional or security bugs in the code."
            },
            {
                "text": "Automated test and retest",
                "correct": false,
                "explain": "Incorrect. This is a generic term. 'Regression testing' is the specific type of testing needed to prevent old bugs from reappearing."
            },
            {
                "text": "User acceptance testing",
                "correct": false,
                "explain": "Incorrect. User Acceptance Testing (UAT) is typically focused on whether the software meets the business requirements from a user's perspective. It may not be detailed enough to catch a specific security logic flaw like this. A dedicated regression test suite is more reliable."
            },
            {
                "text": "Software composition analysis",
                "correct": false,
                "explain": "Incorrect. SCA checks for vulnerabilities in third-party libraries, not for bugs in the custom-written application logic."
            }
        ]
    },
    {
        "id": 244,
        "q": "After several companies in the financial industry were affected by a similar incident, they shared information about threat intelligence and the malware used for exploitation. Which of the following should the companies do to best indicate whether the attacks are being conducted by the same actor?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "Apply code stylometry.",
                "correct": true,
                "explain": "Correct. Code stylometry is the analysis of a programmer's unique coding style (e.g., variable naming conventions, commenting style, function structure). If malware samples from different incidents show a consistent and unique coding style, it provides a strong indication that the malware was written by the same developer or group, which is a key part of attributing the attacks to the same threat actor."
            },
            {
                "text": "Look for common TTPs.",
                "correct": false,
                "explain": "Incorrect. While common TTPs suggest a similar methodology, many different actors can use the same tools and techniques. Code stylometry provides a much more specific link to the author of the malware itself."
            },
            {
                "text": "Use IoC extractions.",
                "correct": false,
                "explain": "Incorrect. Extracting Indicators of Compromise (IoCs) like IP addresses or file hashes is useful for detection, but attackers frequently change their infrastructure. Similarities in the code itself are a stronger indicator of a common actor."
            },
            {
                "text": "Leverage malware detonation.",
                "correct": false,
                "explain": "Incorrect. Malware detonation (running it in a sandbox) shows what the malware does, but doesn't necessarily reveal who wrote it. The analysis of the code's style is more direct for attribution."
            }
        ]
    },
    {
        "id": 245,
        "q": "Which of the following most likely explains the reason a security engineer replaced ECC with a lattice-based cryptographic technique?",
        "type": "single",
        "category": "3.7 Explain the importance of advanced cryptographic concepts.",
        "answers": [
            {
                "text": "It is computationally efficient and provides perfect forward secrecy.",
                "correct": false,
                "explain": "Incorrect. Lattice-based cryptography is generally more computationally intensive than ECC, not more efficient."
            },
            {
                "text": "It is more resilient to brute-force attacks than ECC.",
                "correct": false,
                "explain": "Incorrect. Both ECC and lattice-based crypto are considered resistant to brute-force attacks by classical computers. The key difference is their resistance to quantum computers."
            },
            {
                "text": "It supports ephemeral key exchange and digital signatures.",
                "correct": false,
                "explain": "Incorrect. Both ECC and lattice-based schemes can be used for key exchange and digital signatures. This is not a differentiating factor."
            },
            {
                "text": "It is currently considered a robust PQC technique.",
                "correct": true,
                "explain": "Correct. Elliptic Curve Cryptography (ECC) is a type of public-key cryptography that is secure against attacks by classical computers but is vulnerable to attacks by future quantum computers (using Shor's algorithm). Lattice-based cryptography is one of the leading families of Post-Quantum Cryptography (PQC) techniques. It is based on mathematical problems that are believed to be hard to solve for both classical and quantum computers. A security engineer would replace ECC with a lattice-based technique to prepare for and defend against the future threat of quantum computing."
            },
            {
                "text": "It enables processing on data while remaining in an encrypted state.",
                "correct": false,
                "explain": "Incorrect. This describes homomorphic encryption, which is a different cryptographic concept from PQC."
            }
        ]
    },
    {
        "id": 246,
        "q": "An administrator reviews the following log and determines the root cause of a site-to-site tunnel failure: <br><br> <img src='../../assets/quiz-images/CAS-005_246.png' alt='VPN tunnel failure log'> <br><br> Which of the following actions should the administrator take to most effectively correct the failure?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "Enable perfect forward secrecy on the remote peer.",
                "correct": false,
                "explain": "Incorrect. The logs show the cipher suite proposals match, so PFS is likely not the source of the failure. The failure is explicitly stated as 'no peer config found'."
            },
            {
                "text": "Update the cipher suites configured for use on the server side.",
                "correct": false,
                "explain": "Incorrect. The log explicitly shows that the 'received proposals' and 'configured proposals' for the cipher suite match exactly. The cipher suite is not the problem."
            },
            {
                "text": "Add a new subnet as a permitted initiator.",
                "correct": true,
                "explain": "Correct. The log clearly shows the root cause. The server side has a configured 'own selector set' of `8.18.99.1/24`, but the remote peer is initiating the connection with a 'client selector set' of `8.19.99.1/24`. The server's response is `no matching selector config` and `no peer config found`. The administrator needs to modify the VPN configuration on the server to add the remote subnet (`8.19.99.1/24`) as a permitted peer/initiator for the tunnel."
            },
            {
                "text": "Disable IKE version 1 and run IKE version 2.",
                "correct": false,
                "explain": "Incorrect. The log shows a 'QUICK_MODE request,' which is part of IKEv1. While upgrading to IKEv2 is a good practice, it would not solve the fundamental configuration mismatch of the permitted subnets."
            }
        ]
    },
    {
        "id": 247,
        "q": "A security architect is mitigating a vulnerability that previously led to a web application data breach. An analysis into the root cause of the issue finds the following: An administrators account was hijacked and used on several Autonomous System Numbers within 30 minutes. All administrators use named accounts that require multifactor authentication. Single sign-on is used for all company applications. Which of the following should the security architect do to mitigate the issue?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Configure token theft detections on the single sign-on system with automatic account lockouts.",
                "correct": true,
                "explain": "Correct. The findings indicate that even with MFA, the administrator's session was hijacked. In an SSO system, after a user authenticates, they are given a session token (or cookie) that is presented to applications to grant access. An attacker can steal this session token from the administrator's machine and replay it from their own machine to bypass MFA and hijack the session. The use of the account from multiple ASNs (different networks/countries) in a short time is a strong indicator of this. The best mitigation is to configure the SSO system with advanced security features that can detect token theft, such as by correlating the ASN/IP address with the original login location and automatically locking the account if suspicious behavior is detected."
            },
            {
                "text": "Enable context-based authentication when network locations change on administrator login attempts.",
                "correct": false,
                "explain": "Incorrect. The attacker is not logging in again; they are replaying a stolen session token, which bypasses the login process."
            },
            {
                "text": "Decentralize administrator accounts and force unique passwords for each application.",
                "correct": false,
                "explain": "Incorrect. This would eliminate the benefits of SSO and would not prevent session hijacking within a single application."
            },
            {
                "text": "Enforce biometric authentication requirements for the administrators named accounts.",
                "correct": false,
                "explain": "Incorrect. Biometrics are a form of MFA used at login. A token theft attack bypasses the login process entirely."
            }
        ]
    },
    {
        "id": 248,
        "q": "An organization currently has IDS, firewall, and DLP systems in place. The systems administrator needs to integrate the tools in the environment to reduce response time. Which of the following should the administrator use?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "SOAR",
                "correct": true,
                "explain": "Correct. Security Orchestration, Automation, and Response (SOAR) platforms are designed specifically to integrate disparate security tools. A SOAR can ingest alerts from the IDS, use that information to automatically update a rule on the firewall to block the attacker's IP, and trigger a scan on the DLP system. By orchestrating actions across these different tools, a SOAR dramatically reduces manual effort and response time."
            },
            {
                "text": "CWPP",
                "correct": false,
                "explain": "Incorrect. A Cloud Workload Protection Platform (CWPP) is for securing cloud servers and containers; it is not a general-purpose integration tool."
            },
            {
                "text": "XCCDF",
                "correct": false,
                "explain": "Incorrect. XCCDF is a language for specifying security checklists and benchmarks; it is not an integration platform."
            },
            {
                "text": "CMDB",
                "correct": false,
                "explain": "Incorrect. A Configuration Management Database (CMDB) is an asset inventory; it does not orchestrate actions between security tools."
            }
        ]
    },
    {
        "id": 249,
        "q": "A company migrating to a remote work model requires that company-owned devices connect to a VPN before logging in to the device itself. The VPN gateway requires that a specific key extension is deployed to the machine certificates in the internal PKI. Which of the following best explains this requirement?",
        "type": "single",
        "category": "2.4 Given a scenario, apply security concepts to the design of access, authentication, and authorization systems.",
        "answers": [
            {
                "text": "The certificate is an additional factor to meet regulatory MFA requirements for VPN access.",
                "correct": false,
                "explain": "Incorrect. A device certificate is typically considered 'something you have,' but for regulatory MFA, this is usually combined with 'something you know' (password) or 'something you are' (biometric). The primary reason here is to automate the connection."
            },
            {
                "text": "The VPN client selected the certificate with the correct key usage without user interaction.",
                "correct": true,
                "explain": "Correct. The requirement is for an 'always-on' VPN that connects *before* the user logs in. This means the connection must be established by the machine itself, not the user. The VPN client needs to automatically select the correct certificate from the machine's certificate store to authenticate itself to the VPN gateway. The specific key extension (likely 'Client Authentication' in the Extended Key Usage field) acts as a flag that identifies the certificate as being suitable for this purpose, allowing the VPN client to find and use it without any user interaction."
            },
            {
                "text": "The internal PKI certificate deployment allows for Wi-Fi connectivity before logging in to other systems.",
                "correct": false,
                "explain": "Incorrect. This describes pre-logon authentication for Wi-Fi (802.1X), which is a similar concept but not what is being described for the VPN."
            },
            {
                "text": "The server connection uses SSL VPN, which uses certificates for secure communication.",
                "correct": false,
                "explain": "Incorrect. While true that SSL VPNs use certificates, this doesn't explain the specific requirement for a key extension on the *client* certificate to enable a pre-logon connection."
            }
        ]
    },
    {
        "id": 250,
        "q": "A company that uses several cloud applications wants to properly identify: All the devices potentially affected by a given vulnerability. All the internal servers utilizing the same physical switch. The number of endpoints using a particular operating system. Which of the following is the best way to meet the requirements?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "SBoM",
                "correct": false,
                "explain": "Incorrect. A Software Bill of Materials (SBoM) is for a single application. It cannot identify all devices, their OS, or their network connections."
            },
            {
                "text": "CASB",
                "correct": false,
                "explain": "Incorrect. A Cloud Access Security Broker (CASB) monitors cloud application usage but does not maintain a detailed inventory of physical and OS-level attributes."
            },
            {
                "text": "GRC",
                "correct": false,
                "explain": "Incorrect. A Governance, Risk, and Compliance (GRC) tool manages policies and risks; it does not serve as a technical asset inventory."
            },
            {
                "text": "CMDB",
                "correct": true,
                "explain": "Correct. A Configuration Management Database (CMDB) is the single source of truth for an organization's IT assets and their relationships. A well-maintained CMDB would contain the necessary data to answer all these questions: it would list all devices and the software/versions installed on them (to identify those affected by a vulnerability), map the network connections between servers and switches, and store the operating system details for every endpoint."
            }
        ]
    },
    {
        "id": 251,
        "q": "An external threat actor attacks public infrastructure providers. In response to the attack and during follow-up activities, various providers share information obtained during response efforts. After the attack, energy sector companies share their status and response data: <br><br> <img src='../../assets/quiz-images/CAS-005_251.png' alt='Security posture comparison table'> <br><br> Which of the following is the most important issue to address to defend against future attacks?",
        "type": "single",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "Failure to implement a UEBA system",
                "correct": false,
                "explain": "Incorrect. Company 1 had the fastest response time without having a UEBA system, indicating that UEBA was not the most critical factor in this scenario."
            },
            {
                "text": "Failure to implement a DLP system",
                "correct": false,
                "explain": "Incorrect. Company 3 had a fast response time without having a DLP system, indicating that DLP was not the most critical factor."
            },
            {
                "text": "Failure to join the industry ISAC",
                "correct": false,
                "explain": "Incorrect. Company 2 was an ISAC member but had the slowest response times, indicating that membership alone is not enough."
            },
            {
                "text": "Failure to integrate with the TIP",
                "correct": true,
                "explain": "Correct. The data shows a clear correlation between slow response times and the lack of TIP integration. Company 2, the only one without Threat Intelligence Platform (TIP) integration, had by far the longest time to detect and respond. A TIP automates the ingestion and operationalization of threat data from sources like an ISAC, enabling security tools to act on intelligence much faster. This lack of automation is the most important issue to address."
            }
        ]
    },
    {
        "id": 252,
        "q": "Which of the following best describes the challenges associated with widespread adoption of homomorphic encryption techniques?",
        "type": "single",
        "category": "3.7 Explain the importance of advanced cryptographic concepts.",
        "answers": [
            {
                "text": "Incomplete mathematical primitives",
                "correct": false,
                "explain": "Incorrect. The mathematical foundations for homomorphic encryption are well-established, although they are still an active area of research for improvement."
            },
            {
                "text": "No use cases to drive adoption",
                "correct": false,
                "explain": "Incorrect. There are many compelling use cases, such as privacy-preserving data analysis in the cloud, but performance barriers hinder their implementation."
            },
            {
                "text": "Quantum computers not yet capable",
                "correct": false,
                "explain": "Incorrect. Homomorphic encryption is a classical cryptography concept; its adoption is not dependent on the availability of quantum computers."
            },
            {
                "text": "Insufficient coprocessor support",
                "correct": true,
                "explain": "Correct. The primary challenge hindering the widespread adoption of homomorphic encryption is its extremely high computational overhead. Performing calculations on encrypted data is orders of magnitude slower than on plaintext. The lack of mainstream, specialized hardware acceleration (coprocessors) to speed up these complex calculations makes it impractical for most real-time or large-scale applications."
            }
        ]
    },
    {
        "id": 253,
        "q": "A company is migrating from company-owned phones to a BYOD strategy for mobile devices. The pilot program will start with the executive management team and be rolled out to the rest of the staff in phases. The companys Chief Financial Officer loses a phone multiple times a year. Which of the following will most likely secure the data on the lost device?",
        "type": "single",
        "category": "3.2 Given a scenario, analyze requirements to enhance the security of endpoints and servers.",
        "answers": [
            {
                "text": "Require a VPN to be active to access company data.",
                "correct": false,
                "explain": "Incorrect. A VPN secures data in transit but does nothing to protect data stored at rest on the lost device."
            },
            {
                "text": "Set up different profiles based on the persons risk.",
                "correct": false,
                "explain": "Incorrect. While risk-based profiling is a good concept, it doesn't describe the specific action needed to secure a device once it is lost."
            },
            {
                "text": "Remotely wipe the device.",
                "correct": true,
                "explain": "Correct. When a device containing corporate data is lost or stolen, the most effective security control is to issue a remote wipe command from the Mobile Device Management (MDM) solution. This command erases all data on the device, or at least the corporate data within a secure container, ensuring that the sensitive information cannot be accessed by an unauthorized individual."
            },
            {
                "text": "Require MFA to access company applications.",
                "correct": false,
                "explain": "Incorrect. MFA protects access to the applications but does not erase any data that may have been cached or stored locally on the device itself."
            }
        ]
    },
    {
        "id": 254,
        "q": "Company A acquired Company B. Both companies serve a user base in different geographic regions but now collectively serve a globally distributed user base. A security architect needs to design resilient monitoring systems with the following requirements: User data must remain on the systems of each respective company. Low latency is needed for all users regardless of company location and user location. Each company must have its own redundancy. Which of the following practices are the most beneficial in meeting the requirements? (Choose two).",
        "type": "multiple",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "Replicating each companys system in the other companys region",
                "correct": false,
                "explain": "Incorrect. This would violate the requirement that user data must remain on the systems of each respective company (a data sovereignty requirement)."
            },
            {
                "text": "Adding additional resources in each companys original region",
                "correct": true,
                "explain": "Correct. To provide redundancy for each company's systems, adding more resources (e.g., servers in a cluster) within their own existing region is a standard high-availability practice. This directly addresses the 'own redundancy' requirement without violating data sovereignty."
            },
            {
                "text": "Implementing a network load balancer",
                "correct": true,
                "explain": "Correct. A network load balancer is a key component for achieving both low latency and resiliency. A global load balancer can direct users to the data center that is geographically closest to them, reducing latency. It can also detect if one data center is unavailable and automatically reroute traffic to the healthy one, providing redundancy."
            },
            {
                "text": "Deploying a reverse proxy",
                "correct": false,
                "explain": "Incorrect. While a reverse proxy can be part of a solution, a network load balancer is the specific technology that handles traffic distribution for low latency and high availability on a global scale."
            },
            {
                "text": "Utilizing an API gateway",
                "correct": false,
                "explain": "Incorrect. An API gateway manages access to backend APIs and is not a solution for global load balancing and user latency."
            },
            {
                "text": "Enabling automated vertical scaling",
                "correct": false,
                "explain": "Incorrect. Vertical scaling (making a single server bigger) is less resilient than horizontal scaling (adding more servers), which is what a load balancer enables."
            }
        ]
    },
    {
        "id": 255,
        "q": "During a security assessment using an EDR solution, a security engineer generates the following report about the assets in the system: <br><br> <img src='../../assets/quiz-images/CAS-005_255.png' alt='EDR status report'> <br><br> After five days, the EDR console reports a blocked infection on the host 0WIN23 by a remote access Trojan. Which of the following most likely enabled the attempted infection?",
        "type": "single",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "0WIN23 uses a legacy version of Windows that is not supported by the EDR.",
                "correct": true,
                "explain": "Correct. Host 0WIN23 is running Windows 7, which is a legacy, end-of-life operating system. EOL systems no longer receive security patches from the vendor, making them rife with unpatched vulnerabilities. An attacker could easily exploit one of these vulnerabilities to gain initial access and attempt to install the RAT. The EDR then detected and blocked the RAT, but the underlying vulnerability in the legacy OS was the enabler."
            },
            {
                "text": "LN002 was not supported by the EDR solution and propagates the RAT.",
                "correct": false,
                "explain": "Incorrect. The log shows the EDR is enabled on LN002, even if it is unmanaged. There's no evidence it was the source of the infection."
            },
            {
                "text": "0WIN29s EDR has an unknown vulnerability that was exploited by the attacker.",
                "correct": false,
                "explain": "Incorrect. The infection was attempted on 0WIN23, not 0WIN29. The bypass status on 0WIN29 is a concern, but not the cause of this specific incident."
            },
            {
                "text": "MAC005 spreads the malware through other hosts in the network.",
                "correct": false,
                "explain": "Incorrect. There is no evidence in the report to suggest the Mac OS host was involved in spreading a Windows-based RAT."
            }
        ]
    },
    {
        "id": 256,
        "q": "A security engineer must ensure that sensitive corporate information is not exposed if a company laptop is stolen. Which of the following actions best addresses this requirement?",
        "type": "single",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "Utilizing desktop as a service for all company data and multifactor authentication",
                "correct": true,
                "explain": "Correct. This is the most effective solution. By using Desktop as a Service (DaaS) or Virtual Desktop Infrastructure (VDI), no sensitive corporate data is ever stored locally on the laptop. The user is simply interacting with a remote desktop session that runs in a secure data center. If the laptop is stolen, the attacker gains access to a 'dumb terminal' with no data on it. Combining this with MFA for login ensures the attacker cannot use the stolen laptop to access the remote session either."
            },
            {
                "text": "Using explicit allow lists of specific IP addresses and deploying single sign-on",
                "correct": false,
                "explain": "Incorrect. IP allow lists are easily bypassed, and SSO doesn't protect the data stored at rest on the stolen laptop."
            },
            {
                "text": "Deploying mobile device management and requiring stronger passwords",
                "correct": false,
                "explain": "Incorrect. While MDM and strong passwords are good controls, they don't eliminate the risk entirely. A determined attacker could still potentially bypass the password and access the data on the disk. The DaaS solution prevents the data from being on the disk in the first place."
            },
            {
                "text": "Updating security mobile reporting policies and monitoring data breaches",
                "correct": false,
                "explain": "Incorrect. These are administrative and detective controls that do not prevent the initial data exposure from a stolen device."
            }
        ]
    },
    {
        "id": 257,
        "q": "A company discovers intellectual property data on commonly known collaboration web applications that allow the use of slide templates. The systems administrator is reviewing the configurations of each tool to determine how to prevent this issue. The following security solutions are deployed: CASB, SASE, WAF, EDR, Firewall, IDS, SIEM, DLP endpoints. Which of the following should the administrator do to address the issue?",
        "type": "single",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "Enable blocking for all WAF policies.",
                "correct": false,
                "explain": "Incorrect. A WAF protects the company's own web applications from attack; it does not control what users do on external SaaS applications."
            },
            {
                "text": "Enforce a policy to block unauthorized web applications within CASB.",
                "correct": true,
                "explain": "Correct. The issue is that users are uploading sensitive data to unauthorized or risky cloud applications ('shadow IT'). A Cloud Access Security Broker (CASB) is the specific security tool designed to address this. The administrator can configure a policy within the CASB to identify and block traffic to these specific unauthorized collaboration applications, preventing users from uploading intellectual property to them."
            },
            {
                "text": "Create an alert within the SIEM for outgoing network traffic to the suspected website.",
                "correct": false,
                "explain": "Incorrect. Creating an alert is a detective control. A preventative control is needed to stop the data from being uploaded in the first place."
            },
            {
                "text": "Configure DLP endpoints to block sensitive data to removable storage.",
                "correct": false,
                "explain": "Incorrect. The data is being uploaded to web applications, not copied to removable storage like a USB drive. A network-aware solution like a CASB is needed."
            }
        ]
    },
    {
        "id": 258,
        "q": "After some employees are caught uploading data to online personal storage accounts, a company becomes concerned about data leaks related to sensitive, internal documentation. Which of the following would the company most likely do to decrease this type of risk?",
        "type": "single",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "Improve firewall rules to block source IP addresses.",
                "correct": false,
                "explain": "Incorrect. Blocking the IP addresses of cloud storage providers is an unreliable and incomplete solution, as these IPs change frequently and blocking them could impact legitimate services."
            },
            {
                "text": "Implement a cloud access security broker.",
                "correct": true,
                "explain": "Correct. A Cloud Access Security Broker (CASB) is a security policy enforcement point placed between cloud service consumers and cloud service providers. It is specifically designed to address risks like this. A CASB can identify and block access to unsanctioned personal storage accounts, inspect traffic for sensitive data, and enforce DLP policies, directly decreasing the risk of data leakage to these services."
            },
            {
                "text": "Create SIEM rules to raise alerts for access to those platforms.",
                "correct": false,
                "explain": "Incorrect. A SIEM can only provide alerts (detection). A CASB can actively block the activity (prevention), which is a much stronger control."
            },
            {
                "text": "Deploy a FIM solution to trigger when files are accessed.",
                "correct": false,
                "explain": "Incorrect. File Integrity Monitoring (FIM) would create alerts when files are accessed, but it cannot determine the destination of the data or block the upload to a cloud service."
            }
        ]
    },
    {
        "id": 259,
        "q": "A global companys Chief Financial Officer (CFO) receives a phone call from someone claiming to be the Chief Executive Officer (CEO). The caller claims to be stranded and in desperate need of money. The CFO is suspicious, but the callers voice sounds similar to the CEOs. Which of the following best describes this type of attack?",
        "type": "single",
        "category": "1.5 Summarize the information security challenges associated with artificial intelligence (AI) adoption.",
        "answers": [
            {
                "text": "Smishing",
                "correct": false,
                "explain": "Incorrect. Smishing is phishing conducted via SMS text messages."
            },
            {
                "text": "Deepfake",
                "correct": true,
                "explain": "Correct. This is a classic example of an attack using deepfake technology. A deepfake uses artificial intelligence to synthesize a person's voice (or image/video). In this case, the attacker is using an AI-generated voice that sounds like the CEO to try and trick the CFO. This is a sophisticated form of social engineering enabled by AI."
            },
            {
                "text": "Automated exploit generation",
                "correct": false,
                "explain": "Incorrect. Automated exploit generation is the use of AI to create technical exploits for software vulnerabilities, not to impersonate someone's voice."
            },
            {
                "text": "Spear phishing",
                "correct": false,
                "explain": "Incorrect. While this is a targeted attack (a form of whaling, which is spear phishing aimed at executives), the specific technique usedvoice impersonation via AIis best described as a deepfake."
            }
        ]
    },
    {
        "id": 260,
        "q": "A cloud engineer wants to configure mail security protocols to support email authenticity and enable the flow of email security information to a third-party platform for further analysis. Which of the following must be configured to achieve these requirements? (Choose two.)",
        "type": "multiple",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "DMARC",
                "correct": true,
                "explain": "Correct. DMARC (Domain-based Message Authentication, Reporting, and Conformance) is an email authentication policy and reporting protocol. It builds on SPF and DKIM and, crucially, provides a reporting mechanism (`rua` and `ruf` tags) that instructs receiving mail servers to send aggregate and forensic reports about authentication successes and failures to a specified address. This allows a third-party platform to receive and analyze this data."
            },
            {
                "text": "DKIM",
                "correct": true,
                "explain": "Correct. DKIM (DomainKeys Identified Mail) provides email authenticity by adding a digital signature to outgoing messages. This allows the receiving server to verify that the email actually came from the claimed domain and has not been tampered with. It is a foundational component of modern email authentication."
            },
            {
                "text": "TLS",
                "correct": false,
                "explain": "Incorrect. TLS encrypts the communication channel between mail servers but does not authenticate the message sender's domain itself."
            },
            {
                "text": "SPF",
                "correct": false,
                "explain": "Incorrect. While SPF is a key email authentication protocol, the question asks for a way to enable the flow of information to a third party. DMARC is the protocol that provides this reporting capability."
            },
            {
                "text": "DNSSEC",
                "correct": false,
                "explain": "Incorrect. DNSSEC secures DNS lookups but is not a mail security protocol itself."
            },
            {
                "text": "MX",
                "correct": false,
                "explain": "Incorrect. An MX record directs email traffic but does not authenticate it."
            }
        ]
    },
    {
        "id": 261,
        "q": "A company is preparing to move a new version of a web application to production. No issues were reported during security scanning or quality assurance in the CI/CD pipeline. Which of the following actions should the company take next?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Merge the test branch to the main branch.",
                "correct": false,
                "explain": "Incorrect. Merging the code is part of the deployment process, but a critical review step is missing."
            },
            {
                "text": "Perform threat modeling on the production application.",
                "correct": false,
                "explain": "Incorrect. Threat modeling should be done earlier in the design phase, not as the final step before deployment."
            },
            {
                "text": "Conduct unit testing on the submitted code.",
                "correct": false,
                "explain": "Incorrect. Unit testing should have been completed by the developer before even committing the code to the pipeline."
            },
            {
                "text": "Perform a peer review on the test branch.",
                "correct": true,
                "explain": "Correct. Even with automated security scanning and QA, a manual peer review is a critical final gate in a secure development life cycle. Another developer or a senior engineer should review the code changes to look for logic flaws, security vulnerabilities, or other issues that automated tools might miss. This human oversight is essential before the code is approved for merging and deployment."
            }
        ]
    },
    {
        "id": 262,
        "q": "A SOC team receives notifications that align with playbook incidents. The team wants to analyze the potential threat actors TTPs. Which of the following will best assist the SOC team?",
        "type": "single",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "D3FEND",
                "correct": false,
                "explain": "Incorrect. D3FEND is a knowledge graph of cybersecurity countermeasure techniques. It's used to map defensive techniques to offensive ones, but ATT&CK is the primary framework for analyzing the offensive TTPs themselves."
            },
            {
                "text": "OWASP",
                "correct": false,
                "explain": "Incorrect. OWASP provides resources for web application security, not a comprehensive framework for general adversary TTPs."
            },
            {
                "text": "ATT&CK",
                "correct": true,
                "explain": "Correct. The MITRE ATT&CK (Adversarial Tactics, Techniques, and Common Knowledge) framework is a curated knowledge base and model for cyber adversary behavior. It provides a detailed taxonomy of the Tactics, Techniques, and Procedures (TTPs) used by threat actors. It is the industry-standard resource for SOC teams to analyze alerts, understand an adversary's actions, and map them to a common framework."
            },
            {
                "text": "COPPA",
                "correct": false,
                "explain": "Incorrect. COPPA is a US law regarding children's online privacy and is not a framework for analyzing TTPs."
            },
            {
                "text": "CAPEC",
                "correct": false,
                "explain": "Incorrect. CAPEC is a dictionary of attack patterns, but ATT&CK is the more comprehensive framework used by SOCs for analyzing adversary behavior in the context of an incident."
            }
        ]
    },
    {
        "id": 263,
        "q": "Which of the following best describes the reason PQC preparation is important?",
        "type": "single",
        "category": "3.7 Explain the importance of advanced cryptographic concepts.",
        "answers": [
            {
                "text": "To protect data against decryption due to increases in computational resource availability",
                "correct": true,
                "explain": "Correct. Post-Quantum Cryptography (PQC) is being developed to address the future threat posed by large-scale quantum computers. These future computers, due to their massive increase in specific types of computational resource availability, will be able to break many of the public-key encryption algorithms currently in use (like RSA and ECC). PQC preparation is important to develop and transition to new cryptographic algorithms that are resistant to attack by both classical and quantum computers, thus protecting data in the long term."
            },
            {
                "text": "To have larger key lengths available through key stretching",
                "correct": false,
                "explain": "Incorrect. Key stretching is a technique for strengthening passwords and is unrelated to PQC."
            },
            {
                "text": "To improve encryption performance and speed using lightweight cryptography",
                "correct": false,
                "explain": "Incorrect. Lightweight cryptography is for use in resource-constrained devices (like IoT). PQC algorithms are often more computationally expensive than current algorithms, not less."
            },
            {
                "text": "To leverage asymmetric encryption for large amounts of data",
                "correct": false,
                "explain": "Incorrect. Asymmetric encryption is already used for key exchange, but symmetric encryption is used for encrypting large amounts of data. This principle does not change with PQC."
            }
        ]
    },
    {
        "id": 264,
        "q": "After investigating a recent security incident, a SOC analyst is charged with creating a reference guide for the entire team to use. Which of the following should the analyst create to address future incidents?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "Root cause analysis",
                "correct": false,
                "explain": "Incorrect. The root cause analysis is the investigation that was just completed. Its findings would be an input to the new reference guide."
            },
            {
                "text": "Communication plan",
                "correct": false,
                "explain": "Incorrect. A communication plan outlines how to communicate with stakeholders outside the SOC. The guide needed is for the team's internal technical actions."
            },
            {
                "text": "Runbook",
                "correct": true,
                "explain": "Correct. A runbook (or a playbook) is a detailed, step-by-step guide that documents the standard operating procedures for handling a specific type of security incident. By creating a runbook based on the lessons learned from the recent incident, the analyst provides the entire team with a consistent, repeatable, and efficient process to follow when a similar incident occurs in the future. This is the definition of a reference guide for addressing future incidents."
            },
            {
                "text": "Lessons learned",
                "correct": false,
                "explain": "Incorrect. The lessons learned report is a summary of what went right and wrong during the last incident. A runbook is the forward-looking procedural document created based on those lessons."
            }
        ]
    },
    {
        "id": 265,
        "q": "A DNS forward lookup zone named comptia.org must: Ensure the DNS is protected from on-path attacks. Ensure zone transfers use mutual authentication and are authenticated and negotiated. Which of the following should the security architect configure to meet these requirements? (Choose two).",
        "type": "multiple",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "Public keys",
                "correct": false,
                "explain": "Incorrect. While DNSSEC uses public-key cryptography, simply having public keys doesn't meet the requirements. You need to configure the specific DNSSEC protocol."
            },
            {
                "text": "Conditional forwarders",
                "correct": false,
                "explain": "Incorrect. Conditional forwarders are a DNS feature for routing queries for specific domains to specific servers; they do not provide security."
            },
            {
                "text": "Root hints",
                "correct": false,
                "explain": "Incorrect. Root hints are the list of root DNS servers used to resolve external domains; they are not a security configuration for a local zone."
            },
            {
                "text": "DNSSEC",
                "correct": true,
                "explain": "Correct. DNS Security Extensions (DNSSEC) is a suite of protocols that adds a layer of security to the DNS. It uses digital signatures to provide origin authentication and data integrity for DNS records, which directly protects the DNS from on-path attacks like cache poisoning and spoofing."
            },
            {
                "text": "CNAME records",
                "correct": false,
                "explain": "Incorrect. CNAME records are a standard type of DNS record for creating aliases; they are not a security feature."
            },
            {
                "text": "SRV records",
                "correct": true,
                "explain": "Correct. The requirement is for zone transfers (AXFR/IXFR) to be mutually authenticated. While DNSSEC signs the records, securing the transfer itself often involves protocols that leverage Service (SRV) records to discover and negotiate secure transfer mechanisms, such as using transaction signatures (TSIG) or other secure protocols. In a Windows environment, secure dynamic updates and zone transfers are tightly integrated with Active Directory and use Kerberos, which relies on SRV records for service discovery."
            }
        ]
    },
    {
        "id": 266,
        "q": "A security architect is implementing a SOAR solution in an organizations cloud production environment to support detection capabilities. Which of the following will be the most likely benefit?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "Improved security operations center performance",
                "correct": true,
                "explain": "Correct. The primary benefit of a Security Orchestration, Automation, and Response (SOAR) solution is improving the efficiency and effectiveness of the Security Operations Center (SOC). It achieves this by automating repetitive, manual tasks (like alert triage and data enrichment) and orchestrating complex response workflows across multiple tools. This frees up analysts to focus on more complex threats and dramatically reduces the Mean Time to Respond (MTTR), thereby improving overall SOC performance."
            },
            {
                "text": "Automated firewall log collection tasks",
                "correct": false,
                "explain": "Incorrect. Log collection is the primary function of a SIEM or a log aggregator, not a SOAR. A SOAR acts on the alerts generated from those logs."
            },
            {
                "text": "Optimized cloud resource utilization",
                "correct": false,
                "explain": "Incorrect. A SOAR platform does not manage or optimize the utilization of general cloud resources."
            },
            {
                "text": "Increased risk visibility",
                "correct": false,
                "explain": "Incorrect. While improved response can lower risk, tools like vulnerability scanners and SIEMs are more directly responsible for increasing risk visibility."
            }
        ]
    },
    {
        "id": 267,
        "q": "A cloud security architect has been tasked with finding a solution for hardening VMs. The solution must meet the following requirements: Data needs to be stored outside of the VMs. No unauthorized modifications to the VMs are allowed. If a change needs to be done, a new VM needs to be deployed. Which of the following is the best solution?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "Immutable system",
                "correct": true,
                "explain": "Correct. The requirements described are the definition of an immutable infrastructure. In this model, systems (like VMs or containers) are never modified in place after deployment. If a change is needed (like a patch or configuration update), a new, updated VM is built from a golden image and deployed, and the old one is destroyed. This ensures a consistent, known state and prevents configuration drift, which directly meets all the stated requirements."
            },
            {
                "text": "Data loss prevention",
                "correct": false,
                "explain": "Incorrect. DLP is a solution for preventing data exfiltration; it does not relate to the hardening and deployment model of VMs."
            },
            {
                "text": "Storage area network",
                "correct": false,
                "explain": "Incorrect. A SAN is a type of networked storage. While it would be used to store data outside the VMs, it does not enforce the immutability requirement."
            },
            {
                "text": "Baseline template",
                "correct": false,
                "explain": "Incorrect. A baseline template (or golden image) is a component used to build an immutable system, but 'immutable system' is the name of the overall architectural pattern being described."
            }
        ]
    },
    {
        "id": 268,
        "q": "After the latest risk assessment, the Chief Information Security Officer (CISO) decides to meet with the development and security teams to find a way to reduce the security task workload. The CISO would like to: Have a solution that uses an API to communicate with other security tools. Use the latest technology possible. Have the highest controls possible on the solution. Which of following is the best option to meet these requirements?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "EDR",
                "correct": false,
                "explain": "Incorrect. An Endpoint Detection and Response (EDR) solution is focused on endpoints and, while it has APIs, it does not provide the broad orchestration capabilities needed."
            },
            {
                "text": "CSP",
                "correct": false,
                "explain": "Incorrect. A Cloud Service Provider (CSP) is a vendor of cloud services, not a specific technology solution for security automation."
            },
            {
                "text": "SOAR",
                "correct": true,
                "explain": "Correct. A Security Orchestration, Automation, and Response (SOAR) platform is the best fit for all requirements. 1) It is designed to use APIs to integrate with and orchestrate actions across a wide range of other security tools (SIEM, EDR, firewalls, etc.). 2) It represents the latest technology in security operations for reducing workload through automation. 3) It provides a high level of control by allowing teams to build and customize detailed playbooks for incident response."
            },
            {
                "text": "CASB",
                "correct": false,
                "explain": "Incorrect. A Cloud Access Security Broker (CASB) is for securing access to cloud applications and does not provide the general-purpose automation and orchestration capabilities of a SOAR."
            }
        ]
    },
    {
        "id": 269,
        "q": "A new, online file hosting service is being offered. The service has the following security requirements: Threats to customer data integrity and availability should be remediated first. The environment should be dynamic to match increasing customer demands. The solution should not interfere with customers ability to access their data at anytime. Security analysts should focus on high-risk items. Which of the following would best satisfy the requirements?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "Expanding the use of IPS and NGFW devices throughout the environment",
                "correct": false,
                "explain": "Incorrect. While useful, scaling traditional hardware appliances can be difficult in a dynamic environment and might not be the most efficient solution."
            },
            {
                "text": "Increasing the number of analysts to identify risks that need remediation",
                "correct": false,
                "explain": "Incorrect. This is not a scalable solution and goes against the requirement for analysts to focus on high-risk items, not repetitive tasks."
            },
            {
                "text": "Implementing a SOAR solution to address known threats",
                "correct": true,
                "explain": "Correct. A Security Orchestration, Automation, and Response (SOAR) solution is ideal for this scenario. It can automate the response to common, known threats (like malware uploads or brute-force attempts), which addresses the integrity and availability requirements quickly and without analyst intervention. This automation allows the limited number of security analysts to focus their efforts on novel, high-risk threats, satisfying all the key requirements."
            },
            {
                "text": "Integrating enterprise threat feeds in the existing SIEM",
                "correct": false,
                "explain": "Incorrect. Integrating threat feeds improves detection in the SIEM, but it does not automate the remediation and response, which is a key part of the solution needed to free up analyst time."
            }
        ]
    },
    {
        "id": 270,
        "q": "A university issues badges through a homegrown identity management system to all staff and students. Each week during the summer, temporary summer school students arrive and need to be issued a badge to access minimal campus resources. The security team received a report from an outside auditor indicating the homegrown system is not consistent with best practices in the security field. Which of the following should the security team recommend first?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Investigating a potential threat identified in logs related to the identity management system",
                "correct": false,
                "explain": "Incorrect. While any threat should be investigated, the audit finding points to a fundamental, strategic flaw in the system, which needs to be addressed first."
            },
            {
                "text": "Updating the identity management system to use discretionary access control",
                "correct": false,
                "explain": "Incorrect. Deciding on a specific access control model is a tactical decision that would come after the strategic decision to replace the system."
            },
            {
                "text": "Beginning research on two-factor authentication to later introduce into the identity management system",
                "correct": false,
                "explain": "Incorrect. Adding features to a homegrown system that is fundamentally not aligned with best practices is not a good use of resources."
            },
            {
                "text": "Working with procurement and creating a requirements document to select a new IAM system/vendor",
                "correct": true,
                "explain": "Correct. The auditor has identified that the homegrown system is not consistent with best practices. Maintaining and securing a custom IAM solution is extremely difficult and risky. The most appropriate first step is to recognize that the homegrown solution needs to be replaced with a commercial, enterprise-grade Identity and Access Management (IAM) system that is built on security best practices and can handle the complex lifecycle of different user types (staff, students, temporary students). Creating a requirements document is the first step in that procurement process."
            }
        ]
    },
    {
        "id": 271,
        "q": "Which of the following are risks associated with vendor lock-in? (Choose two.)",
        "type": "multiple",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "The client can seamlessly move data.",
                "correct": false,
                "explain": "Incorrect. This is the opposite of vendor lock-in. A major risk of lock-in is that it is difficult and expensive to move data to a different vendor."
            },
            {
                "text": "The vendor can change product offerings.",
                "correct": true,
                "explain": "Correct. If a client is locked into a vendor's ecosystem, they are at the mercy of the vendor's business decisions. The vendor could decide to discontinue a critical product or change its features in a way that is detrimental to the client, who has no easy alternative."
            },
            {
                "text": "The client receives a sufficient level of service.",
                "correct": false,
                "explain": "Incorrect. A decrease in service quality is a risk, not receiving a sufficient level."
            },
            {
                "text": "The client experiences decreased quality of service.",
                "correct": true,
                "explain": "Correct. When a vendor knows a client is locked in and cannot easily leave, the vendor may have less incentive to maintain a high quality of service or competitive pricing, as they face little risk of losing the client's business."
            },
            {
                "text": "The client can leverage a multicloud approach.",
                "correct": false,
                "explain": "Incorrect. Vendor lock-in is an obstacle to a multicloud approach, as it ties the client to a single vendor's proprietary services."
            },
            {
                "text": "The client experiences increased interoperability.",
                "correct": false,
                "explain": "Incorrect. Vendor lock-in typically leads to decreased interoperability, as the vendor's services are often proprietary and not designed to work well with competitors' products."
            }
        ]
    },
    {
        "id": 272,
        "q": "Due to budget constraints, an organization created a policy that only permits vulnerabilities rated high and critical according to CVSS to be fixed or mitigated. A security analyst notices that many vulnerabilities that were previously scored as medium are now breaching higher thresholds. Upon further investigation, the analyst notices certain ratings are not aligned with the approved system categorization. Which of the following can the analyst do to get a better picture of the risk while adhering to the organizations policy?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "Align the exploitability metrics to the predetermined system categorization.",
                "correct": false,
                "explain": "Incorrect. Exploitability metrics (like Attack Vector) are inherent to the vulnerability itself and should not be modified based on the system's categorization."
            },
            {
                "text": "Align the remediation levels to the predetermined system categorization.",
                "correct": false,
                "explain": "Incorrect. The remediation level is part of the Temporal score and reflects the availability of a patch. It should not be modified based on system categorization."
            },
            {
                "text": "Align the impact subscore requirements to the predetermined system categorization.",
                "correct": true,
                "explain": "Correct. The CVSS score has three parts: Base, Temporal, and Environmental. The Base score is generic, but the Environmental score allows an organization to customize the score based on their specific environment. The 'Impact Subscore Requirements' (also known as Modified Impact Metrics) within the Environmental score allow the analyst to adjust the Confidentiality, Integrity, and Availability impact based on the importance of the specific asset (the system categorization). By correctly setting these environmental metrics, the analyst can generate a more accurate risk score that reflects the true risk to the organization, ensuring that a vulnerability on a critical system receives a higher, more appropriate score."
            },
            {
                "text": "Align the attack vectors to the predetermined system categorization.",
                "correct": false,
                "explain": "Incorrect. The Attack Vector is a Base metric and should not be changed based on the system's categorization."
            }
        ]
    },
    {
        "id": 273,
        "q": "An IT department is currently working to implement an enterprise DLP solution. Due diligence and best practices must be followed in regard to mitigating risk. Which of the following ensures that authorized modifications are well planned and executed?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "Risk management",
                "correct": false,
                "explain": "Incorrect. Risk management is the overall process of identifying and treating risks. Change management is the specific process for handling modifications."
            },
            {
                "text": "Network management",
                "correct": false,
                "explain": "Incorrect. Network management is focused on the operation of the network infrastructure."
            },
            {
                "text": "Configuration management",
                "correct": false,
                "explain": "Incorrect. Configuration management is the process of tracking and documenting the state of systems. Change management is the process of approving modifications to that state."
            },
            {
                "text": "Change management",
                "correct": true,
                "explain": "Correct. Change management (or change control) is the formal governance process used to ensure that any modifications to IT systems are reviewed, approved, documented, tested, and implemented in a controlled manner. This process directly ensures that 'authorized modifications are well planned and executed,' preventing unauthorized or chaotic changes that could introduce new risks or service disruptions during the DLP implementation."
            }
        ]
    },
    {
        "id": 274,
        "q": "A security architect wants to prevent security impacts from input into data fields, such as the following: `'AND 1=1#` Which of the following would best accomplish this objective?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "APIs",
                "correct": false,
                "explain": "Incorrect. APIs define how software components interact, but they do not inherently prevent injection attacks. The API implementation must be written securely."
            },
            {
                "text": "Coding standards",
                "correct": true,
                "explain": "Correct. The input `'AND 1=1#` is a classic example of a SQL injection attack. The most effective way to prevent this entire class of vulnerability is to establish and enforce secure coding standards for developers. These standards would mandate the use of defenses like query parameterization (prepared statements) instead of dynamic query construction, which would neutralize the injection attack."
            },
            {
                "text": "Base64 encoding",
                "correct": false,
                "explain": "Incorrect. Base64 is an encoding scheme, not a security control. An attacker can easily Base64-encode their malicious payload."
            },
            {
                "text": "Sandboxing",
                "correct": false,
                "explain": "Incorrect. Sandboxing is for running untrusted code in a restricted environment. It does not prevent injection attacks against a web application."
            }
        ]
    },
    {
        "id": 275,
        "q": "A software development company needs to mitigate third-party risks to its software supply chain. Which of the following techniques should the company use in the development environment to best meet this objective?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Performing software composition analysis",
                "correct": true,
                "explain": "Correct. A company's software supply chain includes all the third-party and open-source libraries and components used in its products. Software Composition Analysis (SCA) is the automated process of identifying these components and their known vulnerabilities. By integrating SCA tools into the development environment, the company can proactively identify and mitigate risks from its third-party dependencies."
            },
            {
                "text": "Requiring multifactor authentication",
                "correct": false,
                "explain": "Incorrect. MFA secures developer access but does not address vulnerabilities within the third-party code they use."
            },
            {
                "text": "Establishing coding standards and monitoring for compliance",
                "correct": false,
                "explain": "Incorrect. Coding standards apply to the company's own code, not to the third-party components it consumes."
            },
            {
                "text": "Implementing a robust unit and regression-testing scheme",
                "correct": false,
                "explain": "Incorrect. Functional testing like unit and regression tests are unlikely to discover underlying vulnerabilities in third-party libraries. SCA is the specific tool for this purpose."
            }
        ]
    },
    {
        "id": 276,
        "q": "A mobile device hardware manufacturer receives the following requirements from a company that wants to produce and sell a new mobile platform: The platform should store biometric data. The platform should prevent unapproved firmware from being loaded. A tamper-resistant, hardware-based counter should track if unapproved firmware was loaded. Which of the following should the hardware manufacturer implement? (Choose three).",
        "type": "multiple",
        "category": "3.4 Given a scenario, implement hardware security technologies and techniques.",
        "answers": [
            {
                "text": "ASLR",
                "correct": false,
                "explain": "Incorrect. Address Space Layout Randomization (ASLR) is a memory protection technique implemented by the OS, not a hardware feature for firmware protection."
            },
            {
                "text": "NX",
                "correct": false,
                "explain": "Incorrect. The No-Execute (NX) bit is a CPU feature for memory protection, not for firmware integrity."
            },
            {
                "text": "eFuse",
                "correct": true,
                "explain": "Correct. An eFuse is a one-time programmable, non-volatile memory element on a chip. It can be used as a tamper-resistant hardware counter. For example, it can be 'blown' to permanently record that a device has been unlocked or that unapproved firmware has been loaded."
            },
            {
                "text": "SED",
                "correct": false,
                "explain": "Incorrect. A Self-Encrypting Drive (SED) provides data-at-rest encryption but does not meet the other requirements."
            },
            {
                "text": "SELinux",
                "correct": false,
                "explain": "Incorrect. SELinux is a security module for the Linux OS and is not a hardware feature."
            },
            {
                "text": "Secure boot",
                "correct": true,
                "explain": "Correct. Secure Boot is a hardware-backed UEFI feature that ensures the device only boots using software that is trusted and signed by the OEM. This directly prevents unapproved firmware from being loaded."
            },
            {
                "text": "Shell restriction",
                "correct": false,
                "explain": "Incorrect. This is a software-level configuration, not a hardware feature for securing biometric data or firmware."
            },
            {
                "text": "Secure enclave",
                "correct": true,
                "explain": "Correct. A secure enclave is an isolated, hardware-based secure coprocessor within the main CPU. Its primary purpose is to provide a protected execution environment for sensitive operations and to securely store sensitive data like cryptographic keys and biometric templates. This directly meets the requirement to store biometric data securely."
            }
        ]
    },
    {
        "id": 277,
        "q": "Based on a recent security audit, a company discovered the perimeter strategy is inadequate for its recent growth. To address this issue, the company is looking for a solution that includes the following requirements: Collapse of multiple network security technologies into a single footprint. Support for multiple VPNs with different security contexts. Support for application layer security (Layer 7 of the OSI Model). Which of the following technologies would be the most appropriate solution given these requirements?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "NAT gateway",
                "correct": false,
                "explain": "Incorrect. A NAT gateway only provides network address translation and does not meet any of the advanced security requirements."
            },
            {
                "text": "Reverse proxy",
                "correct": false,
                "explain": "Incorrect. A reverse proxy protects backend servers but doesn't provide the broad network security functions required."
            },
            {
                "text": "NGFW",
                "correct": true,
                "explain": "Correct. A Next-Generation Firewall (NGFW) is the technology that best meets all these requirements. 1) NGFWs consolidate multiple security functions (firewall, IPS, application control, VPN) into a single appliance. 2) They are designed to support multiple VPN tunnels and can use virtual routing and forwarding (VRF) or similar technologies to create different security contexts. 3) A defining feature of an NGFW is its ability to perform deep packet inspection and enforce policies at the application layer (Layer 7)."
            },
            {
                "text": "NIDS",
                "correct": false,
                "explain": "Incorrect. A Network Intrusion Detection System (NIDS) is a passive monitoring tool and does not provide firewalling, VPN, or preventative security capabilities."
            }
        ]
    },
    {
        "id": 278,
        "q": "A security administrator has isolated a computer system because it was targeted by a ransomware attack. Which of the following should the security administrator do to recover from this attack in the most secure way?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Check if file versioning is enabled and restore the files.",
                "correct": false,
                "explain": "Incorrect. While file versioning might allow recovery, modern ransomware often targets and deletes shadow copies and versions. Restoring from a known-good baseline is more secure."
            },
            {
                "text": "Restore the system from a baseline snapshot.",
                "correct": true,
                "explain": "Correct. After a system has been compromised by ransomware, it cannot be trusted. The malware may have established persistence mechanisms or left other malicious code behind. The most secure way to recover is to completely wipe the infected system and restore it from a known-good, trusted baseline image or snapshot that was taken before the infection occurred. The user data can then be restored from a separate, clean backup."
            },
            {
                "text": "Determine if the encryption key can be recovered. If it can, restore the files.",
                "correct": false,
                "explain": "Incorrect. Even if the files are decrypted, the underlying operating system is still compromised and cannot be trusted. The system must be rebuilt."
            },
            {
                "text": "Seek approval from senior leadership to pay the ransom and unencrypt the files with the provided key.",
                "correct": false,
                "explain": "Incorrect. Paying the ransom is a last resort and does not guarantee file recovery. Furthermore, it does not address the fact that the system itself is still compromised."
            }
        ]
    },
    {
        "id": 279,
        "q": "A user from the sales department opened a suspicious file attachment. The sales department then contacted the SOC to investigate a number of unresponsive systems, and the team successfully identified the file and the origin of the attack. Which of the following is the next step of the incident response plan?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "Remediation",
                "correct": false,
                "explain": "Incorrect. Remediation, which involves patching systems and improving defenses, happens after the incident is contained and eradicated."
            },
            {
                "text": "Containment",
                "correct": true,
                "explain": "Correct. According to standard incident response models (like the one from NIST), the phase after Identification is Containment. The team has identified the attack. Their immediate next step is to contain the incident to prevent it from spreading further. This could involve isolating the affected systems from the network, blocking malicious IPs at the firewall, or disabling compromised user accounts."
            },
            {
                "text": "Response",
                "correct": false,
                "explain": "Incorrect. 'Response' is the name for the overall process. 'Containment' is the specific next phase."
            },
            {
                "text": "Recovery",
                "correct": false,
                "explain": "Incorrect. Recovery, which involves restoring systems to normal operation from clean backups, is one of the final phases of the incident response lifecycle."
            }
        ]
    },
    {
        "id": 280,
        "q": "A security manager has written an incident response playbook for insider attacks and is ready to begin testing it. Which of the following should the manager conduct to test the playbook?",
        "type": "single",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "Automated vulnerability scanning",
                "correct": false,
                "explain": "Incorrect. Vulnerability scanning is for finding weaknesses; it does not test an incident response playbook."
            },
            {
                "text": "Centralized logging, data analytics, and visualization",
                "correct": false,
                "explain": "Incorrect. These are the tools that would be used during a response; they are not the method for testing the response plan itself."
            },
            {
                "text": "Threat hunting",
                "correct": false,
                "explain": "Incorrect. Threat hunting is a proactive process to find undetected threats. It is not an exercise to test a specific playbook."
            },
            {
                "text": "Threat emulation",
                "correct": true,
                "explain": "Correct. To test an incident response playbook, the security team needs to simulate the specific threat the playbook is designed for. Threat emulation (or adversary emulation) is the process of mimicking the tactics, techniques, and procedures (TTPs) of a specific threat actor or threat type, in this case, an insider attacker. By conducting a controlled threat emulation exercise, the manager can see how the SOC team uses the playbook to detect and respond to the simulated attack, thereby effectively testing it."
            }
        ]
    },
    {
        "id": 281,
        "q": "The Chief Security Officer (CSO) requested the security team implement technical controls that meet the following requirements: Monitors traffic to and from both local NAS and cloud-based file repositories. Prevents on-site staff who are accessing sensitive customer PII documents on file repositories from accidentally or deliberately sharing sensitive documents on personal SaaS solutions. Uses document attributes to reduce false positives. Is agentless and not installed on staff desktops or laptops. Which of the following when installed and configured would best meet the CSOs requirements? (Choose two.)",
        "type": "multiple",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "DLP",
                "correct": true,
                "explain": "Correct. Data Loss Prevention (DLP) is the core technology that inspects content to identify sensitive data (like PII) and enforce policies to prevent its exfiltration. The requirement to use document attributes (classification labels or tags) to reduce false positives is a key feature of modern DLP solutions."
            },
            {
                "text": "NGFW",
                "correct": false,
                "explain": "Incorrect. While an NGFW can inspect traffic, it typically lacks the granular, content-aware policies of a dedicated DLP or CASB solution."
            },
            {
                "text": "UTM",
                "correct": false,
                "explain": "Incorrect. A Unified Threat Management (UTM) appliance is a collection of security features but may not have the sophisticated cloud application control or content analysis needed."
            },
            {
                "text": "UEBA",
                "correct": false,
                "explain": "Incorrect. UEBA detects anomalous behavior but doesn't typically enforce preventative policies on data flow to cloud applications."
            },
            {
                "text": "CASB",
                "correct": true,
                "explain": "Correct. A Cloud Access Security Broker (CASB) is specifically designed to enforce security policies between users and cloud services. A network-based CASB (which would be agentless) can monitor and control traffic to cloud repositories and personal SaaS solutions. It can integrate with a DLP engine to prevent the sharing of sensitive documents and meets the requirement to monitor both on-premise (via network integration) and cloud repositories."
            },
            {
                "text": "HIPS",
                "correct": false,
                "explain": "Incorrect. A Host-based Intrusion Prevention System (HIPS) is an agent-based solution installed on endpoints, which violates the 'agentless' requirement."
            }
        ]
    },
    {
        "id": 282,
        "q": "A security engineer needs to select the architecture for a cloud database that will protect an organizations sensitive data. The engineer has a choice between a single-tenant or a multitenant database architecture offered by a cloud vendor. Which of the following best describes the security benefits of the single-tenant option? (Choose two.)",
        "type": "multiple",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "Most cost-effective",
                "correct": false,
                "explain": "Incorrect. Single-tenant architecture, which involves dedicated infrastructure, is almost always more expensive than multitenant architecture, which shares resources among customers."
            },
            {
                "text": "Ease of backup and restoration",
                "correct": false,
                "explain": "Incorrect. Backup and restoration procedures are not inherently easier in a single-tenant environment; they are just more isolated."
            },
            {
                "text": "High degree of privacy",
                "correct": true,
                "explain": "Correct. In a single-tenant architecture, the customer's data and resources are physically or logically isolated from all other customers. This eliminates the risk of data leakage or interference between tenants, providing the highest degree of privacy."
            },
            {
                "text": "Low resilience to side-channel attacks",
                "correct": false,
                "explain": "Incorrect. Single-tenancy provides high resilience to side-channel attacks, as there are no other 'noisy neighbors' on the same physical hardware whose activity can be monitored."
            },
            {
                "text": "Full control and ability to customize",
                "correct": true,
                "explain": "Correct. A significant benefit of a single-tenant environment is that the customer has a greater degree of control over the infrastructure. They can often customize the hardware, network configuration, and security settings to a much greater extent than in a shared, multitenant environment."
            },
            {
                "text": "Increased geographic diversity",
                "correct": false,
                "explain": "Incorrect. Geographic diversity is a separate architectural choice and is not an inherent benefit of single-tenancy."
            }
        ]
    },
    {
        "id": 283,
        "q": "The information security manager at a 24-hour manufacturing facility is reviewing a contract for potential risks to the organization. The contract pertains to the support of printers and multifunction devices during non-standard business hours. Which of the following will the security manager most likely identify as a risk?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Print configurations settings for locked print jobs",
                "correct": false,
                "explain": "Incorrect. This is a technical configuration detail, not a contractual risk."
            },
            {
                "text": "The lack of an NDA with the company that supports its devices",
                "correct": true,
                "explain": "Correct. The contract is with a third-party vendor whose staff will be on-site with physical access to devices during non-standard hours. These multifunction devices often store copies of sensitive documents that have been printed, scanned, or faxed. Without a Non-Disclosure Agreement (NDA) in place, there is no legal protection to prevent the vendor's employees from viewing or disclosing any confidential information they might access, creating a significant data privacy and confidentiality risk."
            },
            {
                "text": "The lack of an MSA to govern other services provided by the service provider",
                "correct": false,
                "explain": "Incorrect. A Master Service Agreement (MSA) is for governing multiple contracts. The immediate risk in this single contract is the lack of confidentiality protection (NDA)."
            },
            {
                "text": "The lack of chain of custody for devices prior to deployment at the company",
                "correct": false,
                "explain": "Incorrect. While important for new devices, the contract pertains to ongoing support, where the confidentiality of data processed by the devices is the primary concern."
            }
        ]
    },
    {
        "id": 284,
        "q": "A penetration tester discovers a condition that causes unexpected behavior in a web application. This results in the dump of the interpreters debugging information, which includes the interpreters version, full path of binary files, and the user ID running the process. Which of the following actions would best mitigate this risk?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Include routines in the application for message handling.",
                "correct": true,
                "explain": "Correct. The vulnerability is an improper error handling weakness. The application is failing in a way that causes it to leak sensitive debugging information to the end user. The proper mitigation is to implement custom error handling routines. These routines should catch all exceptions, log the detailed debugging information to a secure, backend file for developers to review, and present the user with a generic, non-informative error message (e.g., 'An unexpected error has occurred. Please try again later.')."
            },
            {
                "text": "Adopt a compiled programming language instead.",
                "correct": false,
                "explain": "Incorrect. Compiled languages can also suffer from improper error handling and leak information. The choice of language is not the root cause."
            },
            {
                "text": "Perform SAST vulnerability scans on every build.",
                "correct": false,
                "explain": "Incorrect. While SAST is a good practice, it may not find all logic flaws related to error handling. The direct fix is to implement proper message handling."
            },
            {
                "text": "Validate user-generated input.",
                "correct": false,
                "explain": "Incorrect. While input validation is critical, the specific problem here is what the application does *after* an error occurs. Proper error handling is needed even for unexpected errors not caused by user input."
            }
        ]
    },
    {
        "id": 285,
        "q": "A security architect is analyzing an old application that is not covered for maintenance anymore because the software company is no longer in business. Which of the following techniques should have been implemented to prevent these types of risks?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Code reviews",
                "correct": false,
                "explain": "Incorrect. Code reviews assess the quality of the code but do not provide access to it if the vendor goes out of business."
            },
            {
                "text": "Supply chain visibility",
                "correct": false,
                "explain": "Incorrect. Supply chain visibility helps understand dependencies but doesn't guarantee access to the source code."
            },
            {
                "text": "Software audits",
                "correct": false,
                "explain": "Incorrect. An audit assesses the software but doesn't provide a mechanism to maintain it after the vendor disappears."
            },
            {
                "text": "Source code escrows",
                "correct": true,
                "explain": "Correct. A source code escrow is a legal arrangement where the source code for a piece of software is held by a trusted, independent third party. The escrow agreement specifies conditions under which the source code will be released to the licensee (the customer), such as the software vendor going out of business. This is the specific technique designed to mitigate the risk of being left with an unmaintainable, business-critical application if the vendor fails."
            }
        ]
    },
    {
        "id": 286,
        "q": "To bring digital evidence in a court of law, the evidence must be:",
        "type": "single",
        "category": "1.3 Explain how compliance affects information security strategies.",
        "answers": [
            {
                "text": "material.",
                "correct": true,
                "explain": "Correct. In a legal context, for evidence to be admissible, it must be relevant and material. 'Material' means that the evidence has a logical connection to the facts of the case and has a bearing on its outcome. Irrelevant evidence is not admissible."
            },
            {
                "text": "tangible.",
                "correct": false,
                "explain": "Incorrect. Digital evidence is often intangible by nature. Courts have well-established procedures for admitting non-tangible evidence."
            },
            {
                "text": "consistent.",
                "correct": false,
                "explain": "Incorrect. While consistency is a desirable quality, it is not a strict legal requirement for admissibility in the same way materiality is."
            },
            {
                "text": "conserved.",
                "correct": false,
                "explain": "Incorrect. 'Conserved' is not a standard legal term for evidence admissibility. The correct term is 'preserved,' which relates to maintaining the chain of custody and integrity."
            }
        ]
    },
    {
        "id": 287,
        "q": "A cloud security architect has been tasked with selecting the appropriate solution given the following: The solution must allow the lowest RTO possible. The solution must have the least shared responsibility possible. Patching should be a responsibility of the CSP. Which of the following solutions can best fulfill the requirements?",
        "type": "single",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "PaaS",
                "correct": false,
                "explain": "Incorrect. While the CSP handles patching in PaaS, the customer is still responsible for the application and data, which is more responsibility than in a SaaS model."
            },
            {
                "text": "IaaS",
                "correct": false,
                "explain": "Incorrect. In an Infrastructure as a Service (IaaS) model, the customer has the most responsibility, including patching the operating system."
            },
            {
                "text": "Private",
                "correct": false,
                "explain": "Incorrect. A private cloud deployment model typically entails the highest level of responsibility for the organization."
            },
            {
                "text": "SaaS",
                "correct": true,
                "explain": "Correct. Software as a Service (SaaS) best fits these requirements. 1) SaaS solutions are managed by the provider for high availability, typically offering the lowest Recovery Time Objective (RTO). 2) In the shared responsibility model, SaaS places the least responsibility on the customer; the vendor manages everything from the infrastructure up to the application itself. 3) Patching of the application and underlying infrastructure is entirely the responsibility of the Cloud Service Provider (CSP)/SaaS vendor."
            }
        ]
    },
    {
        "id": 288,
        "q": "A security analyst wants to keep track of all outbound web connections from workstations. The analysts company uses an on-premises web filtering solution that forwards the outbound traffic to a perimeter firewall. When the security analyst gets the connection events from the firewall, the source IP of the outbound web traffic is the translated IP of the web filtering solution. Considering this scenario involving source NAT, which of the following would be the best option to inject in the HTTP header to include the real source IP from workstations?",
        "type": "single",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "X-Forwarded-Proto",
                "correct": false,
                "explain": "Incorrect. The X-Forwarded-Proto header is used to identify the protocol (HTTP or HTTPS) that a client used to connect to a proxy or load balancer."
            },
            {
                "text": "X-Forwarded-For",
                "correct": true,
                "explain": "Correct. The scenario describes a problem where a proxy (the web filtering solution) is obscuring the original client IP address due to Network Address Translation (NAT). The X-Forwarded-For (XFF) header is the standard mechanism used by proxies to solve this problem. The proxy adds the XFF header to the HTTP request, and its value is the original IP address of the client workstation. This allows the downstream firewall and other logging tools to see the real source IP."
            },
            {
                "text": "Cache-Control",
                "correct": false,
                "explain": "Incorrect. The Cache-Control header specifies caching policies and is not used for identifying source IPs."
            },
            {
                "text": "Strict-Transport-Security",
                "correct": false,
                "explain": "Incorrect. The HSTS header is a security policy that tells browsers to only connect to a site using HTTPS. It is not used for identifying source IPs."
            },
            {
                "text": "Content-Security-Policy",
                "correct": false,
                "explain": "Incorrect. The CSP header is a security policy to prevent cross-site scripting and other injection attacks. It is not used for identifying source IPs."
            }
        ]
    },
    {
        "id": 289,
        "q": "A security team is creating tickets to track the progress of remediation. Which of the following is used to specify the due dates for high- and critical-priority findings?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "MSA",
                "correct": false,
                "explain": "Incorrect. A Master Service Agreement (MSA) is a contract that governs future agreements and transactions."
            },
            {
                "text": "SLA",
                "correct": true,
                "explain": "Correct. A Service Level Agreement (SLA) is a commitment between a service provider and a client that defines specific, measurable metrics. In a security context, an SLA is often established to define the required timelines for remediating vulnerabilities based on their severity. For example, the SLA might state that all critical-priority findings must be remediated within 7 days, and high-priority findings within 30 days."
            },
            {
                "text": "ISA",
                "correct": false,
                "explain": "Incorrect. An Interconnection Security Agreement (ISA) is an agreement between two organizations that are connecting their IT systems."
            },
            {
                "text": "MOU",
                "correct": false,
                "explain": "Incorrect. A Memorandum of Understanding (MOU) is a non-binding agreement that outlines a framework for collaboration."
            }
        ]
    },
    {
        "id": 290,
        "q": "An organization developed an incident response plan. Which of the following would be best to assess the effectiveness of the plan?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Requesting a third-party review",
                "correct": false,
                "explain": "Incorrect. While a third-party review can be valuable, conducting an internal exercise first is a more direct way to assess the plan's effectiveness in your own environment."
            },
            {
                "text": "Generating a checklist by organizational unit",
                "correct": false,
                "explain": "Incorrect. A checklist is a tool used during a response or an exercise; it is not the assessment method itself."
            },
            {
                "text": "Establishing role succession and call lists",
                "correct": false,
                "explain": "Incorrect. These are components of the plan, not a method for assessing its effectiveness."
            },
            {
                "text": "Creating a playbook",
                "correct": false,
                "explain": "Incorrect. Playbooks are detailed procedures that are part of the overall plan. An exercise is needed to test them."
            },
            {
                "text": "Performing a tabletop exercise",
                "correct": true,
                "explain": "Correct. An incident response plan is just a document until it is tested. A tabletop exercise is a discussion-based simulation where team members walk through a hypothetical incident scenario. This process is the best way to assess the plan's effectiveness by identifying gaps, unclear procedures, communication issues, and areas where personnel need more training, all in a low-risk environment."
            }
        ]
    },
    {
        "id": 291,
        "q": "A few security incidents involving user authentication issues occurred recently. The security team needs to implement technical controls that ensure: User accounts are difficult to compromise. Certain credentials are only used for specific applications. Users are only able to perform functions specified for their specific roles. Passwords are not the only requirement for user authentication. The security team has enabled role-based access control and password complexity requirements throughout the organization. Which of the following additional actions does the security team need to take? (Choose two.)",
        "type": "multiple",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Enable MFA.",
                "correct": true,
                "explain": "Correct. The requirement that 'passwords are not the only requirement' is a direct call for Multifactor Authentication (MFA). MFA adds another layer of security, making accounts much more difficult to compromise even if the password is stolen."
            },
            {
                "text": "Enable mandatory access control.",
                "correct": false,
                "explain": "Incorrect. Mandatory Access Control (MAC) is a very rigid security model and is not typically used for general enterprise user authentication. The team has already implemented RBAC."
            },
            {
                "text": "Require the length of passwords to be 15 characters or more.",
                "correct": false,
                "explain": "Incorrect. The team has already implemented password complexity requirements. While increasing length is good, it doesn't address the other, more significant requirements."
            },
            {
                "text": "Implement a privileged access management system.",
                "correct": true,
                "explain": "Correct. A Privileged Access Management (PAM) system is designed to secure, control, and monitor access to privileged accounts. It directly addresses the requirement that 'certain credentials are only used for specific applications' by vaulting credentials and brokering sessions, preventing users from ever knowing the actual password for a sensitive application. This provides a high degree of control over privileged access."
            },
            {
                "text": "Enable OAuth.",
                "correct": false,
                "explain": "Incorrect. OAuth is a framework for delegated authorization, typically used for third-party applications. It is not a general solution for enterprise authentication and privilege management."
            },
            {
                "text": "Require unsuccessful logins to be logged throughout the network.",
                "correct": false,
                "explain": "Incorrect. Logging is a detective control, not a preventative technical control that meets the stated requirements."
            }
        ]
    },
    {
        "id": 292,
        "q": "An organization is looking to establish more robust security measures by implementing PKI. Which of the following should the security analyst implement when considering mutual authentication?",
        "type": "single",
        "category": "3.7 Explain the importance of advanced cryptographic concepts.",
        "answers": [
            {
                "text": "Perfect forward secrecy on both endpoints",
                "correct": false,
                "explain": "Incorrect. Perfect forward secrecy is a feature of the key exchange protocol, not a requirement for the certificates themselves in mutual authentication."
            },
            {
                "text": "Shared secret for both endpoints",
                "correct": false,
                "explain": "Incorrect. Mutual authentication using PKI is based on asymmetric cryptography (public/private key pairs), not shared secrets."
            },
            {
                "text": "Public keys on both endpoints",
                "correct": true,
                "explain": "Correct. In mutual authentication using Public Key Infrastructure (PKI), both the client and the server have their own unique key pair (a public key and a private key) and a corresponding digital certificate issued by a trusted Certificate Authority. The client presents its certificate to the server, and the server presents its certificate to the client. Each party uses the other's public key to validate their identity. Therefore, both endpoints must possess and exchange their public keys (via certificates)."
            },
            {
                "text": "A common public key on each endpoint",
                "correct": false,
                "explain": "Incorrect. Each endpoint must have its own unique key pair. A common public key would not provide individual authentication."
            },
            {
                "text": "A common private key on each endpoint",
                "correct": false,
                "explain": "Incorrect. Private keys must be kept secret and should never be shared. Each endpoint has its own unique private key."
            }
        ]
    },
    {
        "id": 293,
        "q": "A company was recently infected by malware. During the root cause analysis, the company determined that several users were installing their own applications. To prevent further compromises, the company has decided it will only allow authorized applications to run on its systems. Which of the following should the company implement?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Signing",
                "correct": false,
                "explain": "Incorrect. Code signing is a mechanism used by an application control system, but it is not the system itself."
            },
            {
                "text": "Access control",
                "correct": false,
                "explain": "Incorrect. This is a generic term. 'Permit listing' or application control is the specific type of access control needed."
            },
            {
                "text": "HIPS",
                "correct": false,
                "explain": "Incorrect. A Host-based Intrusion Prevention System (HIPS) monitors for malicious behavior but is less effective at enforcing a strict policy of only allowing authorized applications than a dedicated application control solution."
            },
            {
                "text": "Permit listing",
                "correct": true,
                "explain": "Correct. The requirement is to only allow authorized applications to run. This is the definition of a 'permit list,' more commonly known as an allowlist or whitelisting. The company would implement an application control solution and configure it with a list of all authorized applications. Any application not on this list would be blocked from executing, thus preventing users from installing their own unauthorized software."
            }
        ]
    },
    {
        "id": 294,
        "q": "A security consultant has been asked to recommend best practices for preserving digital evidence. Which of the following can be used to show the evidence has not been tampered with?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Legal hold",
                "correct": false,
                "explain": "Incorrect. A legal hold is a process to ensure data is not deleted, but it does not mathematically prove the data has not been altered."
            },
            {
                "text": "Checksum",
                "correct": false,
                "explain": "Incorrect. A simple checksum (like CRC32) is designed to detect accidental errors, but it is not cryptographically secure and can be easily defeated by a malicious actor. A hash value is required."
            },
            {
                "text": "Hash value",
                "correct": true,
                "explain": "Correct. To prove that digital evidence has not been tampered with, a forensic investigator calculates a cryptographic hash value (e.g., using SHA-256) of the original evidence. This hash acts as a unique digital fingerprint. At any point later in the investigation, the hash can be recalculated. If the new hash matches the original, it provides mathematical proof of the evidence's integrity."
            },
            {
                "text": "E-discovery",
                "correct": false,
                "explain": "Incorrect. E-discovery is the legal process of identifying and producing electronically stored information for a lawsuit; it is not a technique for preserving evidence integrity."
            }
        ]
    },
    {
        "id": 295,
        "q": "A cyberanalyst has been tasked with recovering PDF files from a provided image file. Which of the following is the best file-carving tool for PDF recovery?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "objdump",
                "correct": false,
                "explain": "Incorrect. objdump is a command-line program for displaying information about object files and is used in software development and reverse engineering, not forensics."
            },
            {
                "text": "Strings",
                "correct": false,
                "explain": "Incorrect. The strings command extracts printable character sequences from a file. It does not carve or recover complete files."
            },
            {
                "text": "dd",
                "correct": false,
                "explain": "Incorrect. The dd command is a low-level tool for copying and converting data. While it can be used to create a forensic image, it is not a file carving tool itself."
            },
            {
                "text": "Foremost",
                "correct": true,
                "explain": "Correct. Foremost is a classic and widely used command-line forensic tool specifically designed for file carving. It works by reading through a disk image and identifying files based on their unique headers and footers (magic numbers), even if the file system metadata is lost. It has built-in support for recovering many file types, including PDFs."
            }
        ]
    },
    {
        "id": 296,
        "q": "An organization handles sensitive information that must be displayed on call center technicians screens to verify the identities of remote callers. The technicians use three randomly selected fields of information to complete the identity verification process. Some of the fields contain PII that are unique identifiers for the remote callers. Which of the following should be implemented to identify remote callers while also reducing the risk that technicians could improperly use the identification information?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Data masking",
                "correct": true,
                "explain": "Correct. Data masking is the process of obscuring specific data within a dataset while maintaining its original format. In this case, the call center application could be configured to mask portions of the PII. For example, it might display '***-**-6789' for a social security number or 'j***.d**@email.com' for an email address. This allows the technician to see enough information to verify the caller's identity without exposing the full, sensitive PII, thus reducing the risk of misuse."
            },
            {
                "text": "Encryption",
                "correct": false,
                "explain": "Incorrect. If the data were encrypted, the technician would not be able to see it at all, making identity verification impossible."
            },
            {
                "text": "Tokenization",
                "correct": false,
                "explain": "Incorrect. Tokenization replaces the entire data field with a random token. This would also make verification impossible, as the technician would not see any part of the original data."
            },
            {
                "text": "Scrubbing",
                "correct": false,
                "explain": "Incorrect. Data scrubbing (or cleansing) is the process of fixing or removing incorrect data; it is not a security control for obscuring PII."
            },
            {
                "text": "Substitution",
                "correct": false,
                "explain": "Incorrect. Substitution is a technique used in some forms of data masking or anonymization, but 'data masking' is the broader and more appropriate term for the solution required."
            }
        ]
    },
    {
        "id": 297,
        "q": "A junior developer is informed about the impact of new malware on an Advanced RISC Machine (ARM) CPU, and the code must be fixed accordingly. Based on the debug, the malware is able to insert itself in another process memory location. Which of the following technologies can the developer enable on the ARM architecture to prevent this type of malware?",
        "type": "single",
        "category": "3.4 Given a scenario, implement hardware security technologies and techniques.",
        "answers": [
            {
                "text": "Execute never",
                "correct": true,
                "explain": "Correct. The malware is inserting itself (its code) into another process's memory space, likely a data area like the stack or heap, and then executing it. This is a classic code injection attack. The hardware-based defense against this is to mark data memory regions as non-executable. On ARM architecture CPUs, this feature is called 'Execute Never' (XN). On x86 CPUs, it's called the No-Execute (NX) bit. By enabling XN, the developer ensures that any attempt to execute code from a memory location intended for data will result in a hardware exception, stopping the attack."
            },
            {
                "text": "No-execute",
                "correct": false,
                "explain": "Incorrect. No-Execute (NX) is the term for this technology on x86 processors. The question specifically mentions the ARM architecture, where the equivalent term is Execute Never (XN)."
            },
            {
                "text": "Total memory encryption",
                "correct": false,
                "explain": "Incorrect. Memory encryption protects data confidentiality from physical attacks but does not prevent code injection attacks within the running OS."
            },
            {
                "text": "Virtual memory protection",
                "correct": false,
                "explain": "Incorrect. This is a general term. XN is the specific hardware feature that provides the required protection."
            }
        ]
    },
    {
        "id": 298,
        "q": "A security engineer is creating a single CSR for the following web server hostnames: www.int.internal, www.company.com, home.internal, www.internal. Which of the following would meet the requirement?",
        "type": "single",
        "category": "2.4 Given a scenario, apply security concepts to the design of access, authentication, and authorization systems.",
        "answers": [
            {
                "text": "SAN",
                "correct": true,
                "explain": "Correct. To secure multiple, different hostnames with a single certificate, a Subject Alternative Name (SAN) certificate is required. The Certificate Signing Request (CSR) must be created with a SAN extension that lists all the required hostnames (`www.int.internal`, `www.company.com`, etc.). The resulting certificate will then be valid for all of them."
            },
            {
                "text": "CN",
                "correct": false,
                "explain": "Incorrect. The Common Name (CN) field can only hold a single hostname and has been deprecated in favor of the SAN for modern applications."
            },
            {
                "text": "CA",
                "correct": false,
                "explain": "Incorrect. The Certificate Authority (CA) is the entity that issues the certificate; it is not a field within the certificate."
            },
            {
                "text": "CRL",
                "correct": false,
                "explain": "Incorrect. A Certificate Revocation List (CRL) is a list of revoked certificates and is not used to specify hostnames."
            },
            {
                "text": "Issuer",
                "correct": false,
                "explain": "Incorrect. The Issuer field identifies the CA that signed the certificate, not the hostnames it is valid for."
            }
        ]
    },
    {
        "id": 299,
        "q": "An analyst has prepared several possible solutions to a successful attack on the company. The solutions need to be implemented with the least amount of downtime. Which of the following should the analyst perform?",
        "type": "single",
        "category": "2.2 Given a scenario, implement security in the early stages of the systems life cycle and throughout subsequent stages.",
        "answers": [
            {
                "text": "Implement all the solutions at once in a virtual lab and then run the attack simulation. Collect the metrics and then choose the best solution based on the metrics.",
                "correct": false,
                "explain": "Incorrect. Implementing all solutions at once makes it impossible to know which one was effective or what the individual impact of each solution is."
            },
            {
                "text": "Implement every solution one at a time in a virtual lab, running a metric collection each time. After the collection, run the attack simulation, roll back each solution, and then implement the next. Choose the best solution based on the best metrics.",
                "correct": false,
                "explain": "Incorrect. This workflow is illogical. You should run the simulation while the solution is implemented to test its effectiveness."
            },
            {
                "text": "Implement every solution one at a time in a virtual lab, running an attack simulation each time while collecting metrics. Roll back each solution and then implement the next. Choose the best solution based on the best metrics.",
                "correct": true,
                "explain": "Correct. This describes a methodical and scientific approach to testing. By implementing and testing each solution individually in an isolated lab environment, the analyst can accurately measure the effectiveness of each solution against the attack and its impact on performance (e.g., downtime, latency). Rolling back each change ensures that the tests do not interfere with each other. This allows the analyst to make an evidence-based decision to select the solution that provides the best security with the least negative impact."
            },
            {
                "text": "Implement all the solutions at once in a virtual lab and then collect the metrics. After collection, run the attack simulation. Choose the best solution based on the best metrics.",
                "correct": false,
                "explain": "Incorrect. As with the first option, implementing all solutions at once prevents the analyst from understanding the effect of each individual solution."
            }
        ]
    },
    {
        "id": 300,
        "q": "A security architect examines a section of code and discovers the following: `char username[20]`, `char password[20]`, `gets(username)`, `checkUserExists(username)`. Which of the following changes should the security architect require before approving the code for release?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Allow only alphanumeric characters for the username.",
                "correct": false,
                "explain": "Incorrect. While a form of input validation, this does not fix the underlying buffer overflow vulnerability."
            },
            {
                "text": "Make the password variable longer to support more secure passwords.",
                "correct": false,
                "explain": "Incorrect. The password variable is not being used in this vulnerable section of code. The issue is with the `username` variable."
            },
            {
                "text": "Prevent more than 20 characters from being entered.",
                "correct": true,
                "explain": "Correct. The code shows the use of the `gets()` function, which is notoriously insecure because it does not perform any bounds checking. The `username` variable is allocated to hold 20 characters. If a user enters more than 20 characters, a buffer overflow will occur, potentially leading to arbitrary code execution. The correct change is to replace the unsafe `gets()` function with a safe alternative that limits the input to the size of the buffer (e.g., `fgets(username, 20, stdin)`), thereby preventing more than 20 characters from being entered and mitigating the overflow."
            },
            {
                "text": "Add a password parameter to the checkUserExists function.",
                "correct": false,
                "explain": "Incorrect. This is a functional change to the application logic and does not address the critical buffer overflow security vulnerability."
            }
        ]
    },
    {
        "id": 301,
        "q": "A security manager is creating a connection between two networks that process data at different classification levels. The main goal of this connection is to pass data from the higher classification side to the lower classification side without causing spillage. Only approved fie types and content will be allowed. Which of the following technologies would best meet this objective?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "Network access control",
                "correct": false,
                "explain": "Incorrect. Network Access Control (NAC) is used to control which devices are allowed to connect to a network; it does not manage the flow of data between networks of different classification levels."
            },
            {
                "text": "File integrity monitoring",
                "correct": false,
                "explain": "Incorrect. File integrity monitoring detects if files have been changed; it does not control the flow of information between networks."
            },
            {
                "text": "Cross-domain solution",
                "correct": true,
                "explain": "Correct. A Cross-Domain Solution (CDS) is a specialized, high-assurance information transfer system designed specifically to control the flow of data between networks of different security classifications (e.g., from a Top Secret network to a Secret network). It performs deep content inspection and filtering to prevent data spillage, perfectly matching the scenario's requirements."
            },
            {
                "text": "Microsegmentation",
                "correct": false,
                "explain": "Incorrect. Microsegmentation is a technique for creating granular security zones within a single security domain, not for connecting networks of different classification levels."
            }
        ]
    },
    {
        "id": 302,
        "q": "A security consultant has been asked to identify a simple, secure solution for a small business with a single access point. A single SSID and no guest access will be used. The customer facility is located in a crowded area of town. The customer has asked that the solution require low administrative overhead. Which of the following should the security consultant recommend?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "WPA3-Personal",
                "correct": true,
                "explain": "Correct. WPA3-Personal is the ideal choice. It offers the latest and strongest Wi-Fi security. Critically, it uses Simultaneous Authentication of Equals (SAE), which protects against offline dictionary attacks on the passworda key risk in a crowded area. The 'Personal' mode uses a simple shared password, which meets the requirement for low administrative overhead, as it doesn't require a complex RADIUS server setup like the 'Enterprise' mode does."
            },
            {
                "text": "WPA2-TKIP",
                "correct": false,
                "explain": "Incorrect. TKIP is an old, deprecated, and insecure encryption protocol that should not be used."
            },
            {
                "text": "WPA2-Enterprise",
                "correct": false,
                "explain": "Incorrect. WPA2-Enterprise requires a RADIUS server for 802.1X authentication, which represents a high administrative overhead, violating a key requirement."
            },
            {
                "text": "WPA3-Enterprise",
                "correct": false,
                "explain": "Incorrect. Like its WPA2 counterpart, WPA3-Enterprise requires a RADIUS server and has a high administrative overhead, making it unsuitable for this scenario."
            }
        ]
    },
    {
        "id": 303,
        "q": "A security team is concerned with attacks that are taking advantage of return-oriented programming against the companys public-facing applications. Which of the following should the company implement on the public-facing servers?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "IDS",
                "correct": false,
                "explain": "Incorrect. An Intrusion Detection System (IDS) is a network-level detective control and is not effective at preventing specific memory exploitation techniques within an application."
            },
            {
                "text": "ASLR",
                "correct": true,
                "explain": "Correct. Address Space Layout Randomization (ASLR) is a computer security technique which involves randomly arranging the positions of key data areas of a process, including the base of the executable and the positions of the stack, heap and libraries. Return-oriented programming (ROP) attacks rely on knowing the location of specific code 'gadgets' in memory. ASLR makes these attacks significantly more difficult to execute because the attacker no longer knows the addresses of the gadgets they intend to use."
            },
            {
                "text": "TPM",
                "correct": false,
                "explain": "Incorrect. A Trusted Platform Module (TPM) is a hardware component used for secure key storage and platform integrity measurements. It does not prevent runtime memory corruption attacks like ROP."
            },
            {
                "text": "HSM",
                "correct": false,
                "explain": "Incorrect. A Hardware Security Module (HSM) is an external device for managing cryptographic keys and is not related to application memory protection."
            }
        ]
    },
    {
        "id": 304,
        "q": "An organization is prioritizing efforts to remediate or mitigate risks identified during the latest assessment. For one of the risks, a full remediation was not possible, but the organization was able to successfully apply mitigations to reduce the likelihood of the impact. Which of the following should the organization perform next?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Assess the residual risk.",
                "correct": true,
                "explain": "Correct. Residual risk is the risk that remains after security controls and mitigations have been applied. Since a full remediation was not possible, the organization must now assess the level of risk that is left over. This assessment will determine if the residual risk is within the organization's risk appetite or if further controls are needed."
            },
            {
                "text": "Update the organizations threat model.",
                "correct": false,
                "explain": "Incorrect. While the mitigation might eventually feed into the threat model, the immediate next step is to quantify the remaining risk for the specific issue."
            },
            {
                "text": "Move to the next risk in the register.",
                "correct": false,
                "explain": "Incorrect. The process for the current risk is not complete until the residual risk has been assessed and formally accepted."
            },
            {
                "text": "Recalculate the magnitude of the impact.",
                "correct": false,
                "explain": "Incorrect. The mitigation reduced the likelihood, not necessarily the impact. Assessing the overall residual risk (which is a function of both likelihood and impact) is the correct next step."
            }
        ]
    },
    {
        "id": 305,
        "q": "A third-party organization has implemented a system that allows it to analyze customers data and deliver analysis results without being able to see the raw data. Which of the following is the organization implementing?",
        "type": "single",
        "category": "3.7 Explain the importance of advanced cryptographic concepts.",
        "answers": [
            {
                "text": "Asynchronous keys",
                "correct": false,
                "explain": "Incorrect. This is a typo for asymmetric keys, which are used in public-key cryptography. This doesn't describe the process of computing on encrypted data."
            },
            {
                "text": "Homomorphic encryption",
                "correct": true,
                "explain": "Correct. Homomorphic encryption is a form of encryption that permits users to perform computations on its ciphertext, thus generating an encrypted result which, when decrypted, matches the result of the operations as if they had been performed on the plaintext. This allows the third party to analyze the data without ever decrypting it or seeing the raw information, which exactly matches the scenario."
            },
            {
                "text": "Data lake",
                "correct": false,
                "explain": "Incorrect. A data lake is a storage repository for large amounts of raw data; it is not an encryption technology."
            },
            {
                "text": "Machine learning",
                "correct": false,
                "explain": "Incorrect. Machine learning is the process of analyzing the data; homomorphic encryption is the technology that allows this analysis to happen on encrypted data."
            }
        ]
    },
    {
        "id": 306,
        "q": "A cloud security engineer is setting up a cloud-hosted WAF. The engineer needs to implement a solution to protect the multiple websites the organization hosts. The organization websites are: www.mycompany.org, www.mycompany.com, campus.mycompany.com, wiki.mycompany.org. The solution must save costs and be able to protect all websites. Users should be able to notify the cloud security engineer of any on-path attacks. Which of the following is the best solution?",
        "type": "single",
        "category": "2.4 Given a scenario, apply security concepts to the design of access, authentication, and authorization systems.",
        "answers": [
            {
                "text": "Purchase one SAN certificate.",
                "correct": true,
                "explain": "Correct. A Subject Alternative Name (SAN) certificate is the best solution for this scenario. It allows a single certificate to secure multiple, different domain names (e.g., `mycompany.org` and `mycompany.com`) and their subdomains. This meets the requirement to protect all websites with a single certificate, which saves costs and simplifies management compared to buying four separate certificates. Modern WAFs and browsers fully support SAN certificates."
            },
            {
                "text": "Implement self-signed certificates.",
                "correct": false,
                "explain": "Incorrect. Self-signed certificates are not trusted by browsers and would generate security warnings for all external users, making them unsuitable for public websites."
            },
            {
                "text": "Purchase one certificate for each website.",
                "correct": false,
                "explain": "Incorrect. This would be more expensive and harder to manage than a single SAN certificate, violating the cost-saving requirement."
            },
            {
                "text": "Purchase one wildcard certificate.",
                "correct": false,
                "explain": "Incorrect. A wildcard certificate (e.g., `*.mycompany.com`) can only protect subdomains of a single domain. It could not protect both `mycompany.com` and `mycompany.org`."
            }
        ]
    },
    {
        "id": 307,
        "q": "A security engineer is assessing a legacy server and needs to determine if FTP is running and on which port. The service cannot be turned off, as it would impact a critical applications ability to function. Which of the following commands would provide the information necessary to create a firewall rule to prevent that service from being exploited?",
        "type": "single",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "service --status-all | grep ftpd",
                "correct": false,
                "explain": "Incorrect. This command checks the status of services managed by the older `service` utility, but it doesn't show which port the service is listening on."
            },
            {
                "text": "chkconfig --list",
                "correct": false,
                "explain": "Incorrect. `chkconfig` lists which services are configured to start at boot but does not show their current running state or the ports they are using."
            },
            {
                "text": "netstat -tulpn",
                "correct": true,
                "explain": "Correct. The `netstat` command is used to display network connections, routing tables, and interface statistics. The flags `-tulpn` are highly effective for this task: `-t` (TCP), `-u` (UDP), `-l` (listening sockets), `-p` (show program name/PID), and `-n` (numeric hosts/ports). The output of this command will show all listening services, the ports they are listening on, and the name of the process, allowing the engineer to definitively identify if an FTP daemon is running and on which port, providing the exact information needed for a firewall rule."
            },
            {
                "text": "systemctl list-unit-file --type service ftpd",
                "correct": false,
                "explain": "Incorrect. This command checks if a service unit file for `ftpd` exists for the `systemd` init system, but it does not show if the service is currently running or what port it's using."
            },
            {
                "text": "service ftpd status",
                "correct": false,
                "explain": "Incorrect. This command would check the status of a specific service named 'ftpd', but it would not reveal the port number, and the service might have a different name (e.g., 'vsftpd'). `netstat` is more comprehensive."
            }
        ]
    },
    {
        "id": 308,
        "q": "A security administrator wants to detect a potential forged sender claim in the envelope of an email. Which of the following should the security administrator implement? (Choose two).",
        "type": "multiple",
        "category": "3.3 Given a scenario, troubleshoot complex network infrastructure security issues.",
        "answers": [
            {
                "text": "MX record",
                "correct": false,
                "explain": "Incorrect. An MX record directs where to send email for a domain; it does not authenticate the sender."
            },
            {
                "text": "DMARC",
                "correct": true,
                "explain": "Correct. DMARC (Domain-based Message Authentication, Reporting, and Conformance) is a policy layer that tells receiving servers what to do with emails that fail SPF or DKIM checks. It ensures that the domain in the 'From:' header (what the user sees) aligns with the domain authenticated by SPF and/or DKIM, which directly helps detect forged sender claims."
            },
            {
                "text": "SPF",
                "correct": true,
                "explain": "Correct. Sender Policy Framework (SPF) is a DNS record that specifies which mail servers (by IP address) are authorized to send email on behalf of a domain. Receiving servers check the SPF record to verify that the email is coming from an authorized source, which helps detect forgeries of the envelope sender address."
            },
            {
                "text": "DNSSEC",
                "correct": false,
                "explain": "Incorrect. DNSSEC secures DNS lookups but does not directly authenticate email messages."
            },
            {
                "text": "S/MIME",
                "correct": false,
                "explain": "Incorrect. S/MIME uses digital signatures to provide end-to-end message integrity and authentication, but SPF and DMARC are the domain-level controls used by mail servers to detect forged envelope senders."
            },
            {
                "text": "TLS",
                "correct": false,
                "explain": "Incorrect. TLS encrypts the communication channel between mail servers but does not authenticate the sender's domain."
            }
        ]
    },
    {
        "id": 309,
        "q": "A company recently migrated its critical web application to a cloud providers environment. As part of the companys risk management program, the company intends to conduct an external penetration test. According to the scope of work and the rules of engagement, the penetration tester will validate the web applications security and check for opportunities to expose sensitive company information in the newly migrated cloud environment. Which of the following should be the first consideration prior to engaging in the test?",
        "type": "single",
        "category": "1.3 Explain how compliance affects information security strategies.",
        "answers": [
            {
                "text": "Prepare a redundant server to ensure the critical web applications availability during the test.",
                "correct": false,
                "explain": "Incorrect. While a good practice, this is a technical preparation step. The first consideration should be a legal and contractual one."
            },
            {
                "text": "Obtain agreement between the company and the cloud provider to conduct penetration testing.",
                "correct": true,
                "explain": "Correct. When a company's assets are hosted in a public cloud, the infrastructure is owned and managed by the Cloud Service Provider (CSP). Conducting a penetration test against this environment without permission could be interpreted as an attack on the CSP's infrastructure, violating their terms of service and potentially leading to legal action. Most CSPs have a formal process for customers to request and receive authorization before conducting penetration tests. This is the absolute first consideration."
            },
            {
                "text": "Ensure the latest patches and signatures are deployed on the web server.",
                "correct": false,
                "explain": "Incorrect. While patching is important, some tests are designed to be run against production systems as they are. The primary concern is getting permission to test."
            },
            {
                "text": "Create an NDA between the external penetration tester and the company.",
                "correct": false,
                "explain": "Incorrect. An NDA is a standard part of engaging any third-party tester, but getting permission from the owner of the infrastructure (the CSP) must come first."
            }
        ]
    },
    {
        "id": 310,
        "q": "A technician is reviewing the logs and notices a large number of files were transferred to remote sites over the course of three months. This activity then stopped. The files were transferred via TLS-protected HTTP sessions from systems that do not send traffic to those sites. The technician will define this threat as:",
        "type": "single",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "a decrypting RSA using an obsolete and weakened encryption attack.",
                "correct": false,
                "explain": "Incorrect. The logs state the traffic was TLS-protected, which does not suggest a decryption attack."
            },
            {
                "text": "a zero-day attack.",
                "correct": false,
                "explain": "Incorrect. While a zero-day exploit might have been used to gain initial access, the description of the overall activitylong-term, low-and-slow data exfiltrationpoints to a specific type of threat actor."
            },
            {
                "text": "an advanced persistent threat.",
                "correct": true,
                "explain": "Correct. The characteristics described are the hallmarks of an Advanced Persistent Threat (APT). APTs are characterized by their long-term presence in a network ('persistent', lasting for three months), their stealthy, low-and-slow operations (transferring files over a long period to avoid detection), and their targeted nature. The use of encrypted channels to exfiltrate data from unusual sources is also typical of an APT."
            },
            {
                "text": "an on-path attack.",
                "correct": false,
                "explain": "Incorrect. An on-path (man-in-the-middle) attack involves intercepting traffic. The scenario describes data exfiltration originating from compromised hosts, not interception."
            }
        ]
    },
    {
        "id": 311,
        "q": "The management team at a company with a large, aging server environment is conducting a server risk assessment in order to create a replacement strategy. The replacement strategy will be based upon the likelihood a server will fail, regardless of the criticality of the application running on a particular server. Which of the following should be used to prioritize the server replacements?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "SLE",
                "correct": false,
                "explain": "Incorrect. Single Loss Expectancy (SLE) is part of a quantitative risk assessment and is focused on the monetary impact of an event, which the question states should be disregarded."
            },
            {
                "text": "MTTR",
                "correct": false,
                "explain": "Incorrect. Mean Time To Repair (MTTR) is a measure of how long it takes to recover from a failure, not the likelihood of a failure occurring."
            },
            {
                "text": "TCO",
                "correct": false,
                "explain": "Incorrect. Total Cost of Ownership (TCO) is a financial estimate to help determine the direct and indirect costs of a product or system."
            },
            {
                "text": "MTBF",
                "correct": true,
                "explain": "Correct. Mean Time Between Failures (MTBF) is a metric that represents the average time elapsed between inherent failures of a mechanical or electronic system during normal operation. A server with a low MTBF is more likely to fail than one with a high MTBF. Since the replacement strategy is based solely on the likelihood of failure, MTBF is the appropriate metric to use for prioritization."
            },
            {
                "text": "MSA",
                "correct": false,
                "explain": "Incorrect. A Master Service Agreement (MSA) is a contractual document, not a risk assessment metric."
            }
        ]
    },
    {
        "id": 312,
        "q": "A company created an external application for its customers. A security researcher now reports that the application has a serious LDAP injection vulnerability that could be leveraged to bypass authentication and authorization. Which of the following actions would best resolve the issue? (Choose two.)",
        "type": "multiple",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Conduct input sanitization.",
                "correct": true,
                "explain": "Correct. LDAP injection, like SQL injection, occurs when user-supplied input is not properly sanitized and is included in an LDAP query. The long-term fix is for developers to sanitize all input by escaping special characters or using a safe framework that handles this automatically. This fixes the root cause in the code."
            },
            {
                "text": "Deploy a SIEM.",
                "correct": false,
                "explain": "Incorrect. A SIEM is for detection and alerting; it does not prevent the injection attack."
            },
            {
                "text": "Use containers.",
                "correct": false,
                "explain": "Incorrect. Containerizing the application does not fix the code-level vulnerability within it."
            },
            {
                "text": "Patch the OS.",
                "correct": false,
                "explain": "Incorrect. The vulnerability is in the application's code, not the underlying operating system."
            },
            {
                "text": "Deploy a WAF.",
                "correct": true,
                "explain": "Correct. As an immediate, compensating control, deploying a Web Application Firewall (WAF) can provide protection. A WAF can be configured with rules to inspect incoming requests for patterns that are characteristic of LDAP injection attacks and block them before they reach the vulnerable application. This is a form of 'virtual patching.'"
            },
            {
                "text": "Deploy a reverse proxy.",
                "correct": false,
                "explain": "Incorrect. While a WAF is often a feature of a reverse proxy, the specific functionality needed is the WAF itself."
            },
            {
                "text": "Deploy an IDS.",
                "correct": false,
                "explain": "Incorrect. An IDS can only detect the attack and raise an alert; it cannot block it like a WAF or an IPS can."
            }
        ]
    },
    {
        "id": 313,
        "q": "Due to reports of malware targeting companies in the same industry, an organization wants to develop a comprehensive list of IoCs to determine if its systems might be affected in a similar attack. Which of the following would be best to use to develop this list?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "Simulators",
                "correct": false,
                "explain": "Incorrect. Simulators are not a standard tool for generating IoCs from malware samples."
            },
            {
                "text": "Sandbox detonation",
                "correct": true,
                "explain": "Correct. Sandbox detonation is the process of executing a suspected malware sample in a safe, isolated, and monitored environment. The sandbox observes the malware's behavior, such as the files it creates, the registry keys it modifies, and the network connections it attempts to make. This analysis automatically generates a detailed list of Indicators of Compromise (IoCs) that can then be used to hunt for the malware in the production environment."
            },
            {
                "text": "Antivirus",
                "correct": false,
                "explain": "Incorrect. An antivirus tool can detect malware based on existing signatures, but it doesn't provide the behavioral analysis needed to develop a comprehensive list of new IoCs."
            },
            {
                "text": "Endpoint detection and response",
                "correct": false,
                "explain": "Incorrect. An EDR solution consumes IoCs to hunt for threats; it is not the tool used to generate the IoCs from a raw malware sample. The sandbox is the generation tool."
            }
        ]
    },
    {
        "id": 314,
        "q": "A firewall administrator needs to ensure all traffic across the company network is inspected. The administrator gathers data and finds the following information regarding the typical traffic in the network: <br><br> <img src='../../assets/quiz-images/CAS-005_314.png' alt='Network traffic statistics'> <br><br> Which of the following is the best solution to ensure the administrator can complete the assigned task?",
        "type": "single",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "A full-tunnel VPN",
                "correct": false,
                "explain": "Incorrect. A VPN is for securing remote access and encrypting traffic, not for inspecting it."
            },
            {
                "text": "Web content filtering",
                "correct": false,
                "explain": "Incorrect. Web content filtering inspects web traffic but cannot inspect encrypted traffic."
            },
            {
                "text": "An endpoint DLP solution",
                "correct": false,
                "explain": "Incorrect. A DLP solution focuses on preventing data loss and may not inspect all traffic for all types of threats."
            },
            {
                "text": "SSL/TLS decryption",
                "correct": true,
                "explain": "Correct. The traffic statistics show that 91.4% of the network traffic is on TCP port 443, which is HTTPS. This traffic is encrypted, meaning a standard firewall cannot inspect its contents for threats. To meet the requirement of inspecting *all* traffic, the administrator must implement SSL/TLS decryption (also known as SSL/TLS inspection or break-and-inspect) on the firewall. This allows the firewall to decrypt the traffic, inspect it against its security policies, and then re-encrypt it before sending it to its destination."
            }
        ]
    },
    {
        "id": 315,
        "q": "Which of the following is a security concern for DNP3?",
        "type": "single",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "Free-form messages require support.",
                "correct": false,
                "explain": "Incorrect. The message format is not the primary security concern."
            },
            {
                "text": "Available function codes are not standardized.",
                "correct": false,
                "explain": "Incorrect. The DNP3 function codes are standardized."
            },
            {
                "text": "Authentication is not allocated.",
                "correct": true,
                "explain": "Correct. The original Distributed Network Protocol 3 (DNP3) standard, which is widely used in Industrial Control Systems (ICS) and SCADA environments, did not include any provisions for authentication. This is a major security concern, as it allows an attacker on the network to send spoofed commands to field devices without being authenticated, potentially causing physical disruption. While a secure authentication extension was later added, many legacy deployments do not support it."
            },
            {
                "text": "It is an open source protocol.",
                "correct": false,
                "explain": "Incorrect. The fact that it is an open protocol is generally considered a security benefit ('security through obscurity' is not a valid principle), not a concern."
            }
        ]
    },
    {
        "id": 316,
        "q": "A security administrator needs to develop a remediation plan to address a large number of vulnerability scan results. Which of the following should the administrator use to determine the vulnerabilities that should be addressed first?",
        "type": "single",
        "category": "3.6 Given a scenario, use automation to secure the enterprise.",
        "answers": [
            {
                "text": "CPE",
                "correct": false,
                "explain": "Incorrect. Common Platform Enumeration (CPE) is a standardized naming scheme for IT systems and software. It's used for identification, not for scoring risk."
            },
            {
                "text": "CCE",
                "correct": false,
                "explain": "Incorrect. Common Configuration Enumeration (CCE) provides unique identifiers for system configuration issues. It is not a scoring system."
            },
            {
                "text": "CVSS",
                "correct": true,
                "explain": "Correct. The Common Vulnerability Scoring System (CVSS) is the industry standard for rating the severity of software vulnerabilities. It provides a numerical score (from 0.0 to 10.0) based on a vulnerability's technical characteristics. Administrators use the CVSS score as a primary input to prioritize their remediation efforts, addressing the highest-scoring vulnerabilities first."
            },
            {
                "text": "CVE",
                "correct": false,
                "explain": "Incorrect. Common Vulnerabilities and Exposures (CVE) is a system that provides a unique identification number for a specific, publicly known vulnerability. It is the identifier, not the scoring system."
            }
        ]
    },
    {
        "id": 317,
        "q": "An organization is researching the automation capabilities for systems within an OT network. A security analyst wants to assist with creating secure coding practices and would like to learn about the programming languages used on the PLCs. Which of the following programming languages is the most relevant for PLCs?",
        "type": "single",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "Ladder logic",
                "correct": true,
                "explain": "Correct. Ladder logic (or Ladder Diagram) is the most common and traditional programming language used for Programmable Logic Controllers (PLCs) in industrial and Operational Technology (OT) environments. It is a graphical language that mimics the appearance of relay logic schematics, making it intuitive for electricians and plant technicians."
            },
            {
                "text": "Rust",
                "correct": false,
                "explain": "Incorrect. Rust is a modern, general-purpose programming language focused on performance and safety; it is not typically used for PLC programming."
            },
            {
                "text": "C",
                "correct": false,
                "explain": "Incorrect. While some modern PLCs support C, ladder logic is far more common and relevant across the industry."
            },
            {
                "text": "Python",
                "correct": false,
                "explain": "Incorrect. Python is a high-level scripting language and is not used for the low-level, real-time control logic of PLCs."
            },
            {
                "text": "Java",
                "correct": false,
                "explain": "Incorrect. Java is a general-purpose programming language and is not used for PLC programming."
            }
        ]
    },
    {
        "id": 318,
        "q": "An organizations senior security architect would like to develop cyberdefensive strategies based on standardized adversary techniques, tactics, and procedures commonly observed. Which of the following would best support this objective?",
        "type": "single",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "OSINT analysis",
                "correct": false,
                "explain": "Incorrect. OSINT is a source of information, but a structured framework is needed to organize that information into defensive strategies."
            },
            {
                "text": "The Diamond Model of Intrusion Analysis",
                "correct": false,
                "explain": "Incorrect. The Diamond Model is used for analyzing individual intrusion events, not for developing broad defensive strategies based on standardized TTPs."
            },
            {
                "text": "MITRE ATT&CK",
                "correct": true,
                "explain": "Correct. The MITRE ATT&CK (Adversarial Tactics, Techniques, and Common Knowledge) framework is a curated knowledge base of adversary TTPs based on real-world observations. Security architects use ATT&CK as a standard reference to understand how adversaries operate and to map their defensive controls and strategies against specific techniques. This allows them to identify gaps and develop more effective, TTP-based defensive strategies."
            },
            {
                "text": "Deepfake generation",
                "correct": false,
                "explain": "Incorrect. Deepfake generation is an attack technique, not a defensive framework."
            },
            {
                "text": "Closed-source intelligence reporting",
                "correct": false,
                "explain": "Incorrect. While closed-source intelligence reports are a valuable input, the MITRE ATT&CK framework provides the standardized structure needed to turn that intelligence into actionable defensive strategies."
            }
        ]
    },
    {
        "id": 319,
        "q": "A company is looking for a solution to hide data stored in databases. The solution must meet the following requirements: Be efficient at protecting the production environment. Not require any change to the application. Act at the presentation layer. Which of the following techniques should be used?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Masking",
                "correct": true,
                "explain": "Correct. Data masking is the process of obscuring (masking) original data with fictitious but structurally similar data. Dynamic data masking acts at the presentation layer, modifying the data as it is queried and presented to a user based on their role, without changing the underlying data in the production database. This is efficient, requires no application changes, and meets all the requirements."
            },
            {
                "text": "Steganography",
                "correct": false,
                "explain": "Incorrect. Steganography is the practice of hiding data within other data (like an image) and is not a technique for protecting data within a database."
            },
            {
                "text": "Algorithmic",
                "correct": false,
                "explain": "Incorrect. 'Algorithmic' is a general term, not a specific data hiding technique."
            },
            {
                "text": "Random substitution",
                "correct": false,
                "explain": "Incorrect. Random substitution is one method used to perform data masking, but 'masking' is the name of the overall technique."
            }
        ]
    },
    {
        "id": 320,
        "q": "A software developer is working on a piece of code required by a new software package. The code should use a protocol to verify the validity of a remote identity. Which of the following should the developer implement in the code?",
        "type": "single",
        "category": "2.4 Given a scenario, apply security concepts to the design of access, authentication, and authorization systems.",
        "answers": [
            {
                "text": "RSA",
                "correct": false,
                "explain": "Incorrect. RSA is a cryptographic algorithm, not a protocol for checking certificate validity."
            },
            {
                "text": "OCSP",
                "correct": true,
                "explain": "Correct. When verifying a remote identity using a digital certificate, it's not enough to check the signature and expiration date. The developer must also check if the certificate has been revoked. The Online Certificate Status Protocol (OCSP) is a real-time protocol used to query a Certificate Authority (or its delegate) for the revocation status of a specific certificate. This is a critical step in validating a remote identity."
            },
            {
                "text": "HSTS",
                "correct": false,
                "explain": "Incorrect. HTTP Strict Transport Security (HSTS) is a policy mechanism that tells browsers to only connect to a website using HTTPS. It does not verify certificate validity."
            },
            {
                "text": "CRL",
                "correct": false,
                "explain": "Incorrect. A Certificate Revocation List (CRL) is another method for checking revocation status. However, CRLs can be large and slow to download. OCSP provides a more efficient, real-time check for a single certificate, making it the preferred protocol in many modern applications."
            }
        ]
    },
    {
        "id": 321,
        "q": "An organization is developing a disaster recovery plan that requires data to be backed up and available at a moments notice. Which of the following should the organization consider first to address this requirement?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Implement a change management plan to ensure systems are using the appropriate versions.",
                "correct": false,
                "explain": "Incorrect. Change management is an important operational process but is not the first step in DR planning."
            },
            {
                "text": "Hire additional on-call staff to be deployed if an event occurs.",
                "correct": false,
                "explain": "Incorrect. Staffing is a consideration, but it comes after the fundamental analysis of what needs to be recovered."
            },
            {
                "text": "Design an appropriate warm site for business continuity.",
                "correct": false,
                "explain": "Incorrect. Designing a recovery site is an output of the planning process. The first step is to understand the business requirements."
            },
            {
                "text": "Identify critical business processes and determine associated software and hardware requirements.",
                "correct": true,
                "explain": "Correct. The absolute first step in any disaster recovery or business continuity planning is to conduct a Business Impact Analysis (BIA). The BIA is the process used to identify the organization's most critical business processes and the IT systems (software and hardware) that support them. You cannot design an effective recovery strategy until you first know what is most important to recover."
            }
        ]
    },
    {
        "id": 322,
        "q": "A security analyst is performing a review of a web application. During testing as a standard user, the following error log appears: <br><br> <img src='../../assets/quiz-images/CAS-005_322.png' alt='Database connection error message'> <br><br> Which of the following best describes the analysts findings and a potential mitigation technique?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "The findings indicate unsecure references. All potential user input needs to be properly sanitized.",
                "correct": false,
                "explain": "Incorrect. There is no evidence of insecure direct object references in this error message."
            },
            {
                "text": "The findings indicate unsecure protocols. All cookies should be marked as HttpOnly.",
                "correct": false,
                "explain": "Incorrect. The error is not related to protocols or cookies."
            },
            {
                "text": "The findings indicate information disclosure. The displayed error message should be modified.",
                "correct": true,
                "explain": "Correct. The application is leaking a large amount of sensitive internal information in its error message, which is a form of information disclosure. It reveals the internal hostname of the database server (`USA-WebApp-Database`), the production database name (`Prod-DB01`), and a table name (`CustomerInfo`). This information is highly valuable to an attacker. The proper mitigation is to implement custom error handling that logs these detailed errors on the backend for developers but only shows a generic, non-informative error message to the user."
            },
            {
                "text": "The findings indicate a SQL injection. The database needs to be upgraded.",
                "correct": false,
                "explain": "Incorrect. There is no evidence of a SQL injection attack. The vulnerability is the verbose error message itself, not an injection flaw."
            }
        ]
    },
    {
        "id": 323,
        "q": "Which of the following is record-level encryption commonly used to do?",
        "type": "single",
        "category": "3.8 Given a scenario, apply the appropriate cryptographic use case and/or technique.",
        "answers": [
            {
                "text": "Protect database fields.",
                "correct": true,
                "explain": "Correct. Record-level encryption (also known as field-level or column-level encryption) is a technique used within a database to encrypt specific, sensitive fields (columns) within a record (row). For example, in a customer table, you might encrypt only the credit card number and social security number fields, leaving less sensitive fields like name and address in cleartext. This provides granular protection for the most sensitive data."
            },
            {
                "text": "Protect individual files.",
                "correct": false,
                "explain": "Incorrect. This is known as file-level encryption."
            },
            {
                "text": "Encrypt individual packets.",
                "correct": false,
                "explain": "Incorrect. This is done by network encryption protocols like TLS or IPsec."
            },
            {
                "text": "Encrypt the master boot record.",
                "correct": false,
                "explain": "Incorrect. This is typically part of a full disk encryption scheme."
            }
        ]
    },
    {
        "id": 324,
        "q": "An auditor is reviewing the logs from a web application to determine the source of an incident. The web application architecture includes an internet-accessible application load balancer, a number of web servers in a private subnet, application servers, and one database server in a tiered configuration. The application load balancer cannot store the logs. The following are sample log snippets: <br><br> <img src='../../assets/quiz-images/CAS-005_324.png' alt='Web, app, and DB server logs'> <br><br> Which of the following should the auditor recommend to ensure future incidents can be traced back to the sources?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "Enable the X-Forwarded-For header at the load balancer.",
                "correct": true,
                "explain": "Correct. The web server logs show that the source IP for all requests is `192.168.1.10`. In a tiered architecture, this is the IP address of the load balancer. The load balancer is terminating the client connection and initiating a new one to the web server, thus obscuring the original client's IP address. To solve this, the load balancer should be configured to insert the `X-Forwarded-For` HTTP header, which contains the original client's IP. The web server should then be configured to log this header's value, allowing incidents to be traced back to their true source."
            },
            {
                "text": "Install a software-based HIDS on the application servers.",
                "correct": false,
                "explain": "Incorrect. A HIDS would not solve the problem of the web server logs having the incorrect source IP address."
            },
            {
                "text": "Install a certificate signed by a trusted CA.",
                "correct": false,
                "explain": "Incorrect. The database server logs show a self-signed certificate, which is a separate issue. It does not solve the source IP logging problem at the web tier."
            },
            {
                "text": "Use stored procedures on the database server.",
                "correct": false,
                "explain": "Incorrect. Using stored procedures is a good practice for preventing SQL injection but is unrelated to logging the original client IP address."
            },
            {
                "text": "Store the value of the $_SERVER['REMOTE_ADDR'] received by the web servers.",
                "correct": false,
                "explain": "Incorrect. The `REMOTE_ADDR` variable is what is currently being logged, and it is showing the IP of the load balancer. This does not solve the problem."
            }
        ]
    },
    {
        "id": 325,
        "q": "An organization that performs real-time financial processing is implementing a new backup solution. Given the following business requirements: The backup solution must reduce the risk for potential backup compromise. The backup solution must be resilient to a ransomware attack. The time to restore from backups is less important than the backup data integrity. Multiple copies of production data must be maintained. Which of the following backup strategies best meets these requirements?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Creating a secondary, immutable database and adding live data on a continuous basis",
                "correct": true,
                "explain": "Correct. This solution meets all requirements. An immutable backup is one that, once written, cannot be altered or deleted for the duration of its retention period. This makes it highly resilient to ransomware, which often tries to encrypt or delete backups. Creating multiple, immutable copies ensures data integrity and availability. While continuous data addition might imply a connected backup, immutable storage systems are designed to be secure and tamper-proof, directly addressing the core risks of compromise and ransomware."
            },
            {
                "text": "Utilizing two connected storage arrays and ensuring the arrays constantly sync",
                "correct": false,
                "explain": "Incorrect. If the storage arrays are constantly connected and syncing, ransomware that infects the primary array would be immediately synced to the secondary array, corrupting the backup."
            },
            {
                "text": "Enabling remote journaling on the databases to ensure real-time transactions are mirrored",
                "correct": false,
                "explain": "Incorrect. Remote journaling is a real-time replication technique. Like synchronous storage, any corruption or malicious encryption on the primary database would be instantly replicated to the remote journal, defeating the purpose of a resilient backup."
            },
            {
                "text": "Setting up anti-tampering on the databases to ensure data cannot be changed unintentionally",
                "correct": false,
                "explain": "Incorrect. Anti-tampering controls protect the live database but do not constitute a backup solution that would be resilient to a catastrophic failure or a successful ransomware attack on the primary system."
            }
        ]
    },
    {
        "id": 326,
        "q": "A system of globally distributed certificate servers connected to HSMs provide certificate security services for a publicly available PKI. These services include OCSP, certificate revocation list issuance, and certificate signing/issuance. The HSMs are all physical devices. All other servers are virtualized. Each global site has a network load balancer, and the sites are configured to load balance between sites.Users report occasional but persistent log-on failures to different PKI-enabled websites. There is no apparent pattern to the failures. Some OCSP responses must be signed by the HSM. Each HSM is connected to a physical server containing multiple VMs for the local site with CAT 6e network cable. The backplane connecting the VMs is fiber based. Which of the following would best reduce the OCSP response time in order to rule out the connection between the certificate server and HSM as a cause of the user-reported issues?",
        "type": "single",
        "category": "3.4 Given a scenario, implement hardware security technologies and techniques.",
        "answers": [
            {
                "text": "Virtualize the HSMs and convert the virtualized servers to physical systems.",
                "correct": false,
                "explain": "Incorrect. Virtualizing HSMs would decrease their security assurance level and is not a standard practice."
            },
            {
                "text": "Replace the copper-based network infrastructure with fiber.",
                "correct": false,
                "explain": "Incorrect. The connection between the server and the HSM is already a very short CAT 6e cable, which provides more than enough bandwidth. Replacing it with fiber would have a negligible impact on performance."
            },
            {
                "text": "Shorten the time the duration certificates are valid to 72 hours and implement ACME.",
                "correct": true,
                "explain": "Correct. The problem is occasional logon failures, and the suspicion is slow OCSP responses from the HSM. A common and modern architectural solution to this problem is to issue very short-lived certificates (e.g., valid for 24-72 hours). If a certificate's lifetime is very short, the need to check for its revocation via OCSP is greatly reduced or eliminated entirely. A client can simply trust the certificate until it expires. The ACME (Automated Certificate Management Environment) protocol is then used to automate the frequent renewal of these short-lived certificates. This approach reduces the load on the OCSP responders and HSMs, improving overall performance and reliability."
            },
            {
                "text": "Reduce the number of global sites while increasing the number of HSMs.",
                "correct": false,
                "explain": "Incorrect. Reducing the number of global sites would likely increase latency for users and decrease overall resiliency."
            }
        ]
    },
    {
        "id": 327,
        "q": "An administrator brings the company's fleet of mobile devices into its PKI in order to align device WLAN NAC configurations with existing workstations and laptops. Thousands of devices need to be reconfigured in a cost-effective, time-efficient, and secure manner. Which of the following actions best achieve this goal? (Choose two.)",
        "type": "multiple",
        "category": "2.4 Given a scenario, apply security concepts to the design of access, authentication, and authorization systems.",
        "answers": [
            {
                "text": "Using the existing MDM solution to integrate with directory services for authentication and enrollment",
                "correct": false,
                "explain": "Incorrect. While the MDM is a key part of the solution, the specific protocol for automated certificate enrollment is SCEP."
            },
            {
                "text": "Deploying netAuth extended key usage certificate templates",
                "correct": false,
                "explain": "Incorrect. This is not a standard EKU."
            },
            {
                "text": "Deploying serverAuth extended key usage certificate templates",
                "correct": false,
                "explain": "Incorrect. The 'Server Authentication' EKU is for servers, not for client devices authenticating to a network."
            },
            {
                "text": "Deploying clientAuth extended key usage certificate templates",
                "correct": true,
                "explain": "Correct. The certificates being issued to the mobile devices will be used to authenticate those devices to the WLAN (Wi-Fi network). The certificate template used to issue these certificates must include the 'Client Authentication' Extended Key Usage (EKU) to specify that this is a valid purpose for the certificate."
            },
            {
                "text": "Configuring SCEP on the CA with an OTP for bulk device enrollment",
                "correct": true,
                "explain": "Correct. Manually issuing certificates for thousands of devices is not feasible. The Simple Certificate Enrollment Protocol (SCEP) is designed specifically for automated, large-scale certificate enrollment for devices like routers and mobile phones. It can be integrated with an MDM solution to securely and efficiently push certificates to the entire fleet of mobile devices."
            },
            {
                "text": "Submitting a CSR to the CA to obtain a single certificate that can be used across all devices",
                "correct": false,
                "explain": "Incorrect. Using a single certificate for all devices would be extremely insecure and would not provide individual device authentication."
            }
        ]
    },
    {
        "id": 328,
        "q": "The ISAC for the retail industry recently released a report regarding social engineering tactics in which small groups create distractions for employees while other malicious individuals install advanced card skimmers on the payment systems. The Chief Information Security Officer (CISO) thinks that security awareness training, technical control implementations, and governance already in place is adequate to protect from this threat. The board would like to test these controls. Which of the following should the CISO recommend?",
        "type": "single",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "Dark web monitoring",
                "correct": false,
                "explain": "Incorrect. Dark web monitoring is for finding stolen data or threat actor chatter; it does not test physical and social engineering controls."
            },
            {
                "text": "Adversary emulation engagement",
                "correct": true,
                "explain": "Correct. The board wants to test the existing controls against a specific, multi-faceted threat that combines social engineering and physical tampering. An adversary emulation engagement (or a red team exercise) is the perfect way to do this. A testing team would be hired to mimic the exact TTPs of the attackerscreating distractions, attempting to gain physical access, and trying to install a deviceto see if the company's controls and employee training are effective at detecting and stopping the attack."
            },
            {
                "text": "Supply chain risk consultation",
                "correct": false,
                "explain": "Incorrect. The threat described is a direct attack on the retail locations, not a supply chain attack."
            },
            {
                "text": "Tabletop exercises",
                "correct": false,
                "explain": "Incorrect. A tabletop exercise is discussion-based. To test physical controls and employee response in a real-world scenario, a live test like an adversary emulation is needed."
            }
        ]
    },
    {
        "id": 329,
        "q": "A company finds logs with modified time stamps when compared to other systems. The security team decides to improve logging and auditing for incident response. Which of the following should the team do to best accomplish this goal?",
        "type": "single",
        "category": "4.1 Given a scenario, analyze data to enable monitoring and response activities.",
        "answers": [
            {
                "text": "Integrate a file-monitoring tool with the SIEM.",
                "correct": false,
                "explain": "Incorrect. While FIM is useful, the core issue is the integrity and reliability of the logs themselves, which is best solved by a secure, centralized logging architecture."
            },
            {
                "text": "Change the log solution and integrate it with the existing SIEM.",
                "correct": false,
                "explain": "Incorrect. Simply changing the log solution doesn't guarantee security. The architecture of how the logs are handled is what matters."
            },
            {
                "text": "Implement a central logging server, allowing only log ingestion.",
                "correct": true,
                "explain": "Correct. The finding of modified timestamps indicates that an attacker with local access to a system was able to tamper with the logs on that system. To prevent this, logs should be forwarded in near real-time from endpoints to a dedicated, hardened central logging server (or SIEM). This server should be configured with write-only permissions for the log sources (log ingestion only), meaning that an attacker who compromises an endpoint cannot connect to the central server to modify or delete the logs that have already been forwarded. This creates a secure, tamper-evident audit trail."
            },
            {
                "text": "Rotate and back up logs every 24 hours, encrypting the backups.",
                "correct": false,
                "explain": "Incorrect. Backing up logs once every 24 hours leaves a large window for an attacker to modify the logs on the local system before they are backed up. Real-time forwarding is the more secure solution."
            }
        ]
    },
    {
        "id": 330,
        "q": "A company recently experienced a ransomware attack. Although the company performs systems and data backup on a schedule that aligns with its RPO requirements, the backup administrator could not recover critical systems and data from its offline backups to meet the RPO. Eventually, the systems and data were restored with information that was six months outside of RPO requirements. Which of the following actions should the company take to reduce the risk of a similar attack?",
        "type": "single",
        "category": "1.2 Given a set of organizational security requirements, perform risk management activities.",
        "answers": [
            {
                "text": "Encrypt and label the backup tapes with the appropriate retention schedule before they are sent to the off-site location.",
                "correct": false,
                "explain": "Incorrect. While good practices, this doesn't address the core failure, which was the inability to successfully restore from the backups."
            },
            {
                "text": "Implement a business continuity process that includes reverting manual business processes.",
                "correct": false,
                "explain": "Incorrect. While part of a larger BCP, this doesn't solve the IT recovery failure."
            },
            {
                "text": "Perform regular disaster recovery testing of IT and non-IT systems and process.",
                "correct": true,
                "explain": "Correct. The core failure described is that the backups, while they existed, were not viable for restoration. A backup strategy is useless if it is not regularly tested. By performing regular disaster recovery testswhich involve actually attempting to restore systems and data from backupsthe company can proactively identify and fix issues with the backup media, software, or procedures, ensuring that when a real disaster strikes, the recovery will be successful and meet the required RPO and RTO."
            },
            {
                "text": "Carry out a tabletop exercise to update and verify the RACI matrix with IT and critical business functions.",
                "correct": false,
                "explain": "Incorrect. A tabletop exercise tests plans and communication. A full disaster recovery test is needed to test the technical viability of the backups themselves."
            }
        ]
    },
    {
        "id": 331,
        "q": "A security engineer reviews the SIEM logs after a server crash. The following list of events represents the timeline of actions collected from the SIEM: <br><br> <img src='../../assets/quiz-images/CAS-005_331.png' alt='Process creation timeline'> <br><br> Which of the following best describes this type of attack?",
        "type": "single",
        "category": "3.2 Given a scenario, analyze requirements to enhance the security of endpoints and servers.",
        "answers": [
            {
                "text": "Lateral movement",
                "correct": false,
                "explain": "Incorrect. All the activity is occurring on a single system; there is no movement between systems shown."
            },
            {
                "text": "Credential dumping",
                "correct": true,
                "explain": "Correct. The timeline shows a chain of events characteristic of an attack designed to dump credentials. The attacker uses `Msbuild.exe` (a legitimate Microsoft binary) to launch PowerShell, likely as a way to bypass application controls. The PowerShell process then launches `LSASS.exe` and accesses the Security Account Manager (SAM). The Local Security Authority Subsystem Service (LSASS) process stores credentials for active users in memory, and the SAM database stores local account password hashes. Accessing LSASS and SAM in this manner is the classic technique for credential dumping."
            },
            {
                "text": "Data exfiltration",
                "correct": false,
                "explain": "Incorrect. The logs show the harvesting of credentials on the local machine; they do not show any data being sent out of the network."
            },
            {
                "text": "LOLBin use",
                "correct": false,
                "explain": "Incorrect. While the attacker is using a Living-Off-the-Land Binary (`Msbuild.exe`), the overall goal and result of the attack chain is 'credential dumping,' which is the more specific and accurate description of the attack."
            }
        ]
    },
    {
        "id": 332,
        "q": "An organization hires a security consultant to establish a SOC that includes a threat-modeling function. During initial activities, the consultant works with system engineers to identify antipatterns within the environment. Which of the following is most critical for the engineers to disclose to the consultant during this phase?",
        "type": "single",
        "category": "1.4 Given a scenario, perform threat-modeling activities.",
        "answers": [
            {
                "text": "Results from the most recent infrastructure access review",
                "correct": false,
                "explain": "Incorrect. While useful, this is a point-in-time review. A network diagram provides a more fundamental understanding of the architecture."
            },
            {
                "text": "A listing of unpatchable IoT devices in use in the data center",
                "correct": false,
                "explain": "Incorrect. This is a specific finding. The network and data flow diagrams are needed to understand the context and risk of that finding."
            },
            {
                "text": "Network and data flow diagrams covering the production environment",
                "correct": true,
                "explain": "Correct. Threat modeling is the process of identifying potential threats and vulnerabilities by analyzing a system's architecture and data flows. To identify antipatterns (common but ineffective or counterproductive practices), the consultant first needs a fundamental understanding of how the system is built. Network and data flow diagrams provide this critical foundation, showing what components exist, how they are connected, and what trust boundaries have been established."
            },
            {
                "text": "Results from the most recent software composition analysis",
                "correct": false,
                "explain": "Incorrect. SCA results show vulnerabilities in third-party code, but this is a specific detail. The overall architecture must be understood first."
            },
            {
                "text": "A current inventory of cloud resources and SaaS products in use",
                "correct": false,
                "explain": "Incorrect. An inventory is a list of assets. The diagrams show how those assets are interconnected, which is more critical for initial threat modeling."
            }
        ]
    },
    {
        "id": 333,
        "q": "In a recent audit, several critical legacy systems, which are externally exposed so that a specific vendor can manage them remotely, were identified. These systems must remain available to the vendor for the next six months. A security team segmented the network so these systems can only communicate with internal resources. Which of the following actions would be most appropriate to restore the vendor's access to manage these systems?",
        "type": "single",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "Disable all connections to the systems, and implement a backup solution to capture the needed data to send to the vendor on a weekly basis.",
                "correct": false,
                "explain": "Incorrect. The requirement is for the vendor to manage the systems remotely, which this would prevent."
            },
            {
                "text": "Create a VPN connection and set up firewall rules so only specific connections are allowed to those systems.",
                "correct": true,
                "explain": "Correct. The systems are critical but legacy, and they have been properly segmented from the main network. To provide secure remote access for the vendor, the most appropriate solution is to set up a dedicated VPN connection for that vendor. This creates an encrypted tunnel for their traffic. In addition, strict firewall rules should be implemented at the boundary of the segmented network to ensure that the vendor can only connect from their specific IP address and can only access the specific ports and protocols required for management, enforcing the principle of least privilege."
            },
            {
                "text": "Disable external connections to those systems for the next six months.",
                "correct": false,
                "explain": "Incorrect. This would prevent the vendor from managing the systems, violating the requirements."
            },
            {
                "text": "Isolate the critical systems so they can only be remotely managed from the internet.",
                "correct": false,
                "explain": "Incorrect. Allowing direct management from the public internet is what created the initial risk. Access should be controlled via a secure mechanism like a VPN."
            }
        ]
    },
    {
        "id": 334,
        "q": "While investigating an email server that crashed, an analyst reviews the following log files: <br><br> <img src='../../assets/quiz-images/CAS-005_334.png' alt='Email server log timeline'> <br><br> Which of the following is most likely the root cause?",
        "type": "single",
        "category": "4.4 Given a scenario, analyze data and artifacts in support of incident response activities.",
        "answers": [
            {
                "text": "The administrator's account credentials were intercepted and reused.",
                "correct": false,
                "explain": "Incorrect. The log shows a normal backup process initiating from the admin PC, not a malicious use of admin credentials."
            },
            {
                "text": "The backup process did not complete and caused cascading failure.",
                "correct": false,
                "explain": "Incorrect. The backup process appears to have started normally. The issue starts with the user login."
            },
            {
                "text": "A hardware failure in the storage array caused the mailboxes to be inaccessible.",
                "correct": false,
                "explain": "Incorrect. The logs point to a specific user action leading to the deletion, not a random hardware failure."
            },
            {
                "text": "A user with low privileges was able to escalate and erase all mailboxes.",
                "correct": true,
                "explain": "Correct. The log shows a clear chain of events. At 10:28, `sales-user1` logs in from `SALES-PC1`. This is a low-privilege user. At 10:30, a process `acct-switch` runs locally as SYSTEM, which could be an exploit running. Immediately after, at 10:35, a process (`mailbox-erase`) originating from the user's PC (`SALES-PC1`) but running as SYSTEM deletes the mailboxes from the disk. This indicates that the low-privilege sales user's session was used to launch an exploit that escalated privileges to the SYSTEM level, which was then used to perform the destructive action."
            }
        ]
    },
    {
        "id": 335,
        "q": "An incident response analyst finds the following content inside of a log file that was collected from a compromised server: <br><br> <img src='../../assets/quiz-images/CAS-005_335.png' alt='Obfuscated log file content'> <br><br> Which of the following is the best action to prevent future compromise?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Blocking the processing of external files by forwarding them to another server for processing",
                "correct": false,
                "explain": "Incorrect. This does not solve the root cause, which is a parsing vulnerability."
            },
            {
                "text": "Implementing an allow list for all text boxes throughout the web application",
                "correct": false,
                "explain": "Incorrect. An allow list would be too restrictive and impractical. The correct solution is to properly handle the external entities."
            },
            {
                "text": "Filtering inserted characters for all user inputs and allowing only ASCII characters",
                "correct": false,
                "explain": "Incorrect. While a form of input validation, it might not be sufficient to block this specific attack."
            },
            {
                "text": "Improving file-parsing capabilities to stop external entities from executing commands",
                "correct": true,
                "explain": "Correct. The log content shows an attempt to exploit an XML External Entity (XXE) injection vulnerability. The payload `<!XML?...<!entity...` is characteristic of an XXE attack, where the attacker tricks the XML parser into accessing local files (like `/etc/passwd`) or executing commands (`whoami`). The best way to prevent this is to configure the XML parser to disable the processing of external entities, which is the root cause of the vulnerability."
            }
        ]
    },
    {
        "id": 336,
        "q": "A company isolates its OT systems from other areas of the corporate network. These systems are required to report usage information over the internet to the vendor. Which of the following best prevents compromise or sabotage? (Choose two.)",
        "type": "multiple",
        "category": "3.5 Given a set of requirements, secure specialized and legacy systems against threats.",
        "answers": [
            {
                "text": "Implementing allow lists",
                "correct": true,
                "explain": "Correct. The OT systems only need to communicate with the vendor's specific servers. An egress firewall rule configured as an allowlist would enforce this, permitting outbound connections only to the vendor's known IP addresses and blocking all other outbound traffic. This prevents a compromised OT system from connecting to an attacker's C2 server."
            },
            {
                "text": "Monitoring network behaviors",
                "correct": true,
                "explain": "Correct. Since the allowed communication path is well-defined (OT system to vendor server), any deviation from this baseline is suspicious. Monitoring the network traffic for anomalous behaviors, such as connections to unauthorized IPs, unusual protocols, or abnormal data volumes, can help detect a compromise or sabotage attempt."
            },
            {
                "text": "Encrypting data at rest",
                "correct": false,
                "explain": "Incorrect. Encrypting data at rest on the OT system does not prevent a compromise or stop it from communicating with a malicious server."
            },
            {
                "text": "Performing boot integrity checks",
                "correct": false,
                "explain": "Incorrect. While a good practice, boot integrity checks do not prevent network-based attacks or unauthorized communication."
            },
            {
                "text": "Executing daily health checks",
                "correct": false,
                "explain": "Incorrect. A health check might determine if the system is operational but is unlikely to detect a sophisticated compromise."
            },
            {
                "text": "Implementing a site-to-site IPSec VPN",
                "correct": false,
                "explain": "Incorrect. While a VPN would secure the traffic to the vendor, a strict egress allowlist is a more fundamental control to prevent unauthorized outbound connections to any other location."
            }
        ]
    },
    {
        "id": 337,
        "q": "An organization is implementing Zero Trust architecture. A systems administrator must increase the effectiveness of the organization's context-aware access system. Which of the following is the best way to improve the effectiveness of the system?",
        "type": "single",
        "category": "2.6 Given a scenario, integrate Zero Trust concepts into system architecture design.",
        "answers": [
            {
                "text": "Secure zone architecture",
                "correct": false,
                "explain": "Incorrect. While related, microsegmentation is a more specific and effective implementation of creating secure zones in a Zero Trust model."
            },
            {
                "text": "Always-on VPN",
                "correct": false,
                "explain": "Incorrect. An always-on VPN is a connectivity tool, but it doesn't provide the granular, policy-driven isolation that microsegmentation does."
            },
            {
                "text": "RADIUS",
                "correct": false,
                "explain": "Incorrect. RADIUS is an authentication protocol and is not the primary mechanism for improving context-aware access through network isolation."
            },
            {
                "text": "Microsegmentation",
                "correct": true,
                "explain": "Correct. Context-aware access is a core pillar of Zero Trust, where access policies are dynamically enforced based on the context of the user, device, and resource. Microsegmentation dramatically increases the effectiveness of this by creating granular security boundaries around every workload or application. This allows the context-aware access system to enforce very specific policies, for example, allowing a user on a compliant device to access Application A but not Application B, even if they are on the same network. This granular enforcement point is key to improving effectiveness."
            }
        ]
    },
    {
        "id": 338,
        "q": "A company plans to deploy a new online application that provides video training for its customers. As part of the design, the application must be: Fast for all users, Available for users worldwide, Protected against attacks. Which of the following are the best components the company should use to meet these requirements? (Choose two.)",
        "type": "multiple",
        "category": "2.1 Given a scenario, analyze requirements to design resilient systems.",
        "answers": [
            {
                "text": "WAF",
                "correct": true,
                "explain": "Correct. A Web Application Firewall (WAF) is designed to protect web applications from common attacks like SQL injection and XSS. This directly addresses the requirement to be 'protected against attacks.'"
            },
            {
                "text": "IPS",
                "correct": false,
                "explain": "Incorrect. While an IPS provides protection, a WAF is more specialized for protecting web applications. A CDN often includes WAF capabilities and is a better fit for the other requirements."
            },
            {
                "text": "CDN",
                "correct": true,
                "explain": "Correct. A Content Delivery Network (CDN) addresses both the speed and availability requirements. It caches the video content in servers located all around the world, making it 'fast for all users' by reducing latency. Its distributed nature also provides a high degree of availability and can help absorb denial-of-service attacks."
            },
            {
                "text": "SASE",
                "correct": false,
                "explain": "Incorrect. SASE is a solution for securing user access to applications; it is not a solution for hosting and delivering an application to customers."
            },
            {
                "text": "VPN",
                "correct": false,
                "explain": "Incorrect. A VPN is for providing secure remote access for employees, not for delivering a public application to customers."
            },
            {
                "text": "CASB",
                "correct": false,
                "explain": "Incorrect. A CASB is for securing an organization's use of third-party cloud services, not for protecting a self-hosted application."
            }
        ]
    },
    {
        "id": 339,
        "q": "During a security review for the CI/CD process, a security engineer discovers the following information in a testing repository from the company: <br><br> <img src='../../assets/quiz-images/CAS-005_339.png' alt='WordPress config file with hardcoded credentials'> <br><br> Which of the following options is the best countermeasure to prevent this issue in the future?",
        "type": "single",
        "category": "3.1 Given a scenario, troubleshoot common issues with identity and access management (IAM) components in an enterprise environment.",
        "answers": [
            {
                "text": "Performing an application penetration test over the testing environment before moving to production",
                "correct": false,
                "explain": "Incorrect. A penetration test is a good practice, but a preventative control that stops secrets from being hardcoded is better."
            },
            {
                "text": "Changing the repository technology to avoid inclusion of confidential information",
                "correct": false,
                "explain": "Incorrect. The problem is not the repository technology (like Git), but the insecure practice of storing secrets in code."
            },
            {
                "text": "Automating the upload process of code to the repository and improving the software development life cycle",
                "correct": false,
                "explain": "Incorrect. Automating the upload does not solve the problem of what is being uploaded."
            },
            {
                "text": "Using a secrets management platform to share and manage confidential information",
                "correct": true,
                "explain": "Correct. The code snippet shows database credentials (username and password) hardcoded directly in a configuration file, which is a major security risk. The best practice and proper countermeasure is to use a dedicated secrets management platform (like HashiCorp Vault or AWS Secrets Manager). The application would then retrieve the credentials from this secure, centralized platform at runtime, eliminating the need to store them in insecure configuration files."
            }
        ]
    },
    {
        "id": 340,
        "q": "A company must meet the following security requirements when implementing controls in order to be compliant with government policy: Access to the system document repository must be MFA enabled. Ongoing risk monitoring must be displayed on a system dashboard. Staff must receive email notifications about periodic tasks. Which of the following best meets all of these requirements?",
        "type": "single",
        "category": "1.1 Given a set of organizational security requirements, implement the appropriate governance components.",
        "answers": [
            {
                "text": "Implementing a GRC tool",
                "correct": true,
                "explain": "Correct. A Governance, Risk, and Compliance (GRC) tool is a centralized platform designed to manage and automate these types of activities. Modern GRC tools can integrate with identity systems to manage access controls (like MFA), provide customizable dashboards for risk monitoring, manage and store documentation, and include workflow and notification engines to automate tasks like sending email notifications for periodic reviews."
            },
            {
                "text": "Configuring a privileged access management system",
                "correct": false,
                "explain": "Incorrect. A PAM system is focused on securing privileged accounts and would not provide the broad risk monitoring, documentation, and task notification capabilities required."
            },
            {
                "text": "Launching a vulnerability management program",
                "correct": false,
                "explain": "Incorrect. A vulnerability management program is focused on finding and fixing technical vulnerabilities, not on the broader governance and compliance tasks described."
            },
            {
                "text": "Creating a risk register",
                "correct": false,
                "explain": "Incorrect. A risk register is a document or simple database for tracking risks. It is a component of what a GRC tool manages but is not the tool itself."
            }
        ]
    },
    {
        "id": 341,
        "q": "Based on the results of a SAST report on a legacy application, a security engineer is reviewing the following snippet of code flagged as vulnerable: <br><br> <img src='../../assets/quiz-images/CAS-005_341.png' alt='Vulnerable C code snippet'> <br><br> Which of the following is the vulnerable line of code that must be changed?",
        "type": "single",
        "category": "4.2 Given a scenario, analyze vulnerabilities and attacks, and recommend solutions to reduce the attack surface.",
        "answers": [
            {
                "text": "Line [02]",
                "correct": false,
                "explain": "Incorrect. Line [02] is an include statement for the string library, which is necessary for the function but not the source of the vulnerability."
            },
            {
                "text": "Line [04]",
                "correct": false,
                "explain": "Incorrect. Line [04] initializes the input buffer. The vulnerability is in how this input is used later."
            },
            {
                "text": "Line [07]",
                "correct": false,
                "explain": "Incorrect. Line [07] declares a character pointer, which is not inherently vulnerable."
            },
            {
                "text": "Line [08]",
                "correct": false,
                "explain": "Incorrect. Line [08] uses `printf` to display the input. While format string vulnerabilities exist, the more direct and dangerous vulnerability is the buffer overflow in line [10]."
            },
            {
                "text": "Line [10]",
                "correct": true,
                "explain": "Correct. The vulnerable line is [10]: `ret_xmit = strcpy(transmit, input);`. The `strcpy` function is inherently unsafe because it does not perform bounds checking. The `input` buffer is 256 bytes long, while the `transmit` buffer is only 20 bytes long. This line of code attempts to copy 256 bytes of data into a 20-byte buffer, causing a classic stack-based buffer overflow, which can lead to a crash or arbitrary code execution. This must be replaced with a bounds-checked function like `strncpy`."
            }
        ]
    },
    {
        "id": 342,
        "q": "A company detects suspicious activity associated with inbound connections. Security detection tools are unable to categorize this activity. Which of the following is the best solution to help the company overcome this challenge?",
        "type": "single",
        "category": "4.3 Given a scenario, apply threat-hunting and threat intelligence concepts.",
        "answers": [
            {
                "text": "Implement an interactive honeypot.",
                "correct": true,
                "explain": "Correct. The company is seeing suspicious activity that its existing tools cannot identify. An interactive honeypot (or high-interaction honeypot) is a decoy system that emulates real services and applications, designed to lure attackers into interacting with it. By observing how the attacker behaves within the honeypot, the company can study their novel tools and techniques in a safe environment, helping them to understand and categorize the new, unknown threat."
            },
            {
                "text": "Map network traffic to known IoCs.",
                "correct": false,
                "explain": "Incorrect. The problem is that the activity is unknown and cannot be categorized, meaning there are likely no known IoCs for it yet."
            },
            {
                "text": "Monitor the dark web.",
                "correct": false,
                "explain": "Incorrect. Dark web monitoring might provide some intelligence, but a honeypot provides direct observation of the live attack techniques."
            },
            {
                "text": "Implement UEBA.",
                "correct": false,
                "explain": "Incorrect. While a UEBA tool might flag the activity as anomalous, it wouldn't necessarily help to categorize the threat or understand the specific TTPs being used. A honeypot is designed for this kind of in-depth analysis."
            }
        ]
    },
    {
        "id": 343,
        "q": "After discovering that an employee is using a personal laptop to access highly confidential data, a systems administrator must secure the company's data. Which of the following capabilities best addresses this situation?",
        "type": "single",
        "category": "2.5 Given a scenario, securely implement cloud capabilities in an enterprise environment.",
        "answers": [
            {
                "text": "OCSP stapling",
                "correct": false,
                "explain": "Incorrect. OCSP stapling is a performance enhancement for checking certificate revocation status and is not relevant to controlling device access."
            },
            {
                "text": "CASB",
                "correct": false,
                "explain": "Incorrect. While a CASB controls access to cloud apps, a conditional access policy is the broader mechanism for enforcing device compliance for all resources."
            },
            {
                "text": "SOAR",
                "correct": false,
                "explain": "Incorrect. SOAR is for automating incident response; it does not enforce access control policies."
            },
            {
                "text": "Conditional access",
                "correct": true,
                "explain": "Correct. Conditional access is a feature of modern identity and access management systems (like Azure AD) that acts as a policy engine. The administrator can create a conditional access policy that says, 'To access confidential data, a user must be logging in from a corporate-owned, compliant device.' This would effectively block the employee from using their personal laptop to access the data, directly addressing the situation."
            },
            {
                "text": "Package monitoring",
                "correct": false,
                "explain": "Incorrect. Package monitoring is related to software supply chain security and is not relevant here."
            }
        ]
    }
];
        
        allQuestions.forEach((q, index) => { q.displayId = `Q${index + 1}`; });

        let questions = [];
        let currentQ = 0;

        function populateCategories() {
            const listEl = document.getElementById('category-list');
            let html = '';
            examCategories.forEach(cat => {
                html += `<div class="form-check">
                    <input class="form-check-input category-checkbox" type="checkbox" value="${cat}" id="cat-${cat.replace(/\s+/g, '')}" checked>
                    <label class="form-check-label" for="cat-${cat.replace(/\s+/g, '')}">${cat}</label>
                </div>`;
            });
            listEl.innerHTML = html;
        }

        function startQuiz() {
            const selectedCategories = Array.from(document.querySelectorAll('.category-checkbox:checked')).map(cb => cb.value);
            const numToAsk = parseInt(document.getElementById('numQuestions').value, 10);
            
            if (selectedCategories.length === 0) {
                alert("Please select at least one category.");
                return;
            }

            const shouldRandomize = document.getElementById('randomizeQuestions').checked;
            const setupEl = document.getElementById('quizSetup');
            const quizEl = document.getElementById('quizContainer');
            
            let questionPool = allQuestions.filter(q => selectedCategories.includes(q.category));

            if (questionPool.length === 0) {
                alert("No questions found for the selected categories.");
                return;
            }

            if (shouldRandomize) {
                for (let i = questionPool.length - 1; i > 0; i--) {
                    const j = Math.floor(Math.random() * (i + 1));
                    [questionPool[i], questionPool[j]] = [questionPool[j], questionPool[i]];
                }
            }
            
            const finalQuestionCount = Math.min(numToAsk, questionPool.length);
            questions = questionPool.slice(0, finalQuestionCount).map(q => ({ ...q, selected: [], flagged: false }));

            if (questions.length > 0) {
                setupEl.classList.remove('d-flex');
                setupEl.classList.add('d-none');
                quizEl.classList.remove('d-none');
                document.querySelector('.progress').style.display = 'flex';
                document.querySelector('.quiz-title').textContent = 'SecurityX Practice Quiz';
                
                currentQ = 0;
                renderQuiz();
            } else {
                alert("Something went wrong. No questions were prepared for the quiz.");
            }
        }

        function resetQuiz() {
            const setupEl = document.getElementById('quizSetup');
            const quizEl = document.getElementById('quizContainer');
            questions = [];
            quizEl.classList.add('d-none');
            setupEl.classList.remove('d-none');
            setupEl.classList.add('d-flex');
        }

        function toggleAllCategories(button) {
            const checkboxes = document.querySelectorAll('.category-checkbox');
            const shouldBeChecked = button.innerText === 'Select All';
            checkboxes.forEach(cb => {
            cb.checked = shouldBeChecked;
        });

        button.innerText = shouldBeChecked ? 'Deselect All' : 'Select All';
        }

        function renderQuiz() {
            renderSidebar();
            let html = '';
            if (!questions[currentQ]) return;

            const q = questions[currentQ];
            const nextButtonHtml = currentQ === questions.length - 1
                ? `<button class="nav-btn next" onclick="finishQuiz()">Finish</button>`
                : `<button class="nav-btn next" onclick="nextQuestion()">Next</button>`;

            html += `<div class="quiz-card" id="questionCard${currentQ}">
                <div class="d-flex justify-content-between align-items-center">
                    <h5 class="mb-4">${q.displayId}: ${q.q}</h5>
                    <div>
                        <button class="btn btn-sm btn-outline-warning me-2" onclick="flagQuestion()">${q.flagged ? 'Unflag' : 'Flag'}</button>
                    </div>
                </div>
                <div>`;

            q.answers.forEach((answer, aIdx) => {
                if (q.type === "multiple") {
                    const isSelected = q.selected.includes(aIdx);
                    html += `<div class="answer-option${isSelected ? ' selected' : ''}" onclick="selectAnswer(${aIdx}, true)">
                        <input type="checkbox" ${isSelected ? "checked" : ""} style="margin-right:10px;"/>${answer.text}
                    </div>`;
                } else {
                    const isSelected = q.selected[0] === aIdx;
                    html += `<div class="answer-option${isSelected ? ' selected' : ''}" onclick="selectAnswer(${aIdx}, false)">
                        <input type="radio" name="q${currentQ}" ${isSelected ? "checked" : ""} style="margin-right:10px;"/>${answer.text}
                    </div>`;
                }
            });

            html += `</div>
                <div class="nav-btns mt-4">
                    <button class="nav-btn prev" onclick="prevQuestion()" ${currentQ === 0 ? "disabled" : ""}>Previous</button>
                    ${nextButtonHtml}
                </div>
            </div>`;
            document.getElementById('quizArea').innerHTML = html;
            updateCounters();
        }
        
        function renderSidebar() {
            let sidebar = "";
            questions.forEach((q, i) => {
                let btnClass = "sidebar-btn";
                if (i === currentQ) btnClass += " active";
                if (q.flagged) btnClass += " flagged";
                if (isAnswered(q) && !isCorrect(i)) btnClass += " missed";
                sidebar += `<button class="${btnClass}" onclick="showQuestion(${i})">${q.displayId}</button>`;
            });
            document.getElementById('sidebarList').innerHTML = sidebar;
        }

        function updateCounters() {
            const correctCount = questions.filter((q, i) => isAnswered(q) && isCorrect(i)).length;
            const incorrectCount = questions.filter((q, i) => isAnswered(q) && !isCorrect(i)).length;
            const flaggedCount = questions.filter(q => q.flagged).length;

            document.getElementById('correct-counter').innerText = correctCount;
            document.getElementById('incorrect-counter').innerText = incorrectCount;
            document.getElementById('flagged-counter').innerText = flaggedCount;
            updateProgress();
        }
        
        function updateProgress() {
            const correctCount = questions.filter((q, i) => isCorrect(i)).length;
            const percent = questions.length > 0 ? Math.round(100 * correctCount / questions.length) : 0;
            const bar = document.getElementById('progressBar');
            bar.style.width = percent + "%";
            bar.innerText = percent + "%";
        }

        function selectAnswer(aIdx, isMultiple) {
            let q = questions[currentQ];
            if (isMultiple) {
                const selIndex = q.selected.indexOf(aIdx);
                if (selIndex >= 0) {
                    q.selected.splice(selIndex, 1);
                } else {
                    q.selected.push(aIdx);
                }
            } else {
                q.selected = [aIdx];
            }
            renderQuiz();
            showExplanation(currentQ, aIdx, isMultiple);
        }

        function flagQuestion() {
            questions[currentQ].flagged = !questions[currentQ].flagged;
            renderQuiz();
        }

        function showQuestion(idx) {
            currentQ = idx;
            renderQuiz();
        }

        function nextQuestion() {
            if (currentQ < questions.length - 1) {
                currentQ++;
                renderQuiz();
            }
        }

        function prevQuestion() {
            if (currentQ > 0) {
                currentQ--;
                renderQuiz();
            }
        }
        
        function showExplanation(qIdx, aIdx, isMultiple) {
            const q = questions[qIdx];
            let explainHtml = "";
            if (isMultiple) {
                q.selected.forEach(selectedIndex => {
                    explainHtml += `<div style="margin-bottom:10px;"><strong>${q.answers[selectedIndex].text}</strong><br>${q.answers[selectedIndex].explain}</div>`;
                });
            } else {
                explainHtml = `<div><strong>${q.answers[aIdx].text}</strong><br>${q.answers[aIdx].explain}</div>`;
            }
            document.getElementById('explanationBody').innerHTML = explainHtml;
            const modalEl = document.getElementById('explanationModal');
            const modalInstance = bootstrap.Modal.getOrCreateInstance(modalEl);
            modalInstance.show();
        }

        function finishQuiz() {
            const reportHtml = generateReport();
            document.getElementById('quizArea').innerHTML = reportHtml;
            document.querySelector('.progress').style.display = 'none';
            document.querySelector('.quiz-title').textContent = 'Quiz Report';
        }

        function generateReport() {
            const totalQuestions = questions.length;
            let correctCount = 0;
            let incorrectCount = 0;
            let flaggedCount = 0;
            const objectiveStats = {};

            questions.forEach((q, index) => {
                const category = q.category;
                
                if (!objectiveStats[category]) {
                    objectiveStats[category] = { total: 0, correct: 0, incorrect: 0, flagged: 0 };
                }

                objectiveStats[category].total++;

                if (isCorrect(index)) {
                    correctCount++;
                    objectiveStats[category].correct++;
                } 

                else if (isAnswered(q)) {
                    incorrectCount++;
                    objectiveStats[category].incorrect++;
                }
                
                if (q.flagged) {
                    flaggedCount++;
                    objectiveStats[category].flagged++;
                }
            });

            const overallPercentage = totalQuestions > 0 ? ((correctCount / totalQuestions) * 100).toFixed(1) : 0;

            const reportData = {
                overallStats: {
                    totalQuestions: totalQuestions,
                    correctCount: correctCount,
                    incorrectCount: incorrectCount,
                    flaggedCount: flaggedCount,
                    overallPercentage: parseFloat(overallPercentage)
                },
                objectiveStats: objectiveStats
            };

            const jsonData = JSON.stringify(reportData, null, 2);
            console.log(jsonData);

            const blob = new Blob([jsonData], { type: 'application/json' });
            const link = document.createElement('a');
            link.href = URL.createObjectURL(blob);
            link.download = 'stats.json';
            document.body.appendChild(link);
            link.click();
            document.body.removeChild(link);
            URL.revokeObjectURL(link.href);

            let reportHtml = `<div class="quiz-card">`;
            
            reportHtml += `
                <h4 class="mb-4">Overall Score</h4>
                <div class="display-4 text-center mb-3" style="color: var(--sidebar-active);">${overallPercentage}%</div>
                <div class="d-flex justify-content-around text-center mb-5">
                    <div>
                        <div class="fs-4 fw-bold text-success">${correctCount}</div>
                        <div class="text-muted; color: white;">Correct</div>
                    </div>
                    <div>
                        <div class="fs-4 fw-bold text-danger">${incorrectCount}</div>
                        <div class="text-muted; color: white;">Incorrect</div>
                    </div>
                    <div>
                        <div class="fs-4 fw-bold text-warning">${flaggedCount}</div>
                        <div class="text-muted; color: white;">Flagged</div>
                    </div>
                </div>
                <hr style="border-top: 1px solid #444;">
            `;

            reportHtml += `<h4 class="mt-5 mb-4">Breakdown by Objective</h4>`;

            for (const category in objectiveStats) {
                if (Object.hasOwnProperty.call(objectiveStats, category)) {
                    const stats = objectiveStats[category];
                    const { total, correct, incorrect, flagged } = stats;
                    const correctPercent = total > 0 ? (correct / total) * 100 : 0;
                    const incorrectPercent = total > 0 ? (incorrect / total) * 100 : 0;
                    const flaggedPercent = total > 0 ? (flagged / total) * 100 : 0;

                    reportHtml += `
                        <div class="mb-4">
                            <p class="mb-1"><strong>${category}</strong></p>
                            <div class="d-flex justify-content-between small text-muted; color: white; mb-1">
                                <span>Total: ${total}</span>
                                <span>
                                    <span class="text-success">Correct: ${correct} (${((correct/total)*100).toFixed(0)}%)</span> | 
                                    <span class="text-danger">Incorrect: ${incorrect} (${((incorrect/total)*100).toFixed(0)}%)</span> |
                                    <span class="text-warning">Flagged: ${flagged}</span>
                                </span>
                            </div>
                            <div class="progress-bar-objective">
                                <div class="progress-bar-correct" style="width: ${correctPercent}%" title="Correct: ${correctPercent.toFixed(1)}%"></div>
                                <div class="progress-bar-incorrect" style="width: ${incorrectPercent}%" title="Incorrect: ${incorrectPercent.toFixed(1)}%"></div>
                            </div>
                        </div>
                    `;
                }
            }

            reportHtml += `</div>`;
            return reportHtml;
        }

        function isAnswered(q) {
            return q.selected && q.selected.length > 0;
        }

        function isCorrect(idx) {
            const q = questions[idx];
            if (!isAnswered(q)) return false;
            if (q.type === "multiple") {
                const correctIndices = q.answers.map((a, i) => a.correct ? i : -1).filter(i => i >= 0);
                const selectedIndices = [...q.selected].sort((a,b)=>a-b);
                if (correctIndices.length !== selectedIndices.length) return false;
                return correctIndices.every((val, index) => val === selectedIndices[index]);
            } else {
                return q.answers[q.selected[0]] && q.answers[q.selected[0]].correct;
            }
        }

        document.addEventListener('DOMContentLoaded', populateCategories);

    </script>
<script src="../../../disable_dev_tools.js"></script>
</body>
</html>